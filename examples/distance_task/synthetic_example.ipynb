{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Dacapo\n",
    "\n",
    " DaCapo is a framework that allows for easy configuration and execution of established machine learning techniques on arbitrarily large volumes of multi-dimensional images.\n",
    "\n",
    " DaCapo has 4 major configurable components:\n",
    " 1. **dacapo.datasplits.DataSplit**\n",
    "\n",
    " 2. **dacapo.tasks.Task**\n",
    "\n",
    " 3. **dacapo.architectures.Architecture**\n",
    "\n",
    " 4. **dacapo.trainers.Trainer**\n",
    "\n",
    " These are then combined in a single **dacapo.experiments.Run** that includes your starting point (whether you want to start training from scratch or continue off of a previously trained model) and stopping criterion (the number of iterations you want to train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Environment setup\n",
    " If you have not already done so, you will need to install DaCapo. You can do this by first creating a new environment and then installing DaCapo using pip.\n",
    "\n",
    " ```bash\n",
    " conda create -n dacapo python=3.10\n",
    " conda activate dacapo\n",
    " ```\n",
    "\n",
    " Then, you can install DaCapo using pip, via GitHub:\n",
    "\n",
    " ```bash\n",
    " pip install git+https://github.com/janelia-cellmap/dacapo.git\n",
    " ```\n",
    "\n",
    " Or you can clone the repository and install it locally:\n",
    "\n",
    " ```bash\n",
    " git clone https://github.com/janelia-cellmap/dacapo.git\n",
    " cd dacapo\n",
    " pip install -e .\n",
    " ```\n",
    "\n",
    " Be sure to select this environment in your Jupyter notebook or JupyterLab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Store\n",
    "To define where the data goes, create a dacapo.yaml configuration file either in `~/.config/dacapo/dacapo.yaml` or in `./dacapo.yaml`. Here is a template:\n",
    "```yaml\n",
    "type: files\n",
    "runs_base_dir: /path/to/my/data/storage\n",
    "```\n",
    "The `runs_base_dir` defines where your on-disk data will be stored. The `type` setting determines the database backend. The default is `files`, which stores the data in a file tree on disk. Alternatively, you can use `mongodb` to store the data in a MongoDB database. To use MongoDB, you will need to provide a `mongodbhost` and `mongodbname` in the configuration file:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "mongodbhost: mongodb://dbuser:dbpass@dburl:dbport/\n",
    "mongodbname: dacapo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileConfigStore:\n",
      "\tpath: /nrs/cellmap/ackermand/dacapo_learnathon/configs\n"
     ]
    }
   ],
   "source": [
    "# First we need to create a config store to store our configurations\n",
    "from dacapo.store.create_store import create_config_store\n",
    "\n",
    "config_store = create_config_store()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then let's make sure we have data to train on. If this is already provided, you can skip to the Datasplit section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dacapo import Options\n",
    "from dacapo.utils.view import get_viewer\n",
    "from examples.synthetic_source_worker import generate_synthetic_dataset\n",
    "from funlib.geometry import Coordinate\n",
    "from funlib.persistence import open_ds\n",
    "\n",
    "options = Options.instance()\n",
    "runs_base_dir = options.runs_base_dir\n",
    "force_example_creation = False\n",
    "num_workers = 32\n",
    "\n",
    "# First for training data\n",
    "train_data_path = Path(runs_base_dir, \"example_train.zarr\")\n",
    "try:\n",
    "    assert not force_example_creation\n",
    "    raw_array = open_ds(str(train_data_path), \"raw\")\n",
    "    labels_array = open_ds(str(train_data_path), \"labels\")\n",
    "except:\n",
    "    train_shape = Coordinate((512, 512, 512))\n",
    "    generate_synthetic_dataset(\n",
    "        train_data_path,\n",
    "        shape=train_shape,\n",
    "        overwrite=True,\n",
    "        num_workers=num_workers,\n",
    "        write_shape=Coordinate((128, 128, 128)),\n",
    "    )\n",
    "    raw_array = open_ds(str(train_data_path), \"raw\")\n",
    "    labels_array = open_ds(str(train_data_path), \"labels\")\n",
    "arrays = {\n",
    "    \"raw\": {\"array\": raw_array},\n",
    "    \"labels\": {\"array\": labels_array, \"meshes\": True},\n",
    "}\n",
    "get_viewer(arrays, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then for validation data\n",
    "validate_data_path = Path(runs_base_dir, \"example_validate.zarr\")\n",
    "try:\n",
    "    assert not force_example_creation\n",
    "    raw_array = open_ds(str(validate_data_path), \"raw\")\n",
    "    labels_array = open_ds(str(validate_data_path), \"labels\")\n",
    "except:\n",
    "    validate_shape = Coordinate((152, 152, 152)) * 1\n",
    "    generate_synthetic_dataset(\n",
    "        validate_data_path,\n",
    "        shape=validate_shape,\n",
    "        write_shape=Coordinate((152, 152, 152)),\n",
    "        overwrite=True,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "arrays = {\n",
    "    \"raw\": {\"array\": raw_array},\n",
    "    \"labels\": {\"array\": labels_array, \"meshes\": True},\n",
    "}\n",
    "get_viewer(arrays, headless=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then let's make some test data\n",
    "test_data_path = Path(runs_base_dir, \"example_test.zarr\")\n",
    "try:\n",
    "    assert not force_example_creation\n",
    "    raw_array = open_ds(str(test_data_path), \"raw\")\n",
    "    labels_array = open_ds(str(test_data_path), \"labels\")\n",
    "except:\n",
    "    test_shape = Coordinate((152, 152, 152)) * 3\n",
    "    generate_synthetic_dataset(\n",
    "        test_data_path,\n",
    "        shape=test_shape,\n",
    "        overwrite=True,\n",
    "        write_shape=Coordinate((152, 152, 152)),\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "arrays = {\n",
    "    \"raw\": {\"array\": raw_array},\n",
    "    \"labels\": {\"array\": labels_array, \"meshes\": True},\n",
    "}\n",
    "get_viewer(arrays, headless=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Datasplit\n",
    " Where can you find your data? What format is it in? Does it need to be normalized? What data do you want to use for validation?\n",
    " We'll assume your data is in a zarr file, and that you have a raw and a ground truth dataset, all stored in your `runs_base_dir` as `example_{type}.zarr` where `{type}` is either `train` or `validate`.\n",
    " NOTE: You may need to delete old config stores if you are re-running this cell with modifications to the configs. The config names are unique and will throw an error if you try to store a config with the same name as an existing config. For the `files` backend, you can delete the `runs_base_dir/configs` directory to remove all stored configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.experiments.datasplits.datasplit_generator: No targets specified, using all classes in the dataset as target ['labels'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuroglancer link: http://h10u28.int.janelia.org:29177/v/ed755b5bc9da5e2c1a7430ea93932da85284a040/\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dacapo.experiments.datasplits import DataSplitGenerator\n",
    "from funlib.geometry import Coordinate\n",
    "\n",
    "input_resolution = Coordinate(8, 8, 8)\n",
    "output_resolution = Coordinate(8, 8, 8)\n",
    "datasplit_config = DataSplitGenerator.generate_from_csv(\n",
    "    \"/misc/public/dacapo_learnathon/datasplit_csvs/synthetic_example.csv\",\n",
    "    input_resolution,\n",
    "    output_resolution,\n",
    ").compute()\n",
    "\n",
    "datasplit = datasplit_config.datasplit_type(datasplit_config)\n",
    "viewer = datasplit._neuroglancer()\n",
    "# config_store.store_datasplit_config(datasplit_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The above datasplit_generator automates a lot of the heavy lifting for configuring data to set up a run. The following shows everything that it is doing, and an equivalent way to set up the datasplit.\n",
    " ```python\n",
    " datasplit_config = TrainValidateDataSplitConfig(\n",
    "     name=\"synthetic_example_semantic_['labels']_8nm\",\n",
    "     train_configs=[\n",
    "         RawGTDatasetConfig(\n",
    "             name=\"example_train_[labels]_['labels']_8nm\",\n",
    "             weight=1,\n",
    "             raw_config=IntensitiesArrayConfig(\n",
    "                 name=\"raw_example_train_uint8\",\n",
    "                 source_array_config=ZarrArrayConfig(\n",
    "                     name=\"raw_example_train_uint8\",\n",
    "                     file_name=Path(\n",
    "                         \"/misc/public/dacapo_learnathon/synthetic/example_train.zarr\"\n",
    "                     ),\n",
    "                     dataset=\"raw\",\n",
    "                 ),\n",
    "                 min=0,\n",
    "                 max=255,\n",
    "             ),\n",
    "             gt_config=BinarizeArrayConfig(\n",
    "                 name=\"example_train_[labels]_labels_8nm_binarized\",\n",
    "                 source_array_config=ZarrArrayConfig(\n",
    "                     name=\"gt_example_train_labels_uint8\",\n",
    "                     file_name=Path(\n",
    "                         \"/misc/public/dacapo_learnathon/synthetic/example_train.zarr\"\n",
    "                     ),\n",
    "                     dataset=\"labels\",\n",
    "                 ),\n",
    "                 groupings=[(\"labels\", [])],\n",
    "                 background=0,\n",
    "             ),\n",
    "             mask_config=None,\n",
    "             sample_points=None,\n",
    "         )\n",
    "     ],\n",
    "     validate_configs=[\n",
    "         RawGTDatasetConfig(\n",
    "             name=\"example_validate_[labels]_['labels']_8nm\",\n",
    "             weight=1,\n",
    "             raw_config=IntensitiesArrayConfig(\n",
    "                 name=\"raw_example_validate_uint8\",\n",
    "                 source_array_config=ZarrArrayConfig(\n",
    "                     name=\"raw_example_validate_uint8\",\n",
    "                     file_name=Path(\n",
    "                         \"/misc/public/dacapo_learnathon/synthetic/example_validate.zarr\"\n",
    "                     ),\n",
    "                     dataset=\"raw\",\n",
    "                 ),\n",
    "                 min=0,\n",
    "                 max=255,\n",
    "             ),\n",
    "             gt_config=BinarizeArrayConfig(\n",
    "                 name=\"example_validate_[labels]_labels_8nm_binarized\",\n",
    "                 source_array_config=ZarrArrayConfig(\n",
    "                     name=\"gt_example_validate_labels_uint8\",\n",
    "                     file_name=Path(\n",
    "                         \"/misc/public/dacapo_learnathon/synthetic/example_validate.zarr\"\n",
    "                     ),\n",
    "                     dataset=\"labels\",\n",
    "                 ),\n",
    "                 groupings=[(\"labels\", [])],\n",
    "                 background=0,\n",
    "             ),\n",
    "             mask_config=None,\n",
    "             sample_points=None,\n",
    "         )\n",
    "     ],\n",
    " )\n",
    " config_store.store_datasplit_config(datasplit_config)\n",
    " datasplit = datasplit_config.datasplit_type(datasplit_config)\n",
    " viewer = datasplit._neuroglancer()\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task\n",
    " What do you want to learn? An instance segmentation? If so, how? Affinities,\n",
    " Distance Transform, Foreground/Background, etc. Each of these tasks are commonly learned\n",
    " and evaluated with specific loss functions and evaluation metrics. Some tasks may\n",
    " also require specific non-linearities or output formats from your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.tasks import DistanceTaskConfig\n",
    "\n",
    "task_config = DistanceTaskConfig(\n",
    "    name=\"example_distance_task\",\n",
    "    channels=[\"labels\"],\n",
    "    clip_distance=80.0,\n",
    "    tol_distance=80.0,\n",
    "    scale_factor=160.0,\n",
    ")\n",
    "# config_store.store_task_config(task_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Architecture\n",
    "\n",
    " The setup of the network you will train. Biomedical image to image translation often utilizes a UNet, but even after choosing a UNet you still need to provide some additional parameters. How much do you want to downsample? How many convolutional layers do you want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.architectures import CNNectomeUNetConfig\n",
    "\n",
    "architecture_config = CNNectomeUNetConfig(\n",
    "    name=\"example-mini_unet\",\n",
    "    input_shape=(172, 172, 172),\n",
    "    fmaps_out=24,\n",
    "    fmaps_in=1,\n",
    "    num_fmaps=12,\n",
    "    fmap_inc_factor=2,\n",
    "    downsample_factors=[(2, 2, 2), (2, 2, 2), (2, 2, 2)],\n",
    "    eval_shape_increase=(72, 72, 72),\n",
    ")\n",
    "# try:\n",
    "#     config_store.store_architecture_config(architecture_config)\n",
    "# except:\n",
    "#     config_store.delete_architecture_config(architecture_config.name)\n",
    "#     config_store.store_architecture_config(architecture_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Trainer\n",
    "\n",
    " How do you want to train? This config defines the training loop and how the other three components work together. What sort of augmentations to apply during training, what learning rate and optimizer to use, what batch size to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.experiments.trainers import GunpowderTrainerConfig\n",
    "from dacapo.experiments.trainers.gp_augments import (\n",
    "    ElasticAugmentConfig,\n",
    "    GammaAugmentConfig,\n",
    "    IntensityAugmentConfig,\n",
    "    IntensityScaleShiftAugmentConfig,\n",
    ")\n",
    "\n",
    "trainer_config = GunpowderTrainerConfig(\n",
    "    name=\"synthetic_distance_trainer\",\n",
    "    batch_size=1,\n",
    "    learning_rate=0.0001,\n",
    "    num_data_fetchers=20,\n",
    "    augments=[\n",
    "        ElasticAugmentConfig(\n",
    "            control_point_spacing=[100, 100, 100],\n",
    "            control_point_displacement_sigma=[10.0, 10.0, 10.0],\n",
    "            rotation_interval=(0.0, 1.5707963267948966),\n",
    "            subsample=8,\n",
    "            uniform_3d_rotation=True,\n",
    "        ),\n",
    "        IntensityAugmentConfig(scale=(0.25, 1.75), shift=(-0.5, 0.35), clip=True),\n",
    "        GammaAugmentConfig(gamma_range=(0.5, 2.0)),\n",
    "        IntensityScaleShiftAugmentConfig(scale=2.0, shift=-1.0),\n",
    "    ],\n",
    "    snapshot_interval=10000,\n",
    "    min_masked=0.05,\n",
    "    clip_raw = False,\n",
    ")\n",
    "# config_store.store_trainer_config(trainer_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Run\n",
    " Now that we have our components configured, we just need to combine them into a run and start training. We can have multiple repetitions of a single set of configs in order to increase our chances of finding an optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_synthetic_distance_run\n"
     ]
    }
   ],
   "source": [
    "from dacapo.experiments import RunConfig\n",
    "from dacapo.experiments.run import Run\n",
    "\n",
    "start_config = None\n",
    "\n",
    "# Uncomment to start from a pretrained model\n",
    "# start_config = StartConfig(\n",
    "#     \"setup04\",\n",
    "#     \"best\",\n",
    "# )\n",
    "\n",
    "iterations = 2000\n",
    "validation_interval = 200\n",
    "repetitions = 1\n",
    "for i in range(repetitions):\n",
    "    run_config = RunConfig(\n",
    "        name=\"example_synthetic_distance_run\",\n",
    "        # # NOTE: This is a template for the name of the run. You can customize it as you see fit.\n",
    "        # name=(\"_\").join(\n",
    "        #     [\n",
    "        #         \"example\",\n",
    "        #         \"scratch\" if start_config is None else \"finetuned\",\n",
    "        #         datasplit_config.name,\n",
    "        #         task_config.name,\n",
    "        #         architecture_config.name,\n",
    "        #         trainer_config.name,\n",
    "        #     ]\n",
    "        # )\n",
    "        # + f\"__{i}\",\n",
    "        datasplit_config=datasplit_config,\n",
    "        task_config=task_config,\n",
    "        architecture_config=architecture_config,\n",
    "        trainer_config=trainer_config,\n",
    "        num_iterations=iterations,\n",
    "        validation_interval=validation_interval,\n",
    "        repetition=i,\n",
    "        start_config=start_config,\n",
    "    )\n",
    "\n",
    "    print(run_config.name)\n",
    "    try:\n",
    "        config_store.store_run_config(run_config)\n",
    "    except:\n",
    "        config_store.delete_run_config(run_config.name)\n",
    "        config_store.store_run_config(run_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Train\n",
    " NOTE: The run stats are stored in the `runs_base_dir/stats` directory. You can delete this directory to remove all stored stats if you want to re-run training. Otherwise, the stats will be appended to the existing files, and the run won't start from scratch. This may cause errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileConfigStore:\n",
      "\tpath: /nrs/cellmap/ackermand/dacapo_learnathon/configs\n",
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n",
      "http://h10u28.int.janelia.org:29177/v/b74d1690f735762969e0aecd80ff2f3e7d3cfa2d/\n",
      "New best f1 score of 0.04102007706554391 at iteration 200 and parameter ThresholdPostProcessorParameters(id=2, threshold=150)\n",
      "New best f1 score of 0.9108554920729758 at iteration 400 and parameter ThresholdPostProcessorParameters(id=0, threshold=100)\n",
      "New best f1 score of 0.9333050279457535 at iteration 600 and parameter ThresholdPostProcessorParameters(id=0, threshold=100)\n",
      "New best f1 score of 0.9377384610691492 at iteration 1000 and parameter ThresholdPostProcessorParameters(id=0, threshold=100)\n",
      "New best f1 score of 0.9602866539173243 at iteration 1200 and parameter ThresholdPostProcessorParameters(id=0, threshold=100)\n"
     ]
    }
   ],
   "source": [
    "from dacapo.train import train_run\n",
    "from dacapo.experiments.run import Run\n",
    "from dacapo.store.create_store import create_config_store\n",
    "from dacapo.utils.view import NeuroglancerRunViewer\n",
    "\n",
    "config_store = create_config_store()\n",
    "run = Run(config_store.retrieve_run_config(run_config.name))\n",
    "\n",
    "# Visualize as we go\n",
    "run_viewer = NeuroglancerRunViewer(run)\n",
    "run_viewer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting/resuming training for run <dacapo.experiments.run.Run object at 0x150432d3a830>...\n",
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n",
      "Current state: trained until 0/2000\n",
      "Creating local weights store in directory /nrs/cellmap/ackermand/dacapo_learnathon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 100:   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.experiments.trainers.gunpowder_trainer:Saving Snapshot. Iteration: 0, Loss: 0.3048311173915863!\n",
      "training until 100:   5%|▌         | 100/2000 [00:47<14:59,  2.11it/s, loss=0.296]\n",
      "training until 200:   5%|▌         | 100/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 200:  10%|▉         | 199/2000 [00:43<13:08,  2.29it/s, loss=0.495]\n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 300:  10%|█         | 200/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n",
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 300:  10%|█         | 206/2000 [00:01<11:27,  2.61it/s, loss=0.492]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying validation inputs!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"200/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '200']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 300:  15%|█▍        | 294/2000 [00:40<07:59,  3.56it/s, loss=0.246] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d716ad2bcb4d14aad729f890526dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_02-59-27 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 300:  15%|█▍        | 296/2000 [00:41<09:52,  2.88it/s, loss=0.222]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_02-59-27:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 300:  15%|█▌        | 300/2000 [00:44<12:42,  2.23it/s, loss=0.131] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 400:  15%|█▌        | 300/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 400:  20%|█▉        | 397/2000 [00:46<12:18,  2.17it/s, loss=0.0945] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b679caab5d64732b579b89f3c47a1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-00-06 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 400:  20%|█▉        | 398/2000 [00:48<22:09,  1.21it/s, loss=0.191] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-00-06:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 400:  20%|█▉        | 399/2000 [00:48<20:07,  1.33it/s, loss=0.067]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 400:  20%|█▉        | 399/2000 [00:49<13:14,  2.02it/s, loss=0.188]\n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 500:  20%|██        | 400/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n",
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 500:  20%|██        | 404/2000 [00:01<12:30,  2.13it/s, loss=0.0745]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"400/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '400']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 500:  25%|██▍       | 492/2000 [00:46<18:57,  1.33it/s, loss=0.166] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8596eec3e81d47e397ba48fab70cb9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-01-01 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 500:  25%|██▍       | 494/2000 [00:47<13:49,  1.82it/s, loss=0.104] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-01-01:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 500:  25%|██▍       | 496/2000 [00:48<12:37,  1.99it/s, loss=0.155] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 500:  25%|██▌       | 500/2000 [00:49<12:22,  2.02it/s, loss=0.0937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  25%|██▌       | 500/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  25%|██▌       | 502/2000 [00:01<22:51,  1.09it/s, loss=0.0903]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  26%|██▌       | 513/2000 [00:09<14:48,  1.67it/s, loss=0.0677]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7655756dda0e48fd8decbe668a6010da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-01-01 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  26%|██▌       | 514/2000 [00:10<16:37,  1.49it/s, loss=0.139] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-01-01:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  28%|██▊       | 552/2000 [00:32<15:58,  1.51it/s, loss=0.118]  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc89fb321aa4ee1a1c081d1069746f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-01-50 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  28%|██▊       | 555/2000 [00:35<16:35,  1.45it/s, loss=0.225]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-01-50:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  28%|██▊       | 561/2000 [00:39<17:05,  1.40it/s, loss=0.108] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  29%|██▊       | 573/2000 [00:45<15:33,  1.53it/s, loss=0.168] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507e8d0db3e9441585e5c763bd1d51f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-01-59 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  29%|██▊       | 574/2000 [00:48<29:02,  1.22s/it, loss=0.0896]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-01-59:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  29%|██▉       | 577/2000 [00:49<17:05,  1.39it/s, loss=0.293] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 600:  30%|██▉       | 599/2000 [01:00<14:11,  1.64it/s, loss=0.0946]\n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n",
      "training until 700:  30%|███       | 600/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n",
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  30%|███       | 608/2000 [00:02<06:20,  3.66it/s, loss=0.0468]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"600/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '600']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  31%|███▏      | 626/2000 [00:13<09:22,  2.44it/s, loss=0.0857]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4235c0f3a2614486ae9419e90f839956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-02-39 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  32%|███▏      | 630/2000 [00:14<04:54,  4.66it/s, loss=0.0555] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-02-39:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  32%|███▏      | 631/2000 [00:16<18:20,  1.24it/s, loss=0.161] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  32%|███▏      | 632/2000 [00:17<18:02,  1.26it/s, loss=0.0804]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  34%|███▍      | 683/2000 [00:46<12:27,  1.76it/s, loss=0.045]  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c5f113f008e470abd16ffc37e8c3cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-03-08 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  34%|███▍      | 688/2000 [00:48<11:27,  1.91it/s, loss=0.0395]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa0e818b6a04a79b533a378642f5deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-02-52 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  34%|███▍      | 689/2000 [00:49<13:02,  1.68it/s, loss=0.0573]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-03-08:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  35%|███▍      | 691/2000 [00:49<08:33,  2.55it/s, loss=0.0946]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  35%|███▍      | 692/2000 [00:49<07:57,  2.74it/s, loss=1.35]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-02-52:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  35%|███▍      | 696/2000 [00:54<16:08,  1.35it/s, loss=0.12]  WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 700:  35%|███▌      | 700/2000 [00:57<12:26,  1.74it/s, loss=0.16]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 800:  35%|███▌      | 700/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 800:  37%|███▋      | 735/2000 [00:17<08:35,  2.46it/s, loss=0.0322]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9245a2eb424a0e867660c06180bc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-03-40 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 800:  37%|███▋      | 738/2000 [00:19<13:46,  1.53it/s, loss=0.146] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-03-40:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 800:  37%|███▋      | 740/2000 [00:22<20:41,  1.01it/s, loss=1.28] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 800:  40%|███▉      | 799/2000 [00:51<10:21,  1.93it/s, loss=0.18]   \n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 800\n",
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  40%|████      | 800/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n",
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  40%|████      | 804/2000 [00:01<10:22,  1.92it/s, loss=0.163]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"800/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '800']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  41%|████      | 812/2000 [00:05<05:29,  3.60it/s, loss=0.213] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dfd4e126c94a379a9f5b400186616e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-04-10 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  41%|████      | 815/2000 [00:07<11:15,  1.76it/s, loss=0.117]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-04-10:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  41%|████      | 817/2000 [00:08<09:21,  2.11it/s, loss=0.159]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  43%|████▎     | 868/2000 [00:38<12:01,  1.57it/s, loss=0.0443]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cde7e576cf24f6c802096e733ba8ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-04-49 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  44%|████▎     | 873/2000 [00:40<09:07,  2.06it/s, loss=0.194] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-04-49:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  44%|████▎     | 874/2000 [00:40<09:52,  1.90it/s, loss=0.0219]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  44%|████▍     | 877/2000 [00:43<12:24,  1.51it/s, loss=0.0482]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b725b38580fb4161bc8bfd060d4fb5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-04-41 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  44%|████▍     | 878/2000 [00:43<11:51,  1.58it/s, loss=0.0059]WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n",
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-04-41:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 900:  45%|████▌     | 900/2000 [00:57<10:36,  1.73it/s, loss=0.0804]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  45%|████▌     | 900/2000 [00:00<?, ?it/s, loss=0.0192]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  46%|████▌     | 920/2000 [00:10<21:42,  1.21s/it, loss=0.0448]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617899a50f8d4988b758a2b5dd73e380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-05-23 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  46%|████▌     | 923/2000 [00:12<13:13,  1.36it/s, loss=0.0316]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-05-23:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  46%|████▋     | 925/2000 [00:12<07:52,  2.28it/s, loss=0.0196]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  47%|████▋     | 931/2000 [00:14<05:41,  3.13it/s, loss=0.00906]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  49%|████▉     | 980/2000 [00:40<10:51,  1.57it/s, loss=0.0257] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1affe1df388240ed8474217fd3327982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-05-52 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  49%|████▉     | 985/2000 [00:42<08:41,  1.95it/s, loss=0.0259]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-05-52:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  50%|████▉     | 990/2000 [00:46<10:02,  1.68it/s, loss=0.0724]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1000:  50%|████▉     | 999/2000 [00:51<08:40,  1.92it/s, loss=0.0307]\n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 1000\n",
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1100:  50%|█████     | 1000/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n",
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1100:  50%|█████     | 1003/2000 [00:02<12:41,  1.31it/s, loss=0.0451]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"1000/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '1000']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1100:  51%|█████     | 1021/2000 [00:09<04:39,  3.50it/s, loss=0.137]  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93918872301d4607b6190288bebecece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-06-24 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1100:  51%|█████     | 1022/2000 [00:11<11:08,  1.46it/s, loss=0.0381]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-06-24:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1100:  51%|█████▏    | 1025/2000 [00:15<13:51,  1.17it/s, loss=0.121] WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n",
      "training until 1100:  51%|█████▏    | 1026/2000 [00:16<15:08,  1.07it/s, loss=0.145]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1100:  52%|█████▎    | 1050/2000 [00:28<08:30,  1.86it/s, loss=0.0497]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9703bcc8d1548ada2ede2e44effac3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-06-32 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1100:  53%|█████▎    | 1053/2000 [00:28<05:29,  2.88it/s, loss=0.0253]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-06-32:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1100:  55%|█████▌    | 1100/2000 [00:51<07:44,  1.94it/s, loss=0.0775] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1200:  55%|█████▌    | 1101/2000 [00:00<01:32,  9.73it/s, loss=0.033]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1200:  57%|█████▋    | 1137/2000 [00:17<07:26,  1.93it/s, loss=0.0431] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a874fd33c7a94adeb61049eaaef5f21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-06-58 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1200:  57%|█████▋    | 1141/2000 [00:19<07:46,  1.84it/s, loss=0.0257]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-06-58:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1200:  57%|█████▋    | 1146/2000 [00:22<06:08,  2.32it/s, loss=0.0563]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1200:  60%|█████▉    | 1199/2000 [00:48<06:34,  2.03it/s, loss=0.061]  \n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 1200\n",
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1300:  60%|██████    | 1200/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n",
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1300:  60%|██████    | 1202/2000 [00:00<04:07,  3.23it/s, loss=0.0407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"1200/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '1200']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1300:  62%|██████▏   | 1248/2000 [00:23<04:18,  2.91it/s, loss=0.155] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f1ddd21297454d9f1cc40decaca7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-07-43 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1300:  63%|██████▎   | 1253/2000 [00:26<05:14,  2.37it/s, loss=0.236] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-07-43:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1300:  63%|██████▎   | 1257/2000 [00:28<05:03,  2.45it/s, loss=0.0772]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1300:  65%|██████▌   | 1300/2000 [00:51<06:02,  1.93it/s, loss=0.161] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1400:  65%|██████▌   | 1301/2000 [00:00<01:10,  9.91it/s, loss=0.166]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1400:  66%|██████▋   | 1328/2000 [00:11<03:27,  3.24it/s, loss=0.145] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca163106361d407a953d2ec47ff4c5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-08-12 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1400:  66%|██████▋   | 1329/2000 [00:12<04:43,  2.37it/s, loss=0.795]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-08-12:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1400:  68%|██████▊   | 1358/2000 [00:27<08:57,  1.20it/s, loss=0.0971]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19397195c0674fb0b4bedc56d138e7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-08-38 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1400:  68%|██████▊   | 1361/2000 [00:29<07:33,  1.41it/s, loss=0.127] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-08-38:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1400:  68%|██████▊   | 1362/2000 [00:30<06:55,  1.53it/s, loss=0.0957]WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1400:  70%|██████▉   | 1399/2000 [00:51<05:11,  1.93it/s, loss=0.0312]\n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 1400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n",
      "training until 1500:  70%|███████   | 1401/2000 [00:00<01:03,  9.38it/s, loss=0.111]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n",
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1500:  70%|███████   | 1405/2000 [00:01<03:09,  3.14it/s, loss=0.0423]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1500:  70%|███████   | 1406/2000 [00:02<05:04,  1.95it/s, loss=0.0127]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"1400/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '1400']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1500:  72%|███████▏  | 1432/2000 [00:16<05:17,  1.79it/s, loss=0.0617]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14b0999cd8240e6817a0a021287de69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-09-15 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1500:  72%|███████▏  | 1436/2000 [00:18<04:55,  1.91it/s, loss=0.0748]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-09-15:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1500:  72%|███████▏  | 1442/2000 [00:21<03:15,  2.86it/s, loss=0.0184]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1500:  75%|███████▌  | 1500/2000 [00:49<04:07,  2.02it/s, loss=0.00473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1600:  75%|███████▌  | 1500/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1600:  77%|███████▋  | 1544/2000 [00:21<02:24,  3.16it/s, loss=0.0589] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e899c1e1b45462d90203d4d70d01e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-10-16 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1600:  77%|███████▋  | 1545/2000 [00:22<03:32,  2.14it/s, loss=0.0144]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-10-16:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1600:  77%|███████▋  | 1546/2000 [00:25<10:39,  1.41s/it, loss=0.0986]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8750e7cb2e4eb3aedf46caab3c20b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-09-56 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1600:  78%|███████▊  | 1550/2000 [00:26<03:17,  2.27it/s, loss=0.0362]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-09-56:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1600:  78%|███████▊  | 1551/2000 [00:26<03:37,  2.06it/s, loss=0.573] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1600:  78%|███████▊  | 1552/2000 [00:28<05:42,  1.31it/s, loss=0.0405]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1600:  80%|███████▉  | 1599/2000 [00:50<03:26,  1.94it/s, loss=0.0422]  \n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 1600\n",
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1700:  80%|████████  | 1600/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n",
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1700:  80%|████████  | 1602/2000 [00:01<05:04,  1.31it/s, loss=0.0521]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"1600/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '1600']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1700:  85%|████████▍ | 1692/2000 [00:52<02:59,  1.71it/s, loss=0.0505] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43470af4be9548778ba2f19000005ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-11-11 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4e511903084df1b7df77896d706b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-11-10 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1700:  85%|████████▍ | 1696/2000 [00:54<03:15,  1.56it/s, loss=0.049] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-11-11:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-11-10:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1700:  85%|████████▌ | 1700/2000 [00:57<02:52,  1.74it/s, loss=0.286]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1800:  85%|████████▌ | 1701/2000 [00:00<00:38,  7.82it/s, loss=0.0287]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1800:  87%|████████▋ | 1742/2000 [00:20<02:07,  2.03it/s, loss=0.0633]  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a302dbd550a4738bca84cf844521ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-11-37 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-11-37:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1800:  90%|████████▉ | 1799/2000 [00:51<01:43,  1.94it/s, loss=0.0317]  \n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1900:  90%|█████████ | 1800/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1900:  90%|█████████ | 1803/2000 [00:01<01:32,  2.12it/s, loss=0.00701]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"1800/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '1800']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1900:  93%|█████████▎| 1865/2000 [00:35<00:58,  2.30it/s, loss=0.0107] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a7fba0356a4d1698c156948735a3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-12-33 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1900:  94%|█████████▎| 1871/2000 [00:38<00:52,  2.45it/s, loss=0.00243] "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672da980665747bf91f7bc285f7de245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-12-54 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-12-33:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1900:  94%|█████████▎| 1872/2000 [00:40<02:09,  1.01s/it, loss=0.00691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-12-54:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1900:  94%|█████████▍| 1880/2000 [00:46<00:40,  2.95it/s, loss=0.0033] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 1900:  95%|█████████▌| 1900/2000 [00:56<00:56,  1.78it/s, loss=0.0146] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 2000:  95%|█████████▌| 1900/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training until 2000: 100%|█████████▉| 1999/2000 [00:56<00:00,  1.75it/s, loss=0.00962]\n",
      "WARNING:dacapo.store.local_weights_store:Storing weights for run <dacapo.experiments.run.Run object at 0x150432d3a830>, iteration 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating training stats of run example_synthetic_distance_run after iteration 1900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating run example_synthetic_distance_run on dataset example_validate_[labels]_['labels']_8nm\n",
      "Trained until 2000. Finished.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fc1fda45454e06a373d0b249d9373e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-14-06 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation inputs already copied!\n",
      "Predicting with input size (1952, 1952, 1952), output size (1216, 1216, 1216)\n",
      "Total input ROI: [-368:1584, -368:1584, -368:1584] (1952, 1952, 1952), output ROI: [0:1216, 0:1216, 0:1216] (1216, 1216, 1216)\n",
      "Running blockwise prediction with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Defining worker with command:  ['/misc/sc/miniforge/envs/dacapo/bin/python', '/groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py', 'start-worker', '--run-name', 'example_synthetic_distance_run', '--input_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--input_dataset', \"inputs/example_validate_[labels]_['labels']_8nm/raw\", '--output_container', '/nrs/cellmap/ackermand/dacapo_learnathon/example_synthetic_distance_run/validation.zarr', '--output_dataset', \"2000/example_validate_[labels]_['labels']_8nm/prediction\", '--iteration', '2000']\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/predict_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n",
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-14-06:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611bbeab058443ea99b4d8b09d82fbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-14-11 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n",
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-14-11:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a69b65516c43bba98d8bcebc974981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-13-26 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-13-26:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3183199cb646e8bf71dd3038806e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-15-24 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d6fb31155d48238edbb061e341ba26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-15-33 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-15-24:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n",
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-15-33:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3c8ea42120412d9817ba7ef72e1c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predict_worker2024-03-21_03-15-19 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task predict_worker2024-03-21_03-15-19:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Done predicting.\n",
      "Predicted on dataset example_validate_[labels]_['labels']_8nm\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc3c1aab2be49fe80e08b8a46a619c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-16-17 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-16-17:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc0be80ac7a4abfbb1c8789ed600e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-16-19 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n",
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-16-19:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25bfb29c7bf4216b9f2351e0038c05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-16-42 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17189162aca04b7ca85b663bb3ca4b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-16-40 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-16-42:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-16-40:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n",
      "Running blockwise with worker_file:  /groups/cellmap/cellmap/ackermand/Programming/dacapo/dacapo/blockwise/threshold_worker.py\n",
      "Using compute context: LocalTorch(_device=None, oom_limit=4.2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd4cebcd4f948b09159b0759c4d6b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "threshold_worker2024-03-21_03-17-28 ▶:   0%|          | 0/1 [00:00<?, ?blocks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Execution Summary\n",
      "-----------------\n",
      "\n",
      "  Task threshold_worker2024-03-21_03-17-28:\n",
      "\n",
      "    num blocks : 1\n",
      "    completed ✔: 1 (skipped 0)\n",
      "    failed    ✗: 0\n",
      "    orphaned  ∅: 0\n",
      "\n",
      "    all blocks processed successfully\n",
      "Evaluating binary segmentations on evaluation_data of shape: (152, 152, 152)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dacapo.store.file_stats_store:Overwriting previous validation scores for run example_synthetic_distance_run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating FileStatsStore:\n",
      "\tpath    : /nrs/cellmap/ackermand/dacapo_learnathon/stats\n"
     ]
    }
   ],
   "source": [
    "train_run(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_viewer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " If you want to start your run on some compute cluster, you might want to use the command line interface: dacapo train -r {run_config.name}. This makes it particularly convenient to run on compute nodes where you can specify specific compute requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Validate\n",
    " Once you have trained your model, you can validate it on the validation datasets used during training. You can use the `dacapo.validate` function to do this. You can also use the command line interface to validate a run: dacapo validate -r {run_config.name} -i {iteration}\n",
    " Generally we setup training to automatically validate at a set interval and the model checkpoints are saved at these intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.validate import validate\n",
    "\n",
    "validate(run_config.name, iterations, num_workers=1, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Predict\n",
    " Once you have trained and validated your model, you can use it to predict on new data. You can use the `dacapo.predict` function to do this. You can also use the command line interface to predict on a run: dacapo predict -r {run_config.name} -i {iteration} -ic {input_container} -id {input_dataset} -op {output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo.predict import predict\n",
    "\n",
    "predict(\n",
    "    run_config.name,\n",
    "    iterations,\n",
    "    test_data_path,\n",
    "    \"raw\",\n",
    "    test_data_path,\n",
    "    # num_workers=32,\n",
    "    num_workers=1,\n",
    "    overwrite=True,\n",
    "    output_dtype=\"float32\",\n",
    "    output_roi=raw_array.roi,\n",
    ")\n",
    "\n",
    "raw_array = open_ds(str(test_data_path), \"raw\")\n",
    "pred_array = open_ds(str(test_data_path), \"predictions\")\n",
    "gt_array = open_ds(str(test_data_path), \"labels\")\n",
    "\n",
    "arrays = {\n",
    "    \"raw\": {\"array\": raw_array},\n",
    "    \"labels\": {\"array\": gt_array, \"meshes\": True},\n",
    "    \"predictions\": {\"array\": pred_array},\n",
    "}\n",
    "get_viewer(arrays, headless=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
