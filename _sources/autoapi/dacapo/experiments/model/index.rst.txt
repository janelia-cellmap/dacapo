dacapo.experiments.model
========================

.. py:module:: dacapo.experiments.model


Classes
-------

.. autoapisummary::

   dacapo.experiments.model.Architecture
   dacapo.experiments.model.Model


Module Contents
---------------

.. py:class:: Architecture(*args, **kwargs)



   An abstract base class for defining the architecture of a neural network model.
   It is inherited from PyTorch's Module and built-in class `ABC` (Abstract Base Classes).
   Other classes can inherit this class to define their own specific variations of architecture.
   It requires to implement several property methods, and also includes additional methods related to the architecture design.

   .. attribute:: input_shape

      The spatial input shape for the neural network architecture.

      :type: Coordinate

   .. attribute:: eval_shape_increase

      The amount to increase the input shape during prediction.

      :type: Coordinate

   .. attribute:: num_in_channels

      The number of input channels required by the architecture.

      :type: int

   .. attribute:: num_out_channels

      The number of output channels provided by the architecture.

      :type: int

   .. method:: dims

      Returns the number of dimensions of the input shape.

   .. method:: scale

      Scales the input voxel size as required by the architecture.

   .. note:: The class is abstract and requires to implement the abstract methods.


   .. py:property:: input_shape
      :type: funlib.geometry.Coordinate

      :abstractmethod:

      Abstract method to define the spatial input shape for the neural network architecture.
      The shape should not account for the channels and batch dimensions.

      :returns: The spatial input shape.
      :rtype: Coordinate

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> input_shape = Coordinate((128, 128, 128))
      >>> model = MyModel(input_shape)

      .. note:: The method should be implemented in the derived class.


   .. py:property:: eval_shape_increase
      :type: funlib.geometry.Coordinate

      Provides information about how much to increase the input shape during prediction.

      :returns: An instance representing the amount to increase in each dimension of the input shape.
      :rtype: Coordinate

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> eval_shape_increase = Coordinate((0, 0, 0))
      >>> model = MyModel(input_shape, eval_shape_increase)

      .. note:: The method is optional and can be overridden in the derived class.


   .. py:property:: num_in_channels
      :type: int

      :abstractmethod:

      Abstract method to return number of input channels required by the architecture.

      :returns: Required number of input channels.
      :rtype: int

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> num_in_channels = 1
      >>> model = MyModel(input_shape, num_in_channels)

      .. note:: The method should be implemented in the derived class.


   .. py:property:: num_out_channels
      :type: int

      :abstractmethod:

      Abstract method to return the number of output channels provided by the architecture.

      :returns: Number of output channels.
      :rtype: int

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> num_out_channels = 1
      >>> model = MyModel(input_shape, num_out_channels)

      .. note:: The method should be implemented in the derived class.


   .. py:property:: dims
      :type: int

      Returns the number of dimensions of the input shape.

      :returns: The number of dimensions.
      :rtype: int

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> input_shape = Coordinate((128, 128, 128))
      >>> model = MyModel(input_shape)
      >>> model.dims
      3

      .. note:: The method is optional and can be overridden in the derived class.


   .. py:method:: scale(input_voxel_size: funlib.geometry.Coordinate) -> funlib.geometry.Coordinate

      Method to scale the input voxel size as required by the architecture.

      :param input_voxel_size: The original size of the input voxel.
      :type input_voxel_size: Coordinate

      :returns: The scaled voxel size.
      :rtype: Coordinate

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> input_voxel_size = Coordinate((1, 1, 1))
      >>> model = MyModel(input_shape)
      >>> model.scale(input_voxel_size)
      Coordinate((1, 1, 1))

      .. note:: The method is optional and can be overridden in the derived class.



.. py:class:: Model(architecture: dacapo.experiments.architectures.architecture.Architecture, prediction_head: torch.nn.Module, eval_activation: torch.nn.Module | None = None)



   A trainable DaCapo model. Consists of an ``Architecture`` and a
   prediction head. Models are generated by ``Predictor``s.

   May include an optional eval_activation that is only executed when the model
   is in eval mode. This is particularly useful if you want to train with something
   like BCELossWithLogits, since you want to avoid applying softmax while training,
   but apply it during evaluation.

   .. attribute:: architecture

      The architecture of the model.

      :type: Architecture

   .. attribute:: prediction_head

      The prediction head of the model.

      :type: torch.nn.Module

   .. attribute:: chain

      The architecture followed by the prediction head.

      :type: torch.nn.Sequential

   .. attribute:: num_in_channels

      The number of input channels.

      :type: int

   .. attribute:: input_shape

      The shape of the input tensor.

      :type: Coordinate

   .. attribute:: eval_input_shape

      The shape of the input tensor during evaluation.

      :type: Coordinate

   .. attribute:: num_out_channels

      The number of output channels.

      :type: int

   .. attribute:: output_shape

      The shape of the output

      :type: Coordinate

   .. attribute:: eval_activation

      The activation function to apply during evaluation.

      :type: torch.nn.Module | None

   .. method:: forward(x

      torch.Tensor) -> torch.Tensor:
      Forward pass of the model.

   .. method:: compute_output_shape(input_shape

      Coordinate) -> Tuple[int, Coordinate]:
      Compute the spatial shape of this model, when fed a tensor of the given spatial shape as input.

   .. method:: scale(voxel_size

      Coordinate) -> Coordinate:
      Scale the model by the given voxel size.

   .. note:: The output shape is the spatial shape of the model, i.e., not accounting for channels and batch dimensions.


   .. py:attribute:: num_out_channels
      :type:  int


   .. py:attribute:: num_in_channels
      :type:  int


   .. py:method:: forward(x)

      Forward pass of the model.

      :param x: The input tensor.
      :type x: torch.Tensor

      :returns: The output tensor.
      :rtype: torch.Tensor

      .. rubric:: Examples

      >>> model = Model(architecture, prediction_head)
      >>> model.forward(x)
      torch.Tensor

      .. note:: The eval_activation is only applied during evaluation. This is particularly useful if you want to train with something like BCELossWithLogits, since you want to avoid applying softmax while training, but apply it during evaluation.



   .. py:method:: compute_output_shape(input_shape: funlib.geometry.Coordinate) -> Tuple[int, funlib.geometry.Coordinate]

      Compute the spatial shape (i.e., not accounting for channels and
      batch dimensions) of this model, when fed a tensor of the given spatial
      shape as input.

      :param input_shape: The shape of the input tensor.
      :type input_shape: Coordinate

      :returns: The number of output channels and the spatial shape of the output.
      :rtype: Tuple[int, Coordinate]

      :raises AssertionError: If the input_shape is not a Coordinate.

      .. rubric:: Examples

      >>> model = Model(architecture, prediction_head)
      >>> model.compute_output_shape(input_shape)
      (1, Coordinate(1, 1, 1))

      .. note:: The output shape is the spatial shape of the model, i.e., not accounting for channels and batch dimensions.



   .. py:method:: scale(voxel_size: funlib.geometry.Coordinate) -> funlib.geometry.Coordinate

      Scale the model by the given voxel size.

      :param voxel_size: The voxel size to scale the model by.
      :type voxel_size: Coordinate

      :returns: The scaled model.
      :rtype: Coordinate

      :raises AssertionError: If the voxel_size is not a Coordinate.

      .. rubric:: Examples

      >>> model = Model(architecture, prediction_head)
      >>> model.scale(voxel_size)
      Coordinate(1, 1, 1)

      .. note:: The output shape is the spatial shape of the model, i.e., not accounting for channels and batch dimensions.



