dacapo.plot
===========

.. py:module:: dacapo.plot


Attributes
----------

.. autoapisummary::

   dacapo.plot.RunInfo


Classes
-------

.. autoapisummary::

   dacapo.plot.Run


Functions
---------

.. autoapisummary::

   dacapo.plot.create_config_store
   dacapo.plot.create_stats_store
   dacapo.plot.smooth_values
   dacapo.plot.get_runs_info
   dacapo.plot.plot_runs


Module Contents
---------------

.. py:function:: create_config_store()

   Create a config store based on the global DaCapo options.

   :returns: The created config store.
   :rtype: ConfigStore

   :raises ValueError: If the store type is not supported.

   .. rubric:: Examples

   >>> create_config_store()
   <dacapo.store.file_config_store.FileConfigStore object at 0x7f2e4f8e9e80>

   .. note:: Currently, only the FileConfigStore and MongoConfigStore are supported.


.. py:function:: create_stats_store()

   Create a statistics store based on the global DaCapo options.

   :param options: The global DaCapo options.
   :type options: Options

   :returns: The created statistics store.
   :rtype: StatsStore

   :raises ValueError: If the store type is not supported.

   .. rubric:: Examples

   >>> create_stats_store()
   <dacapo.store.file_stats_store.FileStatsStore object at 0x7f2e4f8e9e80>

   .. note:: Currently, only the FileStatsStore and MongoStatsStore are supported.


.. py:class:: Run(run_config, load_starter_model: bool = True)

   Class representing a run in the experiment. A run is a combination of a task, architecture, trainer, datasplit,
   model, optimizer, training stats, and validation scores. It also contains the name of the run, the number of
   iterations to train for, and the interval at which to validate. It also contains a start object that can be used to
   initialize the model with preloaded weights. The run object can be used to move the optimizer to a specified device.

   .. attribute:: name

      The name of the run.

      :type: str

   .. attribute:: train_until

      The number of iterations to train for.

      :type: int

   .. attribute:: validation_interval

      The interval at which to validate.

      :type: int

   .. attribute:: task

      The task object.

      :type: Task

   .. attribute:: architecture

      The architecture object.

      :type: Architecture

   .. attribute:: trainer

      The trainer object.

      :type: Trainer

   .. attribute:: datasplit

      The datasplit object.

      :type: DataSplit

   .. attribute:: model

      The model object.

      :type: Model

   .. attribute:: optimizer

      The optimizer object.

      :type: torch.optim.Optimizer

   .. attribute:: training_stats

      The training stats object.

      :type: TrainingStats

   .. attribute:: validation_scores

      The validation scores object.

      :type: ValidationScores

   .. attribute:: start

      The start object.

      :type: Start

   .. method:: move_optimizer(device

      torch.device, empty_cuda_cache: bool) -> None:
      Moves the optimizer to the specified device.

   .. method:: get_validation_scores(run_config) -> ValidationScores

      
      Static method to get the validation scores without initializing model, optimizer, trainer, etc.

   .. note::

      The iteration stats list is structured as follows:
      - The outer list contains the stats for each iteration.
      - The inner list contains the stats for each training iteration.


   .. py:attribute:: name
      :type:  str


   .. py:attribute:: train_until
      :type:  int


   .. py:attribute:: validation_interval
      :type:  int


   .. py:attribute:: task
      :type:  dacapo.experiments.tasks.task.Task


   .. py:attribute:: architecture
      :type:  dacapo.experiments.architectures.Architecture


   .. py:attribute:: trainer
      :type:  dacapo.experiments.trainers.Trainer


   .. py:attribute:: model
      :type:  dacapo.experiments.model.Model


   .. py:attribute:: optimizer
      :type:  torch.optim.Optimizer


   .. py:attribute:: training_stats
      :type:  dacapo.experiments.training_stats.TrainingStats


   .. py:property:: datasplit


   .. py:property:: validation_scores


   .. py:method:: get_validation_scores(run_config) -> dacapo.experiments.validation_scores.ValidationScores
      :staticmethod:


      Static method to get the validation scores without initializing model, optimizer, trainer, etc.

      :param run_config: The configuration for the run.

      :returns: The validation scores.

      :raises AssertionError: If the task or datasplit types are not specified in the run_config.

      .. rubric:: Examples

      >>> validation_scores = Run.get_validation_scores(run_config)
      >>> validation_scores
      ValidationScores object



   .. py:method:: move_optimizer(device: torch.device, empty_cuda_cache: bool = False) -> None

      Moves the optimizer to the specified device.

      :param device: The device to move the optimizer to.
      :param empty_cuda_cache: Whether to empty the CUDA cache after moving the optimizer.

      :raises AssertionError: If the optimizer state is not a dictionary.

      .. rubric:: Examples

      >>> run.move_optimizer(device)
      >>> run.optimizer
      Optimizer object



.. py:data:: RunInfo

.. py:function:: smooth_values(a, n, stride=1)

   Smooth values with a moving average.

   :param a: values to smooth
   :param n: number of values to average
   :param stride: stride of the smoothing

   :returns: smoothed values
             s: standard deviation of the smoothed values
   :rtype: m

   :raises ValueError: If run_name is not found in config store

   .. rubric:: Examples

   >>> smooth_values([1,2,3,4,5], 3)


.. py:function:: get_runs_info(run_config_names: List[str], validation_score_names: List[str], plot_losses: List[bool]) -> List[RunInfo]

.. py:function:: plot_runs(run_config_base_names, smooth=100, validation_scores=None, higher_is_betters=None, plot_losses=None, return_json=False)

   Plot runs.
   :param run_config_base_names: Names of run configs to plot
   :param smooth: Smoothing factor
   :param validation_scores: Validation scores to plot
   :param higher_is_betters: Whether higher is better
   :param plot_losses: Whether to plot losses
   :param return_json: Whether to return JSON

   :returns: JSON or HTML plot

   :raises ValueError: If run_name is not found in config store

   .. rubric:: Examples

   >>> plot_runs(["run_name"], 100, None, None, [True])


