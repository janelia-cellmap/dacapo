dacapo.store.conversion_hooks
=============================

.. py:module:: dacapo.store.conversion_hooks


Classes
-------

.. autoapisummary::

   dacapo.store.conversion_hooks.Architecture
   dacapo.store.conversion_hooks.ArchitectureConfig
   dacapo.store.conversion_hooks.DummyArchitectureConfig
   dacapo.store.conversion_hooks.DummyArchitecture
   dacapo.store.conversion_hooks.CNNectomeUNetConfig
   dacapo.store.conversion_hooks.CNNectomeUNet
   dacapo.store.conversion_hooks.DataSplit
   dacapo.store.conversion_hooks.DataSplitConfig
   dacapo.store.conversion_hooks.DummyDataSplit
   dacapo.store.conversion_hooks.DummyDataSplitConfig
   dacapo.store.conversion_hooks.TrainValidateDataSplit
   dacapo.store.conversion_hooks.TrainValidateDataSplitConfig
   dacapo.store.conversion_hooks.DataSplitGenerator
   dacapo.store.conversion_hooks.Dataset
   dacapo.store.conversion_hooks.DatasetConfig
   dacapo.store.conversion_hooks.DummyDataset
   dacapo.store.conversion_hooks.DummyDatasetConfig
   dacapo.store.conversion_hooks.RawGTDataset
   dacapo.store.conversion_hooks.RawGTDatasetConfig
   dacapo.store.conversion_hooks.Array
   dacapo.store.conversion_hooks.ArrayConfig
   dacapo.store.conversion_hooks.DummyArray
   dacapo.store.conversion_hooks.DummyArrayConfig
   dacapo.store.conversion_hooks.ZarrArray
   dacapo.store.conversion_hooks.ZarrArrayConfig
   dacapo.store.conversion_hooks.BinarizeArray
   dacapo.store.conversion_hooks.BinarizeArrayConfig
   dacapo.store.conversion_hooks.ResampledArray
   dacapo.store.conversion_hooks.ResampledArrayConfig
   dacapo.store.conversion_hooks.IntensitiesArray
   dacapo.store.conversion_hooks.IntensitiesArrayConfig
   dacapo.store.conversion_hooks.MissingAnnotationsMask
   dacapo.store.conversion_hooks.MissingAnnotationsMaskConfig
   dacapo.store.conversion_hooks.OnesArray
   dacapo.store.conversion_hooks.OnesArrayConfig
   dacapo.store.conversion_hooks.ConcatArray
   dacapo.store.conversion_hooks.ConcatArrayConfig
   dacapo.store.conversion_hooks.LogicalOrArray
   dacapo.store.conversion_hooks.LogicalOrArrayConfig
   dacapo.store.conversion_hooks.CropArray
   dacapo.store.conversion_hooks.CropArrayConfig
   dacapo.store.conversion_hooks.MergeInstancesArray
   dacapo.store.conversion_hooks.MergeInstancesArrayConfig
   dacapo.store.conversion_hooks.DVIDArray
   dacapo.store.conversion_hooks.DVIDArrayConfig
   dacapo.store.conversion_hooks.SumArray
   dacapo.store.conversion_hooks.SumArrayConfig
   dacapo.store.conversion_hooks.NumpyArray
   dacapo.store.conversion_hooks.GraphStoreConfig
   dacapo.store.conversion_hooks.Task
   dacapo.store.conversion_hooks.TaskConfig
   dacapo.store.conversion_hooks.DummyTaskConfig
   dacapo.store.conversion_hooks.DummyTask
   dacapo.store.conversion_hooks.DistanceTaskConfig
   dacapo.store.conversion_hooks.DistanceTask
   dacapo.store.conversion_hooks.OneHotTaskConfig
   dacapo.store.conversion_hooks.OneHotTask
   dacapo.store.conversion_hooks.PretrainedTaskConfig
   dacapo.store.conversion_hooks.PretrainedTask
   dacapo.store.conversion_hooks.AffinitiesTaskConfig
   dacapo.store.conversion_hooks.AffinitiesTask
   dacapo.store.conversion_hooks.InnerDistanceTaskConfig
   dacapo.store.conversion_hooks.InnerDistanceTask
   dacapo.store.conversion_hooks.HotDistanceTaskConfig
   dacapo.store.conversion_hooks.HotDistanceTask
   dacapo.store.conversion_hooks.DummyEvaluationScores
   dacapo.store.conversion_hooks.DummyEvaluator
   dacapo.store.conversion_hooks.EvaluationScores
   dacapo.store.conversion_hooks.Evaluator
   dacapo.store.conversion_hooks.MultiChannelBinarySegmentationEvaluationScores
   dacapo.store.conversion_hooks.BinarySegmentationEvaluationScores
   dacapo.store.conversion_hooks.BinarySegmentationEvaluator
   dacapo.store.conversion_hooks.InstanceEvaluationScores
   dacapo.store.conversion_hooks.InstanceEvaluator
   dacapo.store.conversion_hooks.DummyPostProcessor
   dacapo.store.conversion_hooks.DummyPostProcessorParameters
   dacapo.store.conversion_hooks.PostProcessorParameters
   dacapo.store.conversion_hooks.PostProcessor
   dacapo.store.conversion_hooks.ThresholdPostProcessor
   dacapo.store.conversion_hooks.ThresholdPostProcessorParameters
   dacapo.store.conversion_hooks.ArgmaxPostProcessor
   dacapo.store.conversion_hooks.ArgmaxPostProcessorParameters
   dacapo.store.conversion_hooks.WatershedPostProcessor
   dacapo.store.conversion_hooks.WatershedPostProcessorParameters
   dacapo.store.conversion_hooks.Trainer
   dacapo.store.conversion_hooks.TrainerConfig
   dacapo.store.conversion_hooks.DummyTrainerConfig
   dacapo.store.conversion_hooks.DummyTrainer
   dacapo.store.conversion_hooks.GunpowderTrainerConfig
   dacapo.store.conversion_hooks.GunpowderTrainer
   dacapo.store.conversion_hooks.AugmentConfig
   dacapo.store.conversion_hooks.AugmentConfig
   dacapo.store.conversion_hooks.ElasticAugmentConfig
   dacapo.store.conversion_hooks.SimpleAugmentConfig
   dacapo.store.conversion_hooks.GammaAugmentConfig
   dacapo.store.conversion_hooks.IntensityAugmentConfig
   dacapo.store.conversion_hooks.IntensityScaleShiftAugmentConfig
   dacapo.store.conversion_hooks.Start
   dacapo.store.conversion_hooks.StartConfig
   dacapo.store.conversion_hooks.CosemStart
   dacapo.store.conversion_hooks.CosemStartConfig


Functions
---------

.. autoapisummary::

   dacapo.store.conversion_hooks.register_hierarchy_hooks
   dacapo.store.conversion_hooks.register_hooks
   dacapo.store.conversion_hooks.cls_fun


Module Contents
---------------

.. py:class:: Architecture(*args, **kwargs)



   An abstract base class for defining the architecture of a neural network model.
   It is inherited from PyTorch's Module and built-in class `ABC` (Abstract Base Classes).
   Other classes can inherit this class to define their own specific variations of architecture.
   It requires to implement several property methods, and also includes additional methods related to the architecture design.

   .. attribute:: input_shape

      The spatial input shape for the neural network architecture.

      :type: Coordinate

   .. attribute:: eval_shape_increase

      The amount to increase the input shape during prediction.

      :type: Coordinate

   .. attribute:: num_in_channels

      The number of input channels required by the architecture.

      :type: int

   .. attribute:: num_out_channels

      The number of output channels provided by the architecture.

      :type: int

   .. method:: dims

      Returns the number of dimensions of the input shape.

   .. method:: scale

      Scales the input voxel size as required by the architecture.

   .. note:: The class is abstract and requires to implement the abstract methods.


   .. py:property:: input_shape
      :type: funlib.geometry.Coordinate

      :abstractmethod:

      Abstract method to define the spatial input shape for the neural network architecture.
      The shape should not account for the channels and batch dimensions.

      :returns: The spatial input shape.
      :rtype: Coordinate

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> input_shape = Coordinate((128, 128, 128))
      >>> model = MyModel(input_shape)

      .. note:: The method should be implemented in the derived class.


   .. py:property:: eval_shape_increase
      :type: funlib.geometry.Coordinate

      Provides information about how much to increase the input shape during prediction.

      :returns: An instance representing the amount to increase in each dimension of the input shape.
      :rtype: Coordinate

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> eval_shape_increase = Coordinate((0, 0, 0))
      >>> model = MyModel(input_shape, eval_shape_increase)

      .. note:: The method is optional and can be overridden in the derived class.


   .. py:property:: num_in_channels
      :type: int

      :abstractmethod:

      Abstract method to return number of input channels required by the architecture.

      :returns: Required number of input channels.
      :rtype: int

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> num_in_channels = 1
      >>> model = MyModel(input_shape, num_in_channels)

      .. note:: The method should be implemented in the derived class.


   .. py:property:: num_out_channels
      :type: int

      :abstractmethod:

      Abstract method to return the number of output channels provided by the architecture.

      :returns: Number of output channels.
      :rtype: int

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> num_out_channels = 1
      >>> model = MyModel(input_shape, num_out_channels)

      .. note:: The method should be implemented in the derived class.


   .. py:property:: dims
      :type: int

      Returns the number of dimensions of the input shape.

      :returns: The number of dimensions.
      :rtype: int

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> input_shape = Coordinate((128, 128, 128))
      >>> model = MyModel(input_shape)
      >>> model.dims
      3

      .. note:: The method is optional and can be overridden in the derived class.


   .. py:method:: scale(input_voxel_size: funlib.geometry.Coordinate) -> funlib.geometry.Coordinate

      Method to scale the input voxel size as required by the architecture.

      :param input_voxel_size: The original size of the input voxel.
      :type input_voxel_size: Coordinate

      :returns: The scaled voxel size.
      :rtype: Coordinate

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> input_voxel_size = Coordinate((1, 1, 1))
      >>> model = MyModel(input_shape)
      >>> model.scale(input_voxel_size)
      Coordinate((1, 1, 1))

      .. note:: The method is optional and can be overridden in the derived class.



.. py:class:: ArchitectureConfig

   A class to represent the base configurations of any architecture. It is used to define the architecture of a neural network model.

   .. attribute:: name

      str
      a unique name for the architecture.

   .. method:: verify()

      
      validates the given architecture.

   .. note:: The class is abstract and requires to implement the abstract methods.


   .. py:attribute:: name
      :type:  str


   .. py:method:: verify() -> Tuple[bool, str]

      A method to validate an architecture configuration.

      :returns: A tuple of a boolean indicating if the architecture is valid and a message.
      :rtype: Tuple[bool, str]

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> config = ArchitectureConfig("MyModel")
      >>> is_valid, message = config.verify()
      >>> print(is_valid, message)

      .. note:: The method should be implemented in the derived class.



.. py:class:: DummyArchitectureConfig



   A dummy architecture configuration class used for testing purposes.

   It extends the base class "ArchitectureConfig". This class contains dummy attributes and always
   returns that the configuration is invalid when verified.

   .. attribute:: architecture_type

      A class attribute assigning
      the DummyArchitecture class to this configuration.

      :type: :obj:`DummyArchitecture`

   .. attribute:: num_in_channels

      The number of input channels. This is a dummy attribute and has no real
      functionality or meaning.

      :type: int

   .. attribute:: num_out_channels

      The number of output channels. This is also a dummy attribute and
      has no real functionality or meaning.

      :type: int

   .. method:: verify(self) -> Tuple[bool, str]

      This method is used to check whether this is a valid architecture configuration.

   .. note:: This class is used to represent a DummyArchitectureConfig object in the system.


   .. py:attribute:: architecture_type


   .. py:attribute:: num_in_channels
      :type:  int


   .. py:attribute:: num_out_channels
      :type:  int


   .. py:method:: verify() -> Tuple[bool, str]

      Verifies the configuration validity.

      Since this is a dummy configuration for testing purposes, this method always returns False
      indicating that the configuration is invalid.

      :returns: A tuple containing a boolean validity flag and a reason message string.
      :rtype: tuple

      :raises NotImplementedError: This method is not implemented in this class.

      .. rubric:: Examples

      >>> dummy_architecture_config = DummyArchitectureConfig(num_in_channels=1, num_out_channels=1)
      >>> dummy_architecture_config.verify()
      (False, "This is a DummyArchitectureConfig and is never valid")

      .. note:: This method is used to check whether this is a valid architecture configuration.



.. py:class:: DummyArchitecture(architecture_config)



   A class used to represent a dummy architecture layer for a 3D CNN.

   .. attribute:: channels_in

      An integer representing the number of input channels.

   .. attribute:: channels_out

      An integer representing the number of output channels.

   .. attribute:: conv

      A 3D convolution object.

   .. attribute:: input_shape

      A coordinate object representing the shape of the input.

   .. method:: forward(x)

      Performs the forward pass of the network.

   .. method:: num_in_channels()

      Returns the number of input channels for this architecture.

   .. method:: num_out_channels()

      Returns the number of output channels for this architecture.

   .. note:: This class is used to represent a dummy architecture layer for a 3D CNN.


   .. py:property:: input_shape
      Returns the input shape for this architecture.

      :returns: Input shape of the architecture.
      :rtype: Coordinate

      :raises NotImplementedError: This method is not implemented in this class.

      .. rubric:: Examples

      >>> dummy_architecture.input_shape
      Coordinate(x=40, y=20, z=20)

      .. note:: This method is used to return the input shape for this architecture.


   .. py:property:: num_in_channels
      Returns the number of input channels for this architecture.

      :returns: Number of input channels.
      :rtype: int

      :raises NotImplementedError: This method is not implemented in this class.

      .. rubric:: Examples

      >>> dummy_architecture.num_in_channels
      1

      .. note:: This method is used to return the number of input channels for this architecture.


   .. py:property:: num_out_channels
      Returns the number of output channels for this architecture.

      :returns: Number of output channels.
      :rtype: int

      :raises NotImplementedError: This method is not implemented in this class.

      .. rubric:: Examples

      >>> dummy_architecture.num_out_channels
      1

      .. note:: This method is used to return the number of output channels for this architecture.


   .. py:method:: forward(x)

      Perform the forward pass of the network.

      :param x: Input tensor.

      :returns: Output tensor after the forward pass.
      :rtype: Tensor

      :raises NotImplementedError: This method is not implemented in this class.

      .. rubric:: Examples

      >>> dummy_architecture = DummyArchitecture(architecture_config)
      >>> x = torch.randn(1, 1, 40, 20, 20)
      >>> dummy_architecture.forward(x)

      .. note:: This method is used to perform the forward pass of the network.



.. py:class:: CNNectomeUNetConfig



   This class configures the CNNectomeUNet based on
   https://github.com/saalfeldlab/CNNectome/blob/master/CNNectome/networks/unet_class.py

   Includes support for super resolution via the upsampling factors.

   .. attribute:: input_shape

      Coordinate
      The shape of the data passed into the network during training.

   .. attribute:: fmaps_out

      int
      The number of channels produced by your architecture.

   .. attribute:: fmaps_in

      int
      The number of channels expected from the raw data.

   .. attribute:: num_fmaps

      int
      The number of feature maps in the top level of the UNet.

   .. attribute:: fmap_inc_factor

      int
      The multiplication factor for the number of feature maps for each level of the UNet.

   .. attribute:: downsample_factors

      List[Coordinate]
      The factors to downsample the feature maps along each axis per layer.

   .. attribute:: kernel_size_down

      Optional[List[Coordinate]]
      The size of the convolutional kernels used before downsampling in each layer.

   .. attribute:: kernel_size_up

      Optional[List[Coordinate]]
      The size of the convolutional kernels used before upsampling in each layer.

   .. attribute:: _eval_shape_increase

      Optional[Coordinate]
      The amount by which to increase the input size when just prediction rather than training.
      It is generally possible to significantly increase the input size since we don't have the memory
      constraints of the gradients, the optimizer and the batch size.

   .. attribute:: upsample_factors

      Optional[List[Coordinate]]
      The amount by which to upsample the output of the UNet.

   .. attribute:: constant_upsample

      bool
      Whether to use a transpose convolution or simply copy voxels to upsample.

   .. attribute:: padding

      str
      The padding to use in convolution operations.

   .. attribute:: use_attention

      bool
      Whether to use attention blocks in the UNet. This is supported for 2D and  3D.

   .. method:: architecture_type()

      
      Returns the architecture type.

   .. note:: The architecture_type attribute is set to CNNectomeUNet.

   .. rubric:: References

   Saalfeld, S., Fetter, R., Cardona, A., & Tomancak, P. (2012).


   .. py:attribute:: architecture_type


   .. py:attribute:: input_shape
      :type:  funlib.geometry.Coordinate


   .. py:attribute:: fmaps_out
      :type:  int


   .. py:attribute:: fmaps_in
      :type:  int


   .. py:attribute:: num_fmaps
      :type:  int


   .. py:attribute:: fmap_inc_factor
      :type:  int


   .. py:attribute:: downsample_factors
      :type:  List[funlib.geometry.Coordinate]


   .. py:attribute:: kernel_size_down
      :type:  Optional[List[List[funlib.geometry.Coordinate]]]


   .. py:attribute:: kernel_size_up
      :type:  Optional[List[List[funlib.geometry.Coordinate]]]


   .. py:attribute:: upsample_factors
      :type:  Optional[List[funlib.geometry.Coordinate]]


   .. py:attribute:: constant_upsample
      :type:  bool


   .. py:attribute:: padding
      :type:  str


   .. py:attribute:: use_attention
      :type:  bool


.. py:class:: CNNectomeUNet(architecture_config)



   A U-Net architecture for 3D or 4D data. The U-Net expects 3D or 4D tensors
   shaped like::

       ``(batch=1, channels, [length,] depth, height, width)``.

   This U-Net performs only "valid" convolutions, i.e., sizes of the feature
   maps decrease after each convolution. It will perfrom 4D convolutions as
   long as ``length`` is greater than 1. As soon as ``length`` is 1 due to a
   valid convolution, the time dimension will be dropped and tensors with
   ``(b, c, z, y, x)`` will be use (and returned) from there on.

   .. attribute:: fmaps_in

      The number of input channels.

   .. attribute:: fmaps_out

      The number of feature maps in the output layer. This is also the
      number of output feature maps. Stored in the ``channels`` dimension.

   .. attribute:: num_fmaps

      The number of feature maps in the first layer. This is also the
      number of output feature maps. Stored in the ``channels`` dimension.

   .. attribute:: fmap_inc_factor

      By how much to multiply the number of feature maps between layers.
      If layer 0 has ``k`` feature maps, layer ``l`` will have
      ``k*fmap_inc_factor**l``.

   .. attribute:: downsample_factors

      List of tuples ``(z, y, x)`` to use to down- and up-sample the
      feature maps between layers.

   .. attribute:: kernel_size_down

      List of lists of kernel sizes. The number of sizes in a list
      determines the number of convolutional layers in the corresponding
      level of the build on the left side. Kernel sizes can be given as
      tuples or integer. If not given, each convolutional pass will
      consist of two 3x3x3 convolutions.

      :type: optional

   .. attribute:: kernel_size_up

      List of lists of kernel sizes. The number of sizes in a list
      determines the number of convolutional layers in the corresponding
      level of the build on the right side. Within one of the lists going
      from left to right. Kernel sizes can be given as tuples or integer.
      If not given, each convolutional pass will consist of two 3x3x3
      convolutions.

      :type: optional

   .. attribute:: activation

      Which activation to use after a convolution. Accepts the name of
      any tensorflow activation function (e.g., ``ReLU`` for
      ``torch.nn.ReLU``).

   .. attribute:: fov

      Initial field of view in physical units

      :type: optional

   .. attribute:: voxel_size

      Size of a voxel in the input data, in physical units

      :type: optional

   .. attribute:: num_heads

      Number of decoders. The resulting U-Net has one single encoder
      path and num_heads decoder paths. This is useful in a multi-task
      learning context.

      :type: optional

   .. attribute:: constant_upsample

      If set to true, perform a constant upsampling instead of a
      transposed convolution in the upsampling layers.

      :type: optional

   .. attribute:: padding

      How to pad convolutions. Either 'same' or 'valid' (default).

      :type: optional

   .. attribute:: upsample_channel_contraction

      When performing the ConvTranspose, whether to reduce the number
      of channels by the fmap_increment_factor. can be either bool or
      list of bools to apply independently per layer.

   .. attribute:: activation_on_upsample

      Whether or not to add an activation after the upsample operation.

   .. attribute:: use_attention

      Whether or not to use an attention block in the U-Net.

       Methods:
           forward(x):
               Forward pass of the U-Net.
           scale(voxel_size):
               Scale the voxel size according to the upsampling factors.
           input_shape:
               Return the input shape of the U-Net.
           num_in_channels:
               Return the number of input channels.
           num_out_channels:
               Return the number of output channels.
           eval_shape_increase:
               Return the increase in shape due to the U-Net.
       Note:
           This class is a wrapper around the ``CNNectomeUNetModule`` class.
           The ``CNNectomeUNetModule`` class is the actual implementation of the
           U-Net architecture.


   .. py:property:: eval_shape_increase
      The increase in shape due to the U-Net.

      :returns: The increase in shape due to the U-Net.

      :raises AttributeError: If the increase in shape is not given.

      .. rubric:: Examples

      >>> unet.eval_shape_increase
      (1, 1, 128, 128, 128)

      .. note:: The increase in shape should be given as a tuple ``(batch, channels, [length,] depth, height, width)``.


   .. py:method:: module()

      Create the U-Net module.

      :returns: The U-Net module.

      :raises AttributeError: If the number of input channels is not given.
      :raises AttributeError: If the number of output channels is not given.
      :raises AttributeError: If the number of feature maps in the first layer is not given.
      :raises AttributeError: If the factor by which the number of feature maps increases between layers is not given.
      :raises AttributeError: If the downsample factors are not given.
      :raises AttributeError: If the kernel sizes for the down pass are not given.
      :raises AttributeError: If the kernel sizes for the up pass are not given.
      :raises AttributeError: If the constant upsample flag is not given.
      :raises AttributeError: If the padding is not given.
      :raises AttributeError: If the upsample factors are not given.
      :raises AttributeError: If the activation on upsample flag is not given.
      :raises AttributeError: If the use attention flag is not given.

      .. rubric:: Examples

      >>> unet.module()
      CNNectomeUNetModule(
          in_channels=1,
          num_fmaps=24,
          num_fmaps_out=1,
          fmap_inc_factor=2,
          kernel_size_down=[[(3, 3, 3), (3, 3, 3)], [(3, 3, 3), (3, 3, 3)], [(3, 3, 3), (3, 3, 3)]],
          kernel_size_up=[[(3, 3, 3), (3, 3, 3)], [(3, 3, 3), (3, 3, 3)], [(3, 3, 3), (3, 3, 3)]],
          downsample_factors=[(2, 2, 2), (2, 2, 2), (2, 2, 2)],
          constant_upsample=False,
          padding='valid',
          activation_on_upsample=True,
          upsample_channel_contraction=[False, True, True],
          use_attention=False
      )

      .. note:: The U-Net module is an instance of the ``CNNectomeUNetModule`` class.



   .. py:method:: scale(voxel_size)

      Scale the voxel size according to the upsampling factors.

      :param voxel_size: The size of a voxel in the input data.
      :type voxel_size: tuple

      :returns: The scaled voxel size.

      :raises ValueError: If the voxel size is not given.

      .. rubric:: Examples

      >>> unet.scale((1, 1, 1))
      (1, 1, 1)

      .. note:: The voxel size should be given as a tuple ``(z, y, x)``.



   .. py:property:: input_shape
      Return the input shape of the U-Net.

      :returns: The input shape of the U-Net.

      :raises AttributeError: If the input shape is not given.

      .. rubric:: Examples

      >>> unet.input_shape
      (1, 1, 128, 128, 128)

      .. note:: The input shape should be given as a tuple ``(batch, channels, [length,] depth, height, width)``.


   .. py:property:: num_in_channels
      :type: int

      Return the number of input channels.

      :returns: The number of input channels.

      :raises AttributeError: If the number of input channels is not given.

      .. rubric:: Examples

      >>> unet.num_in_channels
      1

      .. note:: The number of input channels should be given as an integer.


   .. py:property:: num_out_channels
      :type: int

      Return the number of output channels.

      :returns: The number of output channels.

      :raises AttributeError: If the number of output channels is not given.

      .. rubric:: Examples

      >>> unet.num_out_channels
      1

      .. note:: The number of output channels should be given as an integer.


   .. py:method:: forward(x)

      Forward pass of the U-Net.

      :param x: The input tensor.
      :type x: Tensor

      :returns: The output tensor.

      :raises RuntimeError: If the tensors have different dimensions.

      .. rubric:: Examples

      >>> unet = CNNectomeUNet(architecture_config)
      >>> x = torch.randn(1, 1, 64, 64, 64)
      >>> unet(x)

      .. note:: The input tensor should be given as a 5D tensor.



.. py:class:: DataSplit



   A class for creating a simple train dataset and no validation dataset. It is derived from `DataSplit` class.
   It is used to split the data into training and validation datasets. The training and validation datasets are
   used to train and validate the model respectively.

   .. attribute:: train

      list
      The list containing training datasets. In this class, it contains only one dataset for training.

   .. attribute:: validate

      list
      The list containing validation datasets. In this class, it is an empty list as no validation dataset is set.

   .. method:: __init__(self, datasplit_config)

      
      The constructor for DummyDataSplit class. It initialises a list with training datasets according to the input configuration.

   .. rubric:: Notes

   This class is used to split the data into training and validation datasets.


   .. py:attribute:: train
      :type:  List[dacapo.experiments.datasplits.datasets.Dataset]


   .. py:attribute:: validate
      :type:  Optional[List[dacapo.experiments.datasplits.datasets.Dataset]]


.. py:class:: DataSplitConfig

   A class used to create a DataSplit configuration object.

   .. attribute:: name

      str
      A name for the datasplit. This name will be saved so it can be found
      and reused easily. It is recommended to keep it short and avoid special
      characters.

   .. method:: verify() -> Tuple[bool, str]

      
      Validates if it is a valid data split configuration.

   .. rubric:: Notes

   This class is used to create a DataSplit configuration object.


   .. py:attribute:: name
      :type:  str


   .. py:method:: verify() -> Tuple[bool, str]

      Validates if the current configuration is a valid data split configuration.

      :returns:

                Tuple[bool, str]
                    True if the configuration is valid,
                    False otherwise along with respective validation error message.

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> datasplit_config = DataSplitConfig(name="datasplit")
      >>> datasplit_config.verify()
      (True, "No validation for this DataSplit")

      .. rubric:: Notes

      This method is used to validate the configuration of DataSplit.



.. py:class:: DummyDataSplit(datasplit_config)



   A class for creating a simple train dataset and no validation dataset. It is derived from `DataSplit` class.
   It is used to split the data into training and validation datasets. The training and validation datasets are
   used to train and validate the model respectively.

   .. attribute:: train

      list
      The list containing training datasets. In this class, it contains only one dataset for training.

   .. attribute:: validate

      list
      The list containing validation datasets. In this class, it is an empty list as no validation dataset is set.

   .. method:: __init__(self, datasplit_config)

      
      The constructor for DummyDataSplit class. It initialises a list with training datasets according to the input configuration.

   .. rubric:: Notes

   This class is used to split the data into training and validation datasets.


   .. py:attribute:: train
      :type:  List[dacapo.experiments.datasplits.datasets.Dataset]


   .. py:attribute:: validate
      :type:  List[dacapo.experiments.datasplits.datasets.Dataset]


.. py:class:: DummyDataSplitConfig



   A simple class representing config for Dummy DataSplit.

   This class is derived from 'DataSplitConfig' and is initialized with
   'DatasetConfig' for training dataset.

   .. attribute:: datasplit_type

      Class of dummy data split functionality.

   .. attribute:: train_config

      Config for the training dataset. Defaults to DummyDatasetConfig.

   .. method:: verify()

      
      A method for verification. This method always return 'False' plus
      a string indicating the condition.

   .. rubric:: Notes

   This class is used to represent the configuration for Dummy DataSplit.


   .. py:attribute:: datasplit_type


   .. py:attribute:: train_config
      :type:  dacapo.experiments.datasplits.datasets.DatasetConfig


   .. py:method:: verify() -> Tuple[bool, str]

      A method for verification. This method always return 'False' plus
      a string indicating the condition.

      :returns: A tuple contains a boolean 'False' and a string.
      :rtype: Tuple[bool, str]

      .. rubric:: Examples

      >>> dummy_datasplit_config = DummyDataSplitConfig(train_config)
      >>> dummy_datasplit_config.verify()
      (False, "This is a DummyDataSplit and is never valid")

      .. rubric:: Notes

      This method is used to verify the configuration of DummyDataSplit.



.. py:class:: TrainValidateDataSplit(datasplit_config)



   A DataSplit that contains a list of training and validation datasets. This
   class is used to split the data into training and validation datasets. The
   training and validation datasets are used to train and validate the model
   respectively.

   .. attribute:: train

      list
      The list of training datasets.

   .. attribute:: validate

      list
      The list of validation datasets.

   .. method:: __init__(datasplit_config)

      
      Initializes the TrainValidateDataSplit class with specified config to
      split the data into training and validation datasets.

   .. rubric:: Notes

   This class is used to split the data into training and validation datasets.


   .. py:attribute:: train
      :type:  List[dacapo.experiments.datasplits.datasets.Dataset]


   .. py:attribute:: validate
      :type:  List[dacapo.experiments.datasplits.datasets.Dataset]


.. py:class:: TrainValidateDataSplitConfig



   This is the standard Train/Validate DataSplit config. It contains a list of
   training and validation datasets. This class is used to split the data into
   training and validation datasets. The training and validation datasets are
   used to train and validate the model respectively.

   .. attribute:: train_configs

      list
      The list of training datasets.

   .. attribute:: validate_configs

      list
      The list of validation datasets.

   .. method:: __init__(datasplit_config)

      
      Initializes the TrainValidateDataSplitConfig class with specified config to
      split the data into training and validation datasets.

   .. rubric:: Notes

   This class is used to split the data into training and validation datasets.


   .. py:attribute:: datasplit_type


   .. py:attribute:: train_configs
      :type:  List[dacapo.experiments.datasplits.datasets.DatasetConfig]


   .. py:attribute:: validate_configs
      :type:  List[dacapo.experiments.datasplits.datasets.DatasetConfig]


.. py:class:: DataSplitGenerator(name: str, datasets: List[DatasetSpec], input_resolution: Union[Sequence[int], funlib.geometry.Coordinate], output_resolution: Union[Sequence[int], funlib.geometry.Coordinate], targets: Optional[List[str]] = None, segmentation_type: Union[str, SegmentationType] = 'semantic', max_gt_downsample=32, max_gt_upsample=4, max_raw_training_downsample=16, max_raw_training_upsample=2, max_raw_validation_downsample=8, max_raw_validation_upsample=2, min_training_volume_size=8000, raw_min=0, raw_max=255, classes_separator_caracter='&')

   Generates DataSplitConfig for a given task config and datasets.

   Class names in gt_dataset should be within [] e.g. [mito&peroxisome&er] for
   multiple classes or [mito] for one class.

   Currently only supports:
    - semantic segmentation.
    Supports:
       - 2D and 3D datasets.
       - Zarr, N5 and OME-Zarr datasets.
       - Multi class targets.
       - Different resolutions for raw and ground truth datasets.
       - Different resolutions for training and validation datasets.

   .. attribute:: name

      str
      The name of the data split generator.

   .. attribute:: datasets

      list
      The list of dataset specifications.

   .. attribute:: input_resolution

      obj
      The input resolution.

   .. attribute:: output_resolution

      obj
      The output resolution.

   .. attribute:: targets

      list
      The list of targets.

   .. attribute:: segmentation_type

      obj
      The segmentation type.

   .. attribute:: max_gt_downsample

      int
      The maximum ground truth downsample.

   .. attribute:: max_gt_upsample

      int
      The maximum ground truth upsample.

   .. attribute:: max_raw_training_downsample

      int
      The maximum raw training downsample.

   .. attribute:: max_raw_training_upsample

      int
      The maximum raw training upsample.

   .. attribute:: max_raw_validation_downsample

      int
      The maximum raw validation downsample.

   .. attribute:: max_raw_validation_upsample

      int
      The maximum raw validation upsample.

   .. attribute:: min_training_volume_size

      int
      The minimum training volume size.

   .. attribute:: raw_min

      int
      The minimum raw value.

   .. attribute:: raw_max

      int
      The maximum raw value.

   .. attribute:: classes_separator_caracter

      str
      The classes separator character.

   .. method:: __init__(name, datasets, input_resolution, output_resolution, targets, segmentation_type, max_gt_downsample, max_gt_upsample, max_raw_training_downsample, max_raw_training_upsample, max_raw_validation_downsample, max_raw_validation_upsample, min_training_volume_size, raw_min, raw_max, classes_separator_caracter)

      
      Initializes the DataSplitGenerator class with the specified name, datasets, input resolution, output resolution, targets, segmentation type, maximum ground truth downsample, maximum ground truth upsample, maximum raw training downsample, maximum raw training upsample, maximum raw validation downsample, maximum raw validation upsample, minimum training volume size, minimum raw value, maximum raw value, and classes separator character.

   .. method:: __str__(self)

      
      A method to get the string representation of the class.

   .. method:: class_name(self)

      
      A method to get the class name.

   .. method:: check_class_name(self, class_name)

      
      A method to check the class name.

   .. method:: compute(self)

      
      A method to compute the data split.

   .. method:: __generate_semantic_seg_datasplit(self)

      
      A method to generate the semantic segmentation data split.

   .. method:: __generate_semantic_seg_dataset_crop(self, dataset)

      
      A method to generate the semantic segmentation dataset crop.

   .. method:: generate_csv(datasets, csv_path)

      
      A method to generate the CSV file.

   .. method:: generate_from_csv(csv_path, input_resolution, output_resolution, name, **kwargs)

      
      A method to generate the data split from the CSV file.

   .. rubric:: Notes

   - This class is used to generate the DataSplitConfig for a given task config and datasets.
   - Class names in gt_dataset shoulb be within [] e.g. [mito&peroxisome&er] for mutiple classes or [mito] for one class


   .. py:property:: class_name
      Get the class name.

      :param self: obj
                   The object.

      :returns: The class name.
      :rtype: obj

      :raises ValueError:
      :raises If the class name is already set, a ValueError is raised.:

      .. rubric:: Examples

      >>> class_name

      .. rubric:: Notes

      This function is used to get the class name.


   .. py:method:: check_class_name(class_name)

      Check the class name.

      :param self: obj
                   The object.
      :param class_name: obj
                         The class name.

      :returns: The class name.
      :rtype: obj

      :raises ValueError:
      :raises If the class name is already set, a ValueError is raised.:

      .. rubric:: Examples

      >>> check_class_name(class_name)

      .. rubric:: Notes

      This function is used to check the class name.



   .. py:method:: compute()

      Compute the data split.

      :param self: obj
                   The object.

      :returns: The data split.
      :rtype: obj

      :raises NotImplementedError:
      :raises If the segmentation type is not implemented, a NotImplementedError is raised.:

      .. rubric:: Examples

      >>> compute()

      .. rubric:: Notes

      This function is used to compute the data split.



   .. py:method:: generate_from_csv(csv_path: upath.UPath, input_resolution: Union[Sequence[int], funlib.geometry.Coordinate], output_resolution: Union[Sequence[int], funlib.geometry.Coordinate], name: Optional[str] = None, **kwargs)
      :staticmethod:


      Generate the data split from the CSV file.

      :param csv_path: obj
                       The CSV file path.
      :param input_resolution: obj
                               The input resolution.
      :param output_resolution: obj
                                The output resolution.
      :param name: str
                   The name.
      :param \*\*kwargs: dict
                         The keyword arguments.

      :returns: The data split.
      :rtype: obj

      :raises FileNotFoundError:
      :raises If the file does not exist, a FileNotFoundError is raised.:

      .. rubric:: Examples

      >>> generate_from_csv(csv_path, input_resolution, output_resolution, name, **kwargs)

      .. rubric:: Notes

      This function is used to generate the data split from the CSV file.



.. py:class:: Dataset



   A class to represent a dataset.

   .. attribute:: name

      The name of the dataset.

      :type: str

   .. attribute:: raw

      The raw dataset.

      :type: Array

   .. attribute:: gt

      The ground truth data.

      :type: Array, optional

   .. attribute:: mask

      The mask for the data.

      :type: Array, optional

   .. attribute:: weight

      The weight of the dataset.

      :type: int, optional

   .. attribute:: sample_points

      The list of sample points in the dataset.

      :type: list[Coordinate], optional

   .. method:: __eq__(other)

      
      Overloaded equality operator for dataset objects.

   .. method:: __hash__()

      
      Calculates a hash for the dataset.

   .. method:: __repr__()

      
      Returns the official string representation of the dataset object.

   .. method:: __str__()

      
      Returns the string representation of the dataset object.

   .. method:: _neuroglancer_layers(prefix="", exclude_layers=None)

      
      Generates neuroglancer layers for raw, gt and mask if they can be viewed by neuroglance, excluding those in
      the exclude_layers.

   .. rubric:: Notes

   This class is a base class and should not be instantiated.


   .. py:attribute:: name
      :type:  str


   .. py:attribute:: raw
      :type:  dacapo.experiments.datasplits.datasets.arrays.Array


   .. py:attribute:: gt
      :type:  Optional[dacapo.experiments.datasplits.datasets.arrays.Array]


   .. py:attribute:: mask
      :type:  Optional[dacapo.experiments.datasplits.datasets.arrays.Array]


   .. py:attribute:: weight
      :type:  Optional[int]


   .. py:attribute:: sample_points
      :type:  Optional[List[funlib.geometry.Coordinate]]


.. py:class:: DatasetConfig

   A class used to define configuration for datasets. This provides the
   framework to create a Dataset instance.

   .. attribute:: name

      str (eg: "sample_dataset").
      A unique identifier to name the dataset.
      It aids in easy identification and reusability of this dataset.
      Advised to keep it short and refrain from using special characters.

   .. attribute:: weight

      int (default=1).
      A numeric value that indicates how frequently this dataset should be
      sampled in comparison to others. Higher the weight, more frequently it
      gets sampled.

   .. method:: verify

      
      Checks and validates the dataset configuration. The specific rules for
      validation need to be defined by the user.

   .. rubric:: Notes

   This class is used to create a configuration object for datasets.


   .. py:attribute:: name
      :type:  str


   .. py:attribute:: weight
      :type:  int


   .. py:method:: verify() -> Tuple[bool, str]

      Method to verify the dataset configuration.

      Since there is no specific validation logic defined for this DataSet, this
      method will always return True as default reaction and a message stating
      the lack of validation.

      :returns: A tuple of boolean value indicating the check (True or False) and
                message specifying result of validation.
      :rtype: tuple

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> dataset_config = DatasetConfig(name="sample_dataset")
      >>> dataset_config.verify()
      (True, "No validation for this DataSet")

      .. rubric:: Notes

      This method is used to validate the configuration of the dataset.



.. py:class:: DummyDataset(dataset_config)



   DummyDataset is a child class of the Dataset. This class has property 'raw' of Array type and a name.

   .. attribute:: raw

      Array
      The raw data.

   .. method:: __init__(dataset_config)

      
      Initializes the array type 'raw' and name for the DummyDataset instance.

   .. rubric:: Notes

   This class is used to create a dataset with raw data.


   .. py:attribute:: raw
      :type:  dacapo.experiments.datasplits.datasets.arrays.Array


.. py:class:: DummyDatasetConfig



   A dummy configuration class for test datasets.

   .. attribute:: dataset_type

      Clearly mentions the type of dataset

   .. attribute:: raw_config

      This attribute holds the configurations related to dataset arrays.

   .. method:: verify

      A dummy verification method for testing purposes, always returns False and a message.

   .. rubric:: Notes

   This class is used to create a configuration object for the dummy dataset.


   .. py:attribute:: dataset_type


   .. py:attribute:: raw_config
      :type:  dacapo.experiments.datasplits.datasets.arrays.ArrayConfig


   .. py:method:: verify() -> Tuple[bool, str]

      A dummy method that always indicates the dataset config is not valid.

      :returns: A tuple of False and a message indicating the invalidity.

      :raises NotImplementedError: If the method is not implemented in the derived class.

      .. rubric:: Examples

      >>> dataset_config = DummyDatasetConfig(raw_config=DummyArrayConfig(name="dummy_array"))
      >>> dataset_config.verify()
      (False, "This is a DummyDatasetConfig and is never valid")

      .. rubric:: Notes

      This method is used to validate the configuration of the dataset.



.. py:class:: RawGTDataset(dataset_config)



   A dataset that contains raw and ground truth data. Optionally, it can also contain a mask.

   .. attribute:: raw

      Array
      The raw data.

   .. attribute:: gt

      Array
      The ground truth data.

   .. attribute:: mask

      Optional[Array]
      The mask data.

   .. attribute:: sample_points

      Optional[List[Coordinate]]
      The sample points in the graph.

   .. attribute:: weight

      Optional[float]
      The weight of the dataset.

   .. method:: __init__(dataset_config)

      
      Initialize the dataset.

   .. rubric:: Notes

   This class is a base class and should not be instantiated.


   .. py:attribute:: raw
      :type:  dacapo.experiments.datasplits.datasets.arrays.Array


   .. py:attribute:: gt
      :type:  dacapo.experiments.datasplits.datasets.arrays.Array


   .. py:attribute:: mask
      :type:  Optional[dacapo.experiments.datasplits.datasets.arrays.Array]


   .. py:attribute:: sample_points
      :type:  Optional[List[funlib.geometry.Coordinate]]


.. py:class:: RawGTDatasetConfig



   This is a configuration class for the standard dataset with both raw and GT Array.

   The configuration includes array configurations for raw data, ground truth data and mask data.
   The configuration for ground truth (GT) data is mandatory, whereas configurations for raw
   and mask data are optional. It also includes an optional list of points around which training samples
   will be extracted.

   .. attribute:: dataset_type

      The type of dataset that is being configured.

      :type: class

   .. attribute:: raw_config

      Configuration for the raw data associated with this dataset.

      :type: Optional[ArrayConfig]

   .. attribute:: gt_config

      Configuration for the ground truth data associated with this dataset.

      :type: Optional[ArrayConfig]

   .. attribute:: mask_config

      An optional mask configuration that sets the loss
      equal to zero on voxels where the mask is 1.

      :type: Optional[ArrayConfig]

   .. attribute:: sample_points

      An optional list of points around which
      training samples will be extracted.

      :type: Optional[List[Coordinate]]

   .. method:: verify

      A method to verify the validity of the configuration.

   .. rubric:: Notes

   This class is used to create a configuration object for the standard dataset with both raw and GT Array.


   .. py:attribute:: dataset_type


   .. py:attribute:: raw_config
      :type:  Optional[dacapo.experiments.datasplits.datasets.arrays.ArrayConfig]


   .. py:attribute:: gt_config
      :type:  Optional[dacapo.experiments.datasplits.datasets.arrays.ArrayConfig]


   .. py:attribute:: mask_config
      :type:  Optional[dacapo.experiments.datasplits.datasets.arrays.ArrayConfig]


   .. py:attribute:: sample_points
      :type:  Optional[List[funlib.geometry.Coordinate]]


.. py:class:: Array



   An Array is a multi-dimensional array of data that can be read from and written to. It is
   defined by a region of interest (ROI) in world units, a voxel size, and a number of spatial
   dimensions. The data is stored in a numpy array, and can be accessed using numpy-like slicing
   syntax.

   The Array class is an abstract base class that defines the interface for all Array
   implementations. It provides a number of properties that must be implemented by subclasses,
   such as the ROI, voxel size, and data type of the array. It also provides a method for fetching
   data from the array, which is implemented by slicing the numpy array.

   The Array class also provides a method for checking if the array can be visualized in
   Neuroglancer, and a method for generating a Neuroglancer layer for the array. These methods are
   implemented by subclasses that support visualization in Neuroglancer.

   .. attribute:: attrs

      A dictionary of metadata attributes stored on this array.

      :type: Dict[str, Any]

   .. attribute:: axes

      The axes of this dataset as a string of characters, as they are indexed.
      Permitted characters are:
          * ``zyx`` for spatial dimensions
          * ``c`` for channels
          * ``s`` for samples

      :type: List[str]

   .. attribute:: dims

      The number of spatial dimensions.

      :type: int

   .. attribute:: voxel_size

      The size of a voxel in physical units.

      :type: Coordinate

   .. attribute:: roi

      The total ROI of this array, in world units.

      :type: Roi

   .. attribute:: dtype

      The dtype of this array, in numpy dtypes

      :type: Any

   .. attribute:: num_channels

      The number of channels provided by this dataset. Should return
      None if the channel dimension doesn't exist.

      :type: Optional[int]

   .. attribute:: data

      A numpy-like readable and writable view into this array.

      :type: np.ndarray

   .. attribute:: writable

      Can we write to this Array?

      :type: bool

   .. method:: __getitem__(self, roi

      Roi) -> np.ndarray: Get a numpy like readable and writable view into
      this array.

   .. method:: _can_neuroglance(self) -> bool

      Check if this array can be visualized in Neuroglancer.

   .. method:: _neuroglancer_layer(self)

      Generate a Neuroglancer layer for this array.

   .. method:: _slices(self, roi

      Roi) -> Iterable[slice]: Generate a list of slices for the given ROI.

   .. note::

      This class is used to define the interface for all Array implementations. It provides a
      number of properties that must be implemented by subclasses, such as the ROI, voxel size, and
      data type of the array. It also provides a method for fetching data from the array, which is
      implemented by slicing the numpy array. The Array class also provides a method for checking
      if the array can be visualized in Neuroglancer, and a method for generating a Neuroglancer
      layer for the array. These methods are implemented by subclasses that support visualization
      in Neuroglancer.


   .. py:property:: attrs
      :type: Dict[str, Any]

      :abstractmethod:

      Return a dictionary of metadata attributes stored on this array.

      :returns: A dictionary of metadata attributes stored on this array.
      :rtype: Dict[str, Any]

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.attrs
      {}

      .. note:: This method must be implemented by the subclass.


   .. py:property:: axes
      :type: List[str]

      :abstractmethod:

      Returns the axes of this dataset as a string of charactes, as they
      are indexed. Permitted characters are:

          * ``zyx`` for spatial dimensions
          * ``c`` for channels
          * ``s`` for samples

      :returns: The axes of this dataset as a string of characters, as they are indexed.
      :rtype: List[str]

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.axes
      ['z', 'y', 'x']

      .. note:: This method must be implemented by the subclass.


   .. py:property:: dims
      :type: int

      :abstractmethod:

      Returns the number of spatial dimensions.

      :returns: The number of spatial dimensions.
      :rtype: int

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.dims
      3

      .. note:: This method must be implemented by the subclass.


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      :abstractmethod:

      The size of a voxel in physical units.

      :returns: The size of a voxel in physical units.
      :rtype: Coordinate

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.voxel_size
      Coordinate((1, 1, 1))

      .. note:: This method must be implemented by the subclass.


   .. py:property:: roi
      :type: funlib.geometry.Roi

      :abstractmethod:

      The total ROI of this array, in world units.

      :returns: The total ROI of this array, in world units.
      :rtype: Roi

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.roi
      Roi(offset=Coordinate((0, 0, 0)), shape=Coordinate((100, 100, 100)))

      .. note:: This method must be implemented by the subclass.


   .. py:property:: dtype
      :type: Any

      :abstractmethod:

      The dtype of this array, in numpy dtypes

      :returns: The dtype of this array, in numpy dtypes.
      :rtype: Any

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.dtype
      np.dtype('uint8')

      .. note:: This method must be implemented by the subclass.


   .. py:property:: num_channels
      :type: Optional[int]

      :abstractmethod:

      The number of channels provided by this dataset.
      Should return None if the channel dimension doesn't exist.

      :returns: The number of channels provided by this dataset.
      :rtype: Optional[int]

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.num_channels
      1

      .. note:: This method must be implemented by the subclass.


   .. py:property:: data
      :type: numpy.ndarray

      :abstractmethod:

      Get a numpy like readable and writable view into this array.

      :returns: A numpy like readable and writable view into this array.
      :rtype: np.ndarray

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.data
      np.ndarray

      .. note:: This method must be implemented by the subclass.


   .. py:property:: writable
      :type: bool

      :abstractmethod:

      Can we write to this Array?

      :returns: Can we write to this Array?
      :rtype: bool

      :raises NotImplementedError: This method must be implemented by the subclass.

      .. rubric:: Examples

      >>> array = Array()
      >>> array.writable
      False

      .. note:: This method must be implemented by the subclass.


.. py:class:: ArrayConfig

   Base class for array configurations. Each subclass of an
   `Array` should have a corresponding config class derived from
   `ArrayConfig`. This class should be used to store the configuration
   of the array.

   .. attribute:: name

      A unique name for this array. This will be saved so you
      and others can find and reuse this array. Keep it short
      and avoid special characters.

      :type: str

   .. method:: verify(self) -> Tuple[bool, str]

      This method is used to check whether this is a valid Array.

   .. note::

      This class is used to create a base class for array configurations. Each subclass of an
      `Array` should have a corresponding config class derived from `ArrayConfig`.
      This class should be used to store the configuration of the array.


   .. py:attribute:: name
      :type:  str


   .. py:method:: verify() -> Tuple[bool, str]

      Check whether this is a valid Array

      :returns: A tuple with the first element being a boolean
                indicating whether the array is valid and the second element being
                a string with a message explaining why the array is invalid
      :rtype: Tuple[bool, str]

      :raises NotImplementedError: This method is not implemented in this class

      .. rubric:: Examples

      >>> array_config = ArrayConfig(name="array_config")
      >>> array_config.verify()
      (True, "No validation for this Array")

      .. note:: This method is used to check whether this is a valid Array.



.. py:class:: DummyArray(array_config)



   This is just a dummy array for testing. It has a shape of (100, 50, 50) and is filled with zeros.

   .. attribute:: array_config

      The config object for the array

      :type: ArrayConfig

   .. method:: __getitem__

      Returns the intensities normalized to the range (0, 1)

   .. rubric:: Notes

   The array_config must be an ArrayConfig object.
   The min and max values are used to normalize the intensities.
   All intensities are converted to float32.


   .. py:property:: attrs
      Returns the attributes of the source array

      :returns: The attributes of the source array
      :rtype: dict

      :raises ValueError: If the attributes is not a dictionary

      .. rubric:: Examples

      >>> intensities_array.attrs
      {'resolution': (1.0, 1.0, 1.0), 'unit': 'micrometer'}


   .. py:property:: axes
      Returns the axes of the source array

      :returns: The axes of the source array
      :rtype: str

      :raises ValueError: If the axes is not a string

      .. rubric:: Examples

      >>> intensities_array.axes
      'zyx'

      .. rubric:: Notes

      The axes are the same as the source array


   .. py:property:: dims
      Returns the number of dimensions of the source array

      :returns: The number of dimensions of the source array
      :rtype: int

      :raises ValueError: If the dims is not an integer

      .. rubric:: Examples

      >>> intensities_array.dims
      3

      .. rubric:: Notes

      The dims are the same as the source array


   .. py:property:: voxel_size
      Returns the voxel size of the source array

      :returns: The voxel size of the source array
      :rtype: Coordinate

      :raises ValueError: If the voxel size is not a Coordinate object

      .. rubric:: Examples

      >>> intensities_array.voxel_size
      Coordinate(x=1.0, y=1.0, z=1.0)

      .. rubric:: Notes

      The voxel size is the same as the source array


   .. py:property:: roi
      Returns the region of interest of the source array

      :returns: The region of interest of the source array
      :rtype: Roi

      :raises ValueError: If the roi is not a Roi object

      .. rubric:: Examples

      >>> intensities_array.roi
      Roi(offset=(0, 0, 0), shape=(100, 100, 100))

      .. rubric:: Notes

      The roi is the same as the source array


   .. py:property:: writable
      :type: bool

      Returns whether the array is writable

      :returns: Whether the array is writable
      :rtype: bool

      .. rubric:: Examples

      >>> intensities_array.writable
      True

      .. rubric:: Notes

      The array is always writable


   .. py:property:: data
      Returns the data of the source array

      :returns: The data of the source array
      :rtype: np.ndarray

      :raises ValueError: If the data is not a numpy array

      .. rubric:: Examples

      >>> intensities_array.data
      array([[[0., 0., 0., ..., 0., 0., 0.],
              [0., 0., 0., ..., 0., 0., 0.],
              [0., 0., 0., ..., 0., 0., 0.],
              ...,
              [0., 0., 0., ..., 0., 0., 0.],
              [0., 0., 0., ..., 0., 0., 0.],
              [0., 0., 0., ..., 0., 0., 0.]],

      .. rubric:: Notes

      The data is the same as the source array


   .. py:property:: dtype
      Returns the data type of the array

      :returns: The data type of the array
      :rtype: type

      :raises ValueError: If the data type is not a type

      .. rubric:: Examples

      >>> intensities_array.dtype
      numpy.float32

      .. rubric:: Notes

      The data type is the same as the source array


   .. py:property:: num_channels
      Returns the number of channels in the source array

      :returns: The number of channels in the source array
      :rtype: int

      :raises ValueError: If the number of channels is not an integer

      .. rubric:: Examples

      >>> intensities_array.num_channels
      1

      .. rubric:: Notes

      The number of channels is the same as the source array


.. py:class:: DummyArrayConfig



   This is just a dummy array  config used for testing. None of the
   attributes have any particular meaning. It is used to test the
   ArrayConfig class.

   .. method:: to_array

      Returns the DummyArray object

   .. method:: verify

      Returns whether the DummyArrayConfig is valid

   .. rubric:: Notes

   The source_array_config must be an ArrayConfig object.


   .. py:attribute:: array_type


   .. py:method:: verify() -> Tuple[bool, str]

      Check whether this is a valid Array

      :returns: Whether the Array is valid and a message
      :rtype: Tuple[bool, str]

      :raises ValueError: If the source is not a tuple of strings

      .. rubric:: Examples

      >>> dummy_array_config = DummyArrayConfig(...)
      >>> dummy_array_config.verify()
      (False, "This is a DummyArrayConfig and is never valid")

      .. rubric:: Notes

      The source must be a tuple of strings.



.. py:class:: ZarrArray(array_config)



   This is a zarr array.

   .. attribute:: name

      The name of the array.

      :type: str

   .. attribute:: file_name

      The file name of the array.

      :type: Path

   .. attribute:: dataset

      The dataset name.

      :type: str

   .. attribute:: _axes

      The axes of the array.

      :type: Optional[List[str]]

   .. attribute:: snap_to_grid

      The snap to grid.

      :type: Optional[Coordinate]

   .. method:: __init__(array_config)

      
      Initializes the array type 'raw' and name for the DummyDataset instance.

   .. method:: __str__()

      
      Returns the string representation of the ZarrArray.

   .. method:: __repr__()

      
      Returns the string representation of the ZarrArray.

   .. method:: attrs()

      
      Returns the attributes of the array.

   .. method:: axes()

      
      Returns the axes of the array.

   .. method:: dims()

      
      Returns the dimensions of the array.

   .. method:: _daisy_array()

      
      Returns the daisy array.

   .. method:: voxel_size()

      
      Returns the voxel size of the array.

   .. method:: roi()

      
      Returns the region of interest of the array.

   .. method:: writable()

      
      Returns the boolean value of the array.

   .. method:: dtype()

      
      Returns the data type of the array.

   .. method:: num_channels()

      
      Returns the number of channels of the array.

   .. method:: spatial_axes()

      
      Returns the spatial axes of the array.

   .. method:: data()

      
      Returns the data of the array.

   .. method:: __getitem__(roi)

      
      Returns the data of the array for the given region of interest.

   .. method:: __setitem__(roi, value)

      
      Sets the data of the array for the given region of interest.

   .. method:: create_from_array_identifier(array_identifier, axes, roi, num_channels, voxel_size, dtype, write_size=None, name=None, overwrite=False)

      
      Creates a new ZarrArray given an array identifier.

   .. method:: open_from_array_identifier(array_identifier, name="")

      
      Opens a new ZarrArray given an array identifier.

   .. method:: _can_neuroglance()

      
      Returns the boolean value of the array.

   .. method:: _neuroglancer_source()

      
      Returns the neuroglancer source of the array.

   .. method:: _neuroglancer_layer()

      
      Returns the neuroglancer layer of the array.

   .. method:: _transform_matrix()

      
      Returns the transform matrix of the array.

   .. method:: _output_dimensions()

      
      Returns the output dimensions of the array.

   .. method:: _source_name()

      
      Returns the source name of the array.

   .. method:: add_metadata(metadata)

      
      Adds metadata to the array.

   .. rubric:: Notes

   This class is used to create a zarr array.


   .. py:property:: mode


   .. py:property:: attrs
      Returns the attributes of the array.

      :param attrs: The attributes of the array.
      :type attrs: Any

      :returns: The attributes of the array.
      :rtype: Any

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> attrs()

      .. rubric:: Notes

      This method is used to return the attributes of the array.


   .. py:property:: axes
      Returns the axes of the array.

      :param axes: The axes of the array.
      :type axes: List[str]

      :returns: The axes of the array.
      :rtype: List[str]

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> axes()

      .. rubric:: Notes

      This method is used to return the axes of the array.


   .. py:property:: dims
      :type: int

      Returns the dimensions of the array.

      :param dims: The dimensions of the array.
      :type dims: int

      :returns: The dimensions of the array.
      :rtype: int

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> dims()

      .. rubric:: Notes

      This method is used to return the dimensions of the array.


   .. py:method:: voxel_size() -> funlib.geometry.Coordinate

      Returns the voxel size of the array.

      :param voxel_size: The voxel size.
      :type voxel_size: Coordinate

      :returns: The voxel size of the array.
      :rtype: Coordinate

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> voxel_size()

      .. rubric:: Notes

      This method is used to return the voxel size of the array.



   .. py:method:: roi() -> funlib.geometry.Roi

      Returns the region of interest of the array.

      :param roi: The region of interest.
      :type roi: Roi

      :returns: The region of interest of the array.
      :rtype: Roi

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> roi()

      .. rubric:: Notes

      This method is used to return the region of interest of the array.



   .. py:property:: writable
      :type: bool

      Returns the boolean value of the array.

      :param writable: The boolean value of the array.
      :type writable: bool

      :returns: The boolean value of the array.
      :rtype: bool

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> writable()

      .. rubric:: Notes

      This method is used to return the boolean value of the array.


   .. py:property:: dtype
      :type: Any

      Returns the data type of the array.

      :param dtype: The data type of the array.
      :type dtype: Any

      :returns: The data type of the array.
      :rtype: Any

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> dtype()

      .. rubric:: Notes

      This method is used to return the data type of the array.


   .. py:property:: num_channels
      :type: Optional[int]

      Returns the number of channels of the array.

      :param num_channels: The number of channels of the array.
      :type num_channels: Optional[int]

      :returns: The number of channels of the array.
      :rtype: Optional[int]

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> num_channels()

      .. rubric:: Notes

      This method is used to return the number of channels of the array.


   .. py:property:: spatial_axes
      :type: List[str]

      Returns the spatial axes of the array.

      :param spatial_axes: The spatial axes of the array.
      :type spatial_axes: List[str]

      :returns: The spatial axes of the array.
      :rtype: List[str]

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> spatial_axes()

      .. rubric:: Notes

      This method is used to return the spatial axes of the array.


   .. py:property:: data
      :type: Any

      Returns the data of the array.

      :param data: The data of the array.
      :type data: Any

      :returns: The data of the array.
      :rtype: Any

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> data()

      .. rubric:: Notes

      This method is used to return the data of the array.


   .. py:method:: create_from_array_identifier(array_identifier, axes, roi, num_channels, voxel_size, dtype, mode='a', write_size=None, name=None, overwrite=False)
      :classmethod:


      Create a new ZarrArray given an array identifier. It is assumed that
      this array_identifier points to a dataset that does not yet exist.

      :param array_identifier: The array identifier.
      :type array_identifier: ArrayIdentifier
      :param axes: The axes of the array.
      :type axes: List[str]
      :param roi: The region of interest.
      :type roi: Roi
      :param num_channels: The number of channels.
      :type num_channels: int
      :param voxel_size: The voxel size.
      :type voxel_size: Coordinate
      :param dtype: The data type.
      :type dtype: Any
      :param write_size: The write size.
      :type write_size: Optional[Coordinate]
      :param name: The name of the array.
      :type name: Optional[str]
      :param overwrite: The boolean value to overwrite the array.
      :type overwrite: bool

      :returns: The ZarrArray.
      :rtype: ZarrArray

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> create_from_array_identifier(array_identifier, axes, roi, num_channels, voxel_size, dtype, write_size=None, name=None, overwrite=False)

      .. rubric:: Notes

      This method is used to create a new ZarrArray given an array identifier.



   .. py:method:: open_from_array_identifier(array_identifier, name='')
      :classmethod:


      Opens a new ZarrArray given an array identifier.

      :param array_identifier: The array identifier.
      :type array_identifier: ArrayIdentifier
      :param name: The name of the array.
      :type name: str

      :returns: The ZarrArray.
      :rtype: ZarrArray

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> open_from_array_identifier(array_identifier, name="")

      .. rubric:: Notes

      This method is used to open a new ZarrArray given an array identifier.



   .. py:method:: add_metadata(metadata: Dict[str, Any]) -> None

      Adds metadata to the array.

      :param metadata: The metadata to add to the array.
      :type metadata: Dict[str, Any]

      :raises NotImplementedError:

      .. rubric:: Examples

      >>> add_metadata(metadata)

      .. rubric:: Notes

      This method is used to add metadata to the array.



.. py:class:: ZarrArrayConfig



   This config class provides the necessary configuration for a zarr array.

   A zarr array is a container for large, multi-dimensional arrays. It is similar to HDF5, but is designed to work
   with large arrays that do not fit into memory. Zarr arrays can be stored on disk or in the cloud
   and can be accessed concurrently by multiple processes. Zarr arrays can be compressed and
   support chunked, N-dimensional arrays.

   .. attribute:: file_name

      Path
      The file name of the zarr container.

   .. attribute:: dataset

      str
      The name of your dataset. May include '/' characters for nested heirarchies

   .. attribute:: snap_to_grid

      Optional[Coordinate]
      If you need to make sure your ROI's align with a specific voxel_size

   .. attribute:: _axes

      Optional[List[str]]
      The axes of your data!

   .. method:: verify() -> Tuple[bool, str]

      
      Check whether this is a valid Array

   .. note:: This class is a subclass of ArrayConfig.


   .. py:attribute:: array_type


   .. py:attribute:: file_name
      :type:  upath.UPath


   .. py:attribute:: dataset
      :type:  str


   .. py:attribute:: snap_to_grid
      :type:  Optional[funlib.geometry.Coordinate]


   .. py:attribute:: mode
      :type:  Optional[str]


   .. py:method:: verify() -> Tuple[bool, str]

      Check whether this is a valid Array

      :returns: A tuple of a boolean and a string. The boolean indicates whether the Array is valid or not.
                The string provides a reason why the Array is not valid.
      :rtype: Tuple[bool, str]

      :raises NotImplementedError: This method is not implemented for this Array

      .. rubric:: Examples

      >>> zarr_array_config = ZarrArrayConfig(
      ...     file_name=Path("data.zarr"),
      ...     dataset="data",
      ...     snap_to_grid=Coordinate(1, 1, 1),
      ...     _axes=["x", "y", "z"]
      ... )
      >>> zarr_array_config.verify()
      (True, 'No validation for this Array')

      .. note:: This method is not implemented for this Array



.. py:class:: BinarizeArray(array_config)



   This is wrapper around a ZarrArray containing uint annotations.
   Because we often want to predict classes that are a combination
   of a set of labels we wrap a ZarrArray with the BinarizeArray
   and provide something like `groupings=[("mito", [3,4,5])]`
   where 4 corresponds to mito_mem (mitochondria membrane), 5 is mito_ribo
   (mitochondria ribosomes), and 3 is everything else that is part of a
   mitochondria. The BinarizeArray will simply combine labels 3,4,5 into
   a single binary channel for the class of "mito".

   We use a single channel per class because some classes may overlap.
   For example if you had `groupings=[("mito", [3,4,5]), ("membrane", [4, 8, 1])]`
   where 4 is mito_mem, 8 is er_mem (ER membrane), and 1 is pm (plasma membrane).
   Now you can have a binary classification for membrane or not which in
   some cases overlaps with the channel for mitochondria which includes
   the mito membrane.

   .. attribute:: name

      The name of the array.

      :type: str

   .. attribute:: source_array

      The source array to binarize.

      :type: Array

   .. attribute:: background

      The label to treat as background.

      :type: int

   .. attribute:: groupings

      A list of tuples where the first
      element is the name of the class and the second element is a list of
      labels that should be combined into a single binary channel.

      :type: List[Tuple[str, List[int]]]

   .. method:: __init__(self, array_config)

      This method initializes the BinarizeArray object.

   .. method:: __attrs_post_init__(self)

      This method is called after the instance has been initialized by the constructor. It is used to set the default_config to an instance of ArrayConfig if it is None.

   .. method:: __getitem__(self, roi

      Roi) -> np.ndarray: This method returns the binary channels for the given region of interest.

   .. method:: _can_neuroglance(self)

      This method returns True if the source array can be visualized in neuroglance.

   .. method:: _neuroglancer_source(self)

      This method returns the source array for neuroglancer.

   .. method:: _neuroglancer_layer(self)

      This method returns the neuroglancer layer for the source array.

   .. method:: _source_name(self)

      This method returns the name of the source array.

   .. note:: This class is used to create a BinarizeArray object which is a wrapper around a ZarrArray containing uint annotations.


   .. py:property:: attrs
      This method returns the attributes of the source array.

      :returns: The attributes of the source array.
      :rtype: Dict

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.attrs

      .. note:: This method is used to return the attributes of the source array.


   .. py:property:: axes
      This method returns the axes of the source array.

      :returns: The axes of the source array.
      :rtype: List[str]

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.axes

      .. note:: This method is used to return the axes of the source array.


   .. py:property:: dims
      :type: int

      This method returns the dimensions of the source array.

      :returns: The dimensions of the source array.
      :rtype: int

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.dims

      .. note:: This method is used to return the dimensions of the source array.


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      This method returns the voxel size of the source array.

      :returns: The voxel size of the source array.
      :rtype: Coordinate

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.voxel_size

      .. note:: This method is used to return the voxel size of the source array.


   .. py:property:: roi
      :type: funlib.geometry.Roi

      This method returns the region of interest of the source array.

      :returns: The region of interest of the source array.
      :rtype: Roi

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.roi

      .. note:: This method is used to return the region of interest of the source array.


   .. py:property:: writable
      :type: bool

      This method returns True if the source array is writable.

      :returns: True if the source array is writable.
      :rtype: bool

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.writable

      .. note:: This method is used to return True if the source array is writable.


   .. py:property:: dtype
      This method returns the data type of the source array.

      :returns: The data type of the source array.
      :rtype: np.dtype

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.dtype

      .. note:: This method is used to return the data type of the source array.


   .. py:property:: num_channels
      :type: int

      This method returns the number of channels in the source array.

      :returns: The number of channels in the source array.
      :rtype: int

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.num_channels

      .. note:: This method is used to return the number of channels in the source array.


   .. py:property:: data
      This method returns the data of the source array.

      :returns: The data of the source array.
      :rtype: np.ndarray

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.data

      .. note:: This method is used to return the data of the source array.


   .. py:property:: channels
      This method returns the channel names of the source array.

      :returns: The channel names of the source array.
      :rtype: Iterator[str]

      :raises ValueError: If the source array is not writable.

      .. rubric:: Examples

      >>> binarize_array.channels

      .. note:: This method is used to return the channel names of the source array.


.. py:class:: BinarizeArrayConfig



   This config class provides the necessary configuration for turning an Annotated dataset into a
   multi class binary classification problem. Each class will be binarized into a separate channel.

   .. attribute:: source_array_config

      The Array from which to pull annotated data. Is expected to contain a volume with uint64 voxels and no channel dimension

      :type: ArrayConfig

   .. attribute:: groupings

      List of id groups with a symantic name. Each id group is a List of ids.
      Group i found in groupings[i] will be binarized and placed in channel i.
      An empty group will binarize all non background labels.

      :type: List[Tuple[str, List[int]]]

   .. attribute:: background

      The id considered background. Will never be binarized to 1, defaults to 0.

      :type: int

   .. note::

      This class is used to create a BinarizeArray object which is used to turn an Annotated dataset into a multi class binary classification problem.
      Each class will be binarized into a separate channel.


   .. py:attribute:: array_type


   .. py:attribute:: source_array_config
      :type:  dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig


   .. py:attribute:: groupings
      :type:  List[Tuple[str, List[int]]]


   .. py:attribute:: background
      :type:  int


.. py:class:: ResampledArray(array_config)



   This is a zarr array that is a resampled version of another array.

   Resampling is done by rescaling the source array with the given
   upsample and downsample factors. The voxel size of the resampled array
   is the voxel size of the source array divided by the downsample factor
   and multiplied by the upsample factor.

   .. attribute:: name

      str
      The name of the array

   .. attribute:: source_array

      Array
      The source array

   .. attribute:: upsample

      Coordinate
      The upsample factor for each dimension

   .. attribute:: downsample

      Coordinate
      The downsample factor for each dimension

   .. attribute:: interp_order

      int
      The order of the interpolation used for resampling

   .. method:: attrs

      Dict
      Returns the attributes of the source array

   .. method:: axes

      str
      Returns the axes of the source array

   .. method:: dims

      int
      Returns the number of dimensions of the source array

   .. method:: voxel_size

      Coordinate
      Returns the voxel size of the resampled array

   .. method:: roi

      Roi
      Returns the region of interest of the resampled array

   .. method:: writable

      bool
      Returns whether the resampled array is writable

   .. method:: dtype

      np.dtype
      Returns the data type of the resampled array

   .. method:: num_channels

      int
      Returns the number of channels of the resampled array

   .. method:: data

      np.ndarray
      Returns the data of the resampled array

   .. method:: scale

      Tuple[float]
      Returns the scale of the resampled array

   .. method:: __getitem__(roi

      Roi) -> np.ndarray
      Returns the data of the resampled array within the given region of interest

   .. method:: _can_neuroglance() -> bool

      
      Returns whether the source array can be visualized with neuroglance

   .. method:: _neuroglancer_layer() -> Dict

      
      Returns the neuroglancer layer of the source array

   .. method:: _neuroglancer_source() -> Dict

      
      Returns the neuroglancer source of the source array

   .. method:: _source_name() -> str

      
      Returns the name of the source array

   .. note:: This class is a subclass of Array.


   .. py:property:: attrs
      Returns the attributes of the source array.

      :returns: The attributes of the source array
      :rtype: Dict

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.attrs

      .. note:: This method returns the attributes of the source array.


   .. py:property:: axes
      Returns the axes of the source array.

      :returns: The axes of the source array
      :rtype: str

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.axes

      .. note:: This method returns the axes of the source array.


   .. py:property:: dims
      :type: int

      Returns the number of dimensions of the source array.

      :returns: The number of dimensions of the source array
      :rtype: int

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.dims

      .. note:: This method returns the number of dimensions of the source array.


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      Returns the voxel size of the resampled array.

      :returns: The voxel size of the resampled array
      :rtype: Coordinate

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.voxel_size

      .. note:: This method returns the voxel size of the resampled array.


   .. py:property:: roi
      :type: funlib.geometry.Roi

      Returns the region of interest of the resampled array.

      :returns: The region of interest of the resampled array
      :rtype: Roi

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.roi

      .. note:: This method returns the region of interest of the resampled array.


   .. py:property:: writable
      :type: bool

      Returns whether the resampled array is writable.

      :returns: True if the resampled array is writable, False otherwise
      :rtype: bool

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.writable

      .. note:: This method returns whether the resampled array is writable.


   .. py:property:: dtype
      Returns the data type of the resampled array.

      :returns: The data type of the resampled array
      :rtype: np.dtype

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.dtype

      .. note:: This method returns the data type of the resampled array.


   .. py:property:: num_channels
      :type: int

      Returns the number of channels of the resampled array.

      :returns: The number of channels of the resampled array
      :rtype: int

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.num_channels

      .. note:: This method returns the number of channels of the resampled array.


   .. py:property:: data
      Returns the data of the resampled array.

      :returns: The data of the resampled array
      :rtype: np.ndarray

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.data

      .. note:: This method returns the data of the resampled array.


   .. py:property:: scale
      Returns the scale of the resampled array.

      :returns: The scale of the resampled array
      :rtype: Tuple[float]

      :raises ValueError: If the resampled array is not writable

      .. rubric:: Examples

      >>> resampled_array.scale

      .. note:: This method returns the scale of the resampled array.


.. py:class:: ResampledArrayConfig



   A configuration for a ResampledArray. This array will up or down sample an array into the desired voxel size.

   .. attribute:: source_array_config

      The Array that you want to upsample or downsample.

      :type: ArrayConfig

   .. attribute:: upsample

      The amount by which to upsample!

      :type: Coordinate

   .. attribute:: downsample

      The amount by which to downsample!

      :type: Coordinate

   .. attribute:: interp_order

      The order of the interpolation!

      :type: bool

   .. method:: create_array

      Creates a ResampledArray from the configuration.

   .. note:: This class is meant to be used with the ArrayDataset class.


   .. py:attribute:: array_type


   .. py:attribute:: source_array_config
      :type:  dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig


   .. py:attribute:: upsample
      :type:  funlib.geometry.Coordinate


   .. py:attribute:: downsample
      :type:  funlib.geometry.Coordinate


   .. py:attribute:: interp_order
      :type:  bool


.. py:class:: IntensitiesArray(array_config)



   This is wrapper another array that will normalize intensities to
   the range (0, 1) and convert to float32. Use this if you have your
   intensities stored as uint8 or similar and want your model to
   have floats as input.

   .. attribute:: array_config

      The config object for the array

      :type: ArrayConfig

   .. attribute:: min

      The minimum intensity value in the array

      :type: float

   .. attribute:: max

      The maximum intensity value in the array

      :type: float

   .. method:: __getitem__

      Returns the intensities normalized to the range (0, 1)

   .. rubric:: Notes

   The array_config must be an ArrayConfig object.
   The min and max values are used to normalize the intensities.
   All intensities are converted to float32.


   .. py:property:: attrs
      Returns the attributes of the source array

      :returns: The attributes of the source array
      :rtype: dict

      :raises ValueError: If the attributes is not a dictionary

      .. rubric:: Examples

      >>> intensities_array.attrs
      {'resolution': (1.0, 1.0, 1.0), 'unit': 'micrometer'}

      .. rubric:: Notes

      The attributes are the same as the source array


   .. py:property:: axes
      Returns the axes of the source array

      :returns: The axes of the source array
      :rtype: str

      :raises ValueError: If the axes is not a string

      .. rubric:: Examples

      >>> intensities_array.axes
      'zyx'

      .. rubric:: Notes

      The axes are the same as the source array


   .. py:property:: dims
      :type: int

      Returns the dimensions of the source array

      :returns: The dimensions of the source array
      :rtype: int

      :raises ValueError: If the dimensions is not an integer

      .. rubric:: Examples

      >>> intensities_array.dims
      3

      .. rubric:: Notes

      The dimensions are the same as the source array


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      Returns the voxel size of the source array

      :returns: The voxel size of the source array
      :rtype: Coordinate

      :raises ValueError: If the voxel size is not a Coordinate object

      .. rubric:: Examples

      >>> intensities_array.voxel_size
      Coordinate(x=1.0, y=1.0, z=1.0)

      .. rubric:: Notes

      The voxel size is the same as the source array


   .. py:property:: roi
      :type: funlib.geometry.Roi

      Returns the region of interest of the source array

      :returns: The region of interest of the source array
      :rtype: Roi

      :raises ValueError: If the region of interest is not a Roi object

      .. rubric:: Examples

      >>> intensities_array.roi
      Roi(offset=(0, 0, 0), shape=(10, 20, 30))

      .. rubric:: Notes

      The region of interest is the same as the source array


   .. py:property:: writable
      :type: bool

      Returns whether the array is writable

      :returns: Whether the array is writable
      :rtype: bool

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> intensities_array.writable
      False

      .. rubric:: Notes

      The array is not writable because it is a virtual array created by modifying another array on demand.


   .. py:property:: dtype
      Returns the data type of the array

      :returns: The data type of the array
      :rtype: type

      :raises ValueError: If the data type is not a type

      .. rubric:: Examples

      >>> intensities_array.dtype
      numpy.float32

      .. rubric:: Notes

      The data type is always float32


   .. py:property:: num_channels
      :type: int

      Returns the number of channels in the source array

      :returns: The number of channels in the source array
      :rtype: int

      :raises ValueError: If the number of channels is not an integer

      .. rubric:: Examples

      >>> intensities_array.num_channels
      3

      .. rubric:: Notes

      The number of channels is the same as the source array


   .. py:property:: data
      Returns the data of the source array

      :returns: The data of the source array
      :rtype: np.ndarray

      :raises ValueError: If the data is not a numpy array

      .. rubric:: Examples

      >>> intensities_array.data
      array([[[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]], [[0.7, 0.8, 0.9], [1.0, 1.1, 1.2]]])

      .. rubric:: Notes

      The data is the same as the source array


.. py:class:: IntensitiesArrayConfig



   This config class provides the necessary configuration for turning an Annotated dataset into a
   multi class binary classification problem. It takes a source array and normalizes the intensities
   between 0 and 1. The source array is expected to contain a volume with uint64 voxels and no channel dimension.

   .. attribute:: source_array_config

      The Array from which to pull annotated data

      :type: ArrayConfig

   .. attribute:: min

      The minimum intensity in your data

      :type: float

   .. attribute:: max

      The maximum intensity in your data

      :type: float

   .. method:: to_array

      Returns the IntensitiesArray object

   .. rubric:: Notes

   The source_array_config must be an ArrayConfig object.


   .. py:attribute:: array_type


   .. py:attribute:: source_array_config
      :type:  dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig


   .. py:attribute:: min
      :type:  float


   .. py:attribute:: max
      :type:  float


.. py:class:: MissingAnnotationsMask(array_config)



   This is wrapper around a ZarrArray containing uint annotations.
   Complementary to the BinarizeArray class where we convert labels
   into individual channels for training, we may find crops where a
   specific label is present, but not annotated. In that case you
   might want to avoid training specific channels for specific
   training volumes.
   See package fibsem_tools for appropriate metadata format for indicating
   presence of labels in your ground truth.
   "https://github.com/janelia-cosem/fibsem-tools"

   .. attribute:: array_config

      A BinarizeArrayConfig object

   .. method:: __getitem__(roi

      Roi) -> np.ndarray: Returns a binary mask of the
      annotations that are present but not annotated.

   .. note::

      This class is not meant to be used directly. It is used by the
      BinarizeArray class to mask out annotations that are present but
      not annotated.


   .. py:property:: axes
      Returns the axes of the source array

      :returns: Axes of the source array
      :rtype: list

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.axes
      ['x', 'y', 'z']

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: dims
      :type: int

      Returns the number of dimensions of the source array

      :returns: Number of dimensions of the source array
      :rtype: int

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.dims
      3

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      Returns the voxel size of the source array

      :returns: Voxel size of the source array
      :rtype: Coordinate

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.voxel_size
      Coordinate(x=4, y=4, z=40)

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: roi
      :type: funlib.geometry.Roi

      Returns the region of interest of the source array

      :returns: Region of interest of the source array
      :rtype: Roi

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.roi
      Roi(offset=(0, 0, 0), shape=(100, 100, 100))

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: writable
      :type: bool

      Returns whether the source array is writable

      :returns: Whether the source array is writable
      :rtype: bool

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.writable
      False

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: dtype
      Returns the data type of the source array

      :returns: Data type of the source array
      :rtype: np.dtype

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.dtype
      np.uint8

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: num_channels
      :type: int

      Returns the number of channels

      :returns: Number of channels
      :rtype: int

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.num_channels
      2

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: data
      Returns the data of the source array

      :returns: Data of the source array
      :rtype: np.ndarray

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.data
      np.ndarray(...)

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: attrs
      Returns the attributes of the source array

      :returns: Attributes of the source array
      :rtype: dict

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.attrs
      {'name': 'source_array', 'resolution': [4, 4, 40]}

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


   .. py:property:: channels
      Returns the names of the channels

      :returns: Names of the channels
      :rtype: Generator[str]

      :raises ValueError: If the source array does not have a name

      .. rubric:: Examples

      >>> source_array = ZarrArray(ZarrArrayConfig(...))
      >>> source_array.channels
      Generator['channel1', 'channel2', ...]

      .. rubric:: Notes

      This is a helper function for the BinarizeArray class


.. py:class:: MissingAnnotationsMaskConfig



   This config class provides the necessary configuration for turning an Annotated dataset into a
   multi class binary classification problem

   .. attribute:: source_array_config

      ArrayConfig
      The Array from which to pull annotated data. Is expected to contain a volume with uint64 voxels and no channel dimension

   .. attribute:: groupings

      List[Tuple[str, List[int]]]
      List of id groups with a symantic name. Each id group is a List of ids.
      Group i found in groupings[i] will be binarized and placed in channel i.

   .. note::

      The output array will have a channel dimension equal to the number of groups.
      Each channel will be a binary mask of the ids in the groupings list.


   .. py:attribute:: array_type


   .. py:attribute:: source_array_config
      :type:  dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig


   .. py:attribute:: groupings
      :type:  List[Tuple[str, List[int]]]


.. py:class:: OnesArray(array_config)



   This is a wrapper around another `source_array` that simply provides ones
   with the same metadata as the `source_array`.

   This is useful for creating a mask array that is the same size as the
   original array, but with all values set to 1.

   .. attribute:: source_array

      The source array that this array is based on.

   .. method:: like

      Create a new OnesArray with the same metadata as another array.

   .. method:: attrs

      Get the attributes of the array.

   .. method:: axes

      Get the axes of the array.

   .. method:: dims

      Get the dimensions of the array.

   .. method:: voxel_size

      Get the voxel size of the array.

   .. method:: roi

      Get the region of interest of the array.

   .. method:: writable

      Check if the array is writable.

   .. method:: data

      Get the data of the array.

   .. method:: dtype

      Get the data type of the array.

   .. method:: num_channels

      Get the number of channels of the array.

   .. method:: __getitem__

      Get a subarray of the array.

   .. note::

      This class is not meant to be instantiated directly. Instead, use the
      `like` method to create a new OnesArray with the same metadata as
      another array.


   .. py:method:: like(array: dacapo.experiments.datasplits.datasets.arrays.array.Array)
      :classmethod:


      Create a new OnesArray with the same metadata as another array.

      :param array: The source array.

      :returns: The new OnesArray with the same metadata as the source array.

      :raises RuntimeError: If the source array is not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray.like(source_array)
      >>> ones_array.source_array
      NumpyArray(data=array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]), voxel_size=(1.0, 1.0, 1.0), roi=Roi((0, 0, 0), (10, 10, 10)), num_channels=1)

      .. rubric:: Notes

      This class is not meant to be instantiated directly. Instead, use the
      `like` method to create a new OnesArray with the same metadata as
      another array.



   .. py:property:: attrs
      Get the attributes of the array.

      :returns: An empty dictionary.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.attrs
      {}

      .. rubric:: Notes

      This method is used to get the attributes of the array. The attributes
      are stored as key-value pairs in a dictionary. This method returns an
      empty dictionary because the OnesArray does not have any attributes.


   .. py:property:: source_array
      :type: dacapo.experiments.datasplits.datasets.arrays.array.Array

      Get the source array that this array is based on.

      :returns: The source array.

      :raises RuntimeError: If the source array is not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.source_array
      NumpyArray(data=array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
                              [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]), voxel_size=(1.0, 1.0, 1.0), roi=Roi((0, 0, 0), (10, 10, 10)), num_channels=1)

      .. rubric:: Notes

      This method is used to get the source array that this array is based on.
      The source array is the array that the OnesArray is created from. This
      method returns the source array that was specified when the OnesArray
      was created.


   .. py:property:: axes
      Get the axes of the array.

      :returns: The axes of the array.

      :raises RuntimeError: If the axes are not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.axes
      'zyx'

      .. rubric:: Notes

      This method is used to get the axes of the array. The axes are the
      order of the dimensions of the array. This method returns the axes of
      the array that was specified when the OnesArray was created.


   .. py:property:: dims
      Get the dimensions of the array.

      :returns: The dimensions of the array.

      :raises RuntimeError: If the dimensions are not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.dims
      (10, 10, 10)

      .. rubric:: Notes

      This method is used to get the dimensions of the array. The dimensions
      are the size of the array along each axis. This method returns the
      dimensions of the array that was specified when the OnesArray was created.


   .. py:property:: voxel_size
      Get the voxel size of the array.

      :returns: The voxel size of the array.

      :raises RuntimeError: If the voxel size is not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.voxel_size
      (1.0, 1.0, 1.0)

      .. rubric:: Notes

      This method is used to get the voxel size of the array. The voxel size
      is the size of each voxel in the array. This method returns the voxel
      size of the array that was specified when the OnesArray was created.


   .. py:property:: roi
      Get the region of interest of the array.

      :returns: The region of interest of the array.

      :raises RuntimeError: If the region of interest is not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.roi
      Roi((0, 0, 0), (10, 10, 10))

      .. rubric:: Notes

      This method is used to get the region of interest of the array. The
      region of interest is the region of the array that contains the data.
      This method returns the region of interest of the array that was specified
      when the OnesArray was created.


   .. py:property:: writable
      :type: bool

      Check if the array is writable.

      :returns: False.

      :raises RuntimeError: If the writability of the array is not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.writable
      False

      .. rubric:: Notes

      This method is used to check if the array is writable. An array is
      writable if it can be modified in place. This method returns False
      because the OnesArray is read-only and cannot be modified.


   .. py:property:: data
      Get the data of the array.

      :returns: The data of the array.

      :raises RuntimeError: If the data is not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.data
      array([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]])

      .. rubric:: Notes

      This method is used to get the data of the array. The data is the
      values that are stored in the array. This method returns a subarray
      of the array with all values set to 1.


   .. py:property:: dtype
      Get the data type of the array.

      :returns: The data type of the array.

      :raises RuntimeError: If the data type is not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.dtype
      <class 'numpy.bool_'>

      .. rubric:: Notes

      This method is used to get the data type of the array. The data type
      is the type of the values that are stored in the array. This method
      returns the data type of the array that was specified when the OnesArray
      was created.


   .. py:property:: num_channels
      Get the number of channels of the array.

      :returns: The number of channels of the array.

      :raises RuntimeError: If the number of channels is not specified.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import OnesArray
      >>> from dacapo.experiments.datasplits.datasets.arrays import NumpyArray
      >>> import numpy as np
      >>> source_array = NumpyArray(np.zeros((10, 10, 10)))
      >>> ones_array = OnesArray(source_array)
      >>> ones_array.num_channels
      1

      .. rubric:: Notes

      This method is used to get the number of channels of the array. The
      number of channels is the number of values that are stored at each
      voxel in the array. This method returns the number of channels of the
      array that was specified when the OnesArray was created.


.. py:class:: OnesArrayConfig



   This array read data from the source array and then return a np.ones_like() version.

   This is useful for creating a mask array from a source array. For example, if you have a
   2D array of data and you want to create a mask array that is the same shape as the data
   array, you can use this class to create the mask array.

   .. attribute:: source_array_config

      The source array that you want to copy and fill with ones.

   .. method:: create_array

      Create the array.

   .. note:: This class is a subclass of ArrayConfig.


   .. py:attribute:: array_type


   .. py:attribute:: source_array_config
      :type:  dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig


.. py:class:: ConcatArray(array_config)



   This is a wrapper around other `source_arrays` that concatenates
   them along the channel dimension. The `source_arrays` are expected
   to have the same shape and ROI, but can have different data types.

   .. attribute:: name

      The name of the array.

   .. attribute:: channels

      The list of channel names.

   .. attribute:: source_arrays

      A dictionary mapping channel names to source arrays.

   .. attribute:: default_array

      An optional default array to use for channels that are
      not present in `source_arrays`.

   .. method:: from_toml(cls, toml_path

      str) -> ConcatArrayConfig:
      Load the ConcatArrayConfig from a TOML file

   .. method:: to_toml(self, toml_path

      str) -> None:
      Save the ConcatArrayConfig to a TOML file

   .. method:: create_array(self) -> ConcatArray

      
      Create the ConcatArray from the config

   .. note::

      This class is a subclass of Array and inherits all its attributes
      and methods. The only difference is that the array_type is ConcatArray.


   .. py:property:: attrs
      Return the attributes of the ConcatArray as a dictionary.

      :returns: The attributes of the ConcatArray.
      :rtype: Dict[str, Any]

      :raises AssertionError: If the source arrays have different attributes.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.attrs
      {'axes': 'cxyz', 'roi': Roi(...), 'voxel_size': (1, 1, 1)}

      .. note:: The `source_arrays` are expected to have the same attributes.


   .. py:property:: source_arrays
      :type: Dict[str, dacapo.experiments.datasplits.datasets.arrays.array.Array]

      Return the source arrays of the ConcatArray.

      :returns: The source arrays of the ConcatArray.
      :rtype: Dict[str, Array]

      :raises AssertionError: If the source arrays are empty.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.source_arrays
      {'A': Array(...), 'B': Array(...)}

      .. note:: The `source_arrays` are expected to have the same shape and ROI.


   .. py:property:: source_array
      :type: dacapo.experiments.datasplits.datasets.arrays.array.Array

      Return the source array of the ConcatArray.

      :returns: The source array of the ConcatArray.
      :rtype: Array

      :raises AssertionError: If the source array is None.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.source_array
      Array(...)

      .. note:: The `source_array` is expected to have the same shape and ROI.


   .. py:property:: axes
      Return the axes of the ConcatArray.

      :returns: The axes of the ConcatArray.
      :rtype: str

      :raises AssertionError: If the source arrays have different axes.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.axes
      'cxyz'

      .. note:: The `source_arrays` are expected to have the same axes.


   .. py:property:: dims
      Return the dimensions of the ConcatArray.

      :returns: The dimensions of the ConcatArray.
      :rtype: Tuple[int]

      :raises AssertionError: If the source arrays have different dimensions.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.dims
      (2, 100, 100, 100)

      .. note:: The `source_arrays` are expected to have the same dimensions.


   .. py:property:: voxel_size
      Return the voxel size of the ConcatArray.

      :returns: The voxel size of the ConcatArray.
      :rtype: Tuple[float]

      :raises AssertionError: If the source arrays have different voxel sizes.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.voxel_size
      (1, 1, 1)

      .. note:: The `source_arrays` are expected to have the same voxel size.


   .. py:property:: roi
      Return the ROI of the ConcatArray.

      :returns: The ROI of the ConcatArray.
      :rtype: Roi

      :raises AssertionError: If the source arrays have different ROIs.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.roi
      Roi(...)

      .. note:: The `source_arrays` are expected to have the same ROI.


   .. py:property:: writable
      :type: bool

      Return whether the ConcatArray is writable.

      :returns: Whether the ConcatArray is writable.
      :rtype: bool

      :raises AssertionError: If the ConcatArray is writable.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.writable
      False

      .. note:: The ConcatArray is not writable.


   .. py:property:: data
      Return the data of the ConcatArray.

      :returns: The data of the ConcatArray.
      :rtype: np.ndarray

      :raises RuntimeError: If the ConcatArray is not writable.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.data
      np.ndarray(...)

      .. note:: The ConcatArray is not writable.


   .. py:property:: dtype
      Return the data type of the ConcatArray.

      :returns: The data type of the ConcatArray.
      :rtype: np.dtype

      :raises AssertionError: If the source arrays have different data types.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.dtype
      np.float32

      .. note:: The `source_arrays` are expected to have the same data type.


   .. py:property:: num_channels
      Return the number of channels of the ConcatArray.

      :returns: The number of channels of the ConcatArray.
      :rtype: int

      :raises AssertionError: If the source arrays have different numbers of channels.

      .. rubric:: Examples

      >>> config = ConcatArrayConfig(
      ...     name="my_concat_array",
      ...     channels=["A", "B"],
      ...     source_array_configs={
      ...         "A": ArrayConfig(...),
      ...         "B": ArrayConfig(...),
      ...     },
      ...     default_config=ArrayConfig(...),
      ... )
      >>> array = ConcatArray(config)
      >>> array.num_channels
      2

      .. note:: The `source_arrays` are expected to have the same number of channels.


.. py:class:: ConcatArrayConfig



   This array read data from the source array and then return a np.ones_like() version of the data.

   .. attribute:: channels

      An ordering for the source_arrays.

      :type: List[str]

   .. attribute:: source_array_configs

      A mapping from channels to array_configs. If a channel has no ArrayConfig it will be filled with zeros

      :type: Dict[str, ArrayConfig]

   .. attribute:: default_config

      An optional array providing the default array per channel. If not provided, missing channels will simply be filled with 0s

      :type: Optional[ArrayConfig]

   .. method:: __attrs_post_init__(self)

      This method is called after the instance has been initialized by the constructor. It is used to set the default_config to an instance of ArrayConfig if it is None.

   .. method:: get_array(self, source_arrays

      Dict[str, np.ndarray]) -> np.ndarray: This method reads data from the source array and then return a np.ones_like() version of the data.

   .. note::

      This class is used to create a ConcatArray object which is used to read data from the source array and then return a np.ones_like() version of the data.
      The source array is a dictionary with the key being the channel and the value being the array.


   .. py:attribute:: array_type


   .. py:attribute:: channels
      :type:  List[str]


   .. py:attribute:: source_array_configs
      :type:  Dict[str, dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig]


   .. py:attribute:: default_config
      :type:  Optional[dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig]


.. py:class:: LogicalOrArray(array_config)



   Array that computes the logical OR of the instances in a list of source arrays.

   .. attribute:: name

      str
      The name of the array

   .. attribute:: source_array

      Array
      The source array from which to take the logical OR

   .. method:: axes

      () -> List[str]
      Get the axes of the array

   .. method:: dims

      () -> int
      Get the number of dimensions of the array

   .. method:: voxel_size

      () -> Coordinate
      Get the voxel size of the array

   .. method:: roi

      () -> Roi
      Get the region of interest of the array

   .. method:: writable

      () -> bool
      Get whether the array is writable

   .. method:: dtype

      () -> type
      Get the data type of the array

   .. method:: num_channels

      () -> int
      Get the number of channels in the array

   .. method:: data

      () -> np.ndarray
      Get the data of the array

   .. method:: attrs

      () -> dict
      Get the attributes of the array

   .. method:: __getitem__

      (roi: Roi) -> np.ndarray
      Get the data of the array in the region of interest

   .. method:: _can_neuroglance

      () -> bool
      Get whether the array can be visualized in neuroglance

   .. method:: _neuroglancer_source

      () -> dict
      Get the neuroglancer source of the array

   .. method:: _neuroglancer_layer

      () -> Tuple[neuroglancer.Layer, dict]
      Get the neuroglancer layer of the array

   .. method:: _source_name

      () -> str
      Get the name of the source array

   .. rubric:: Notes

   The LogicalOrArray class is used to create a LogicalOrArray. The LogicalOrArray
   class is a subclass of the Array class.


   .. py:property:: axes
      Get the axes of the array

      :returns: The axes of the array
      :rtype: List[str]

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.axes
      ['x', 'y', 'z']

      .. rubric:: Notes

      The axes method is used to get the axes of the array. The axes are the dimensions
      of the array.


   .. py:property:: dims
      :type: int

      Get the number of dimensions of the array

      :returns: The number of dimensions of the array
      :rtype: int

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.dims
      3

      .. rubric:: Notes

      The dims method is used to get the number of dimensions of the array. The number
      of dimensions is the number of axes of the array.


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      Get the voxel size of the array

      :returns: The voxel size of the array
      :rtype: Coordinate

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.voxel_size
      Coordinate(x=1.0, y=1.0, z=1.0)

      .. rubric:: Notes

      The voxel_size method is used to get the voxel size of the array. The voxel size
      is the size of a voxel in the array.


   .. py:property:: roi
      :type: funlib.geometry.Roi

      Get the region of interest of the array

      :returns: The region of interest of the array
      :rtype: Roi

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.roi
      Roi(offset=(0, 0, 0), shape=(10, 10, 10))

      .. rubric:: Notes

      The roi method is used to get the region of interest of the array. The region of
      interest is the shape and offset of the array.


   .. py:property:: writable
      :type: bool

      Get whether the array is writable

      :returns: Whether the array is writable
      :rtype: bool

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.writable
      False

      .. rubric:: Notes

      The writable method is used to get whether the array is writable. An array is
      writable if it can be modified.


   .. py:property:: dtype
      Get the data type of the array

      :returns: The data type of the array
      :rtype: type

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.dtype
      <class 'numpy.uint8'>

      .. rubric:: Notes

      The dtype method is used to get the data type of the array. The data type is the
      type of the data in the array.


   .. py:property:: num_channels
      Get the number of channels in the array

      :returns: The number of channels in the array
      :rtype: int

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.num_channels
      1

      .. rubric:: Notes

      The num_channels method is used to get the number of channels in the array. The
      number of channels is the number of channels in the array.


   .. py:property:: data
      Get the data of the array

      :returns: The data of the array
      :rtype: np.ndarray

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.data
      array([[[1, 1, 1, ..., 1, 1, 1],
              [1, 1, 1, ..., 1, 1, 1],
              [1, 1, 1, ..., 1, 1, 1],
              ...,
              [1, 1, 1, ..., 1, 1, 1],
              [1, 1, 1, ..., 1, 1, 1],
              [1, 1, 1, ..., 1, 1, 1]]], dtype=uint8)

      .. rubric:: Notes

      The data method is used to get the data of the array. The data is the content of
      the array.


   .. py:property:: attrs
      Get the attributes of the array

      :returns: The attributes of the array
      :rtype: dict

      :raises ValueError: If the array is not writable

      .. rubric:: Examples

      >>> array_config = MergeInstancesArrayConfig(
      ...     name="logical_or",
      ...     source_array_configs=[
      ...         ArrayConfig(
      ...             name="mask1",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask1",
      ...                 mask_id=1,
      ...             ),
      ...         ),
      ...         ArrayConfig(
      ...             name="mask2",
      ...             array_type=MaskArray,
      ...             source_array_config=MaskArrayConfig(
      ...                 name="mask2",
      ...                 mask_id=2,
      ...             ),
      ...         ),
      ...     ],
      ... )
      >>> array = array_config.create_array()
      >>> array.attrs
      {'name': 'logical_or'}

      .. rubric:: Notes

      The attrs method is used to get the attributes of the array. The attributes are
      the metadata of the array.


.. py:class:: LogicalOrArrayConfig



   This config class takes a source array and performs a logical or over the channels.
   Good for union multiple masks.

   .. attribute:: source_array_config

      The Array of masks from which to take the union

      :type: ArrayConfig

   .. method:: to_array

      Returns the LogicalOrArray object

   .. rubric:: Notes

   The source_array_config must be an ArrayConfig object.


   .. py:attribute:: array_type


   .. py:attribute:: source_array_config
      :type:  dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig


.. py:class:: CropArray(array_config)



   Used to crop a larger array to a smaller array. This is useful when you
   want to work with a subset of a larger array, but don't want to copy the
   data. The crop is done on demand, so the data is not copied until you
   actually access it.

   .. attribute:: name

      The name of the array.

   .. attribute:: source_array

      The array to crop.

   .. attribute:: crop_roi

      The region of interest to crop to.

   .. method:: attrs

      Returns the attributes of the source array.

   .. method:: axes

      Returns the axes of the source array.

   .. method:: dims

      Returns the number of dimensions of the source array.

   .. method:: voxel_size

      Returns the voxel size of the source array.

   .. method:: roi

      Returns the region of interest of the source array.

   .. method:: writable

      Returns whether the array is writable.

   .. method:: dtype

      Returns the data type of the source array.

   .. method:: num_channels

      Returns the number of channels of the source array.

   .. method:: data

      Returns the data of the source array.

   .. method:: channels

      Returns the channels of the source array.

   .. method:: __getitem__(roi)

      Returns the data of the source array within the
      region of interest.

   .. method:: _can_neuroglance()

      Returns whether the source array can be viewed in
      Neuroglancer.

   .. method:: _neuroglancer_source()

      Returns the source of the source array for
      Neuroglancer.

   .. method:: _neuroglancer_layer()

      Returns the layer of the source array for
      Neuroglancer.

   .. method:: _source_name()

      Returns the name of the source array.

   .. note:: This class is a subclass of Array.


   .. py:property:: attrs
      Returns the attributes of the source array.

      :returns: The attributes of the source array.

      :raises ValueError: If the region of interest to crop to is not within the

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.attrs
      {}

      .. note:: The attributes are empty because the source array is not modified.


   .. py:property:: axes
      Returns the axes of the source array.

      :returns: The axes of the source array.

      :raises ValueError: If the region of interest to crop to is not within the

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.axes
      'zyx'

      .. note:: The axes are 'zyx' because the source array is not modified.


   .. py:property:: dims
      :type: int

      Returns the number of dimensions of the source array.

      :returns: The number of dimensions of the source array.

      :raises ValueError: If the region of interest to crop to is not within the
          region of interest of the source array.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.dims
      3

      .. note::

         The number of dimensions is 3 because the source array is not
         modified.


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      Returns the voxel size of the source array.

      :returns: The voxel size of the source array.

      :raises ValueError: If the region of interest to crop to is not within the
          region of interest of the source array.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.voxel_size
      Coordinate(x=1.0, y=1.0, z=1.0)

      .. note::

         The voxel size is (1.0, 1.0, 1.0) because the source array is not
         modified.


   .. py:property:: roi
      :type: funlib.geometry.Roi

      Returns the region of interest of the source array.

      :returns: The region of interest of the source array.

      :raises ValueError: If the region of interest to crop to is not within the
          region of interest of the source array.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.roi
      Roi(offset=(0, 0, 0), shape=(10, 10, 10))

      .. note::

         The region of interest is (0, 0, 0) with shape (10, 10, 10)
         because the source array is not modified.


   .. py:property:: writable
      :type: bool

      Returns whether the array is writable.

      :returns: False

      :raises ValueError: If the region of interest to crop to is not within the
          region of interest of the source array.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.writable
      False

      .. note::

         The array is not writable because it is a virtual array created by
         modifying another array on demand.


   .. py:property:: dtype
      Returns the data type of the source array.

      :returns: The data type of the source array.

      :raises ValueError: If the region of interest to crop to is not within the
          region of interest of the source array.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.dtype
      numpy.dtype('uint8')

      .. note:: The data type is uint8 because the source array is not modified.


   .. py:property:: num_channels
      :type: int

      Returns the number of channels of the source array.

      :returns: The number of channels of the source array.

      :raises ValueError: If the region of interest to crop to is not within the
          region of interest of the source array.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.num_channels
      1

      .. note::

         The number of channels is 1 because the source array is not
         modified.


   .. py:property:: data
      Returns the data of the source array.

      :returns: The data of the source array.

      :raises ValueError: If the region of interest to crop to is not within the
          region of interest of the source array.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.data
      array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],
             [[0, 0, 0, 0, 0, 0, 0, 0, 0


   .. py:property:: channels
      Returns the channels of the source array.

      :returns: The channels of the source array.

      :raises ValueError: If the region of interest to crop to is not within the
          region of interest of the source array.

      .. rubric:: Examples

      >>> from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      >>> from dacapo.experiments.datasplits.datasets.arrays import CropArray
      >>> from funlib.geometry import Roi
      >>> import numpy as np
      >>> array_config = ArrayConfig(
      ...     name='array',
      ...     source_array_config=source_array_config,
      ...     roi=Roi((0, 0, 0), (10, 10, 10))
      ... )
      >>> crop_array = CropArray(array_config)
      >>> crop_array.channels
      1

      .. note:: The channels is 1 because the source array is not modified.


.. py:class:: CropArrayConfig



   This config class provides the necessary configuration for cropping an
   Array to a smaller ROI. Especially useful for validation volumes that may
   be too large for quick evaluation. The ROI is specified in the config. The
   cropped Array will have the same dtype as the source Array.

   .. attribute:: source_array_config

      The Array to crop

      :type: ArrayConfig

   .. attribute:: roi

      The ROI for cropping

      :type: Roi

   .. method:: from_toml(cls, toml_path

      str) -> CropArrayConfig:
      Load the CropArrayConfig from a TOML file

   .. method:: to_toml(self, toml_path

      str) -> None:
      Save the CropArrayConfig to a TOML file

   .. method:: create_array(self) -> CropArray

      
      Create the CropArray from the config

   .. note::

      This class is a subclass of ArrayConfig and inherits all its attributes
      and methods. The only difference is that the array_type is CropArray.


   .. py:attribute:: array_type


   .. py:attribute:: source_array_config
      :type:  dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig


   .. py:attribute:: roi
      :type:  funlib.geometry.Roi


.. py:class:: MergeInstancesArray(array_config)



   This array merges multiple source arrays into a single array by summing them. This is useful for merging
   instance segmentation arrays into a single array. NeuoGlancer will display each instance as a different color.

   .. attribute:: name

      str
      The name of the array

   .. attribute:: source_array_configs

      List[ArrayConfig]
      A list of source arrays to merge

   .. method:: __getitem__(roi

      Roi) -> np.ndarray
      Returns a numpy array with the requested region of interest

   .. method:: _can_neuroglance() -> bool

      
      Returns True if the array can be visualized in neuroglancer

   .. method:: _neuroglancer_source() -> str

      
      Returns the source name for the array in neuroglancer

   .. method:: _neuroglancer_layer() -> Tuple[neuroglancer.SegmentationLayer, Dict[str, Any]]

      
      Returns a neuroglancer layer and its configuration

   .. method:: _source_name() -> str

      
      Returns the source name for the array

   .. note::

      This array is not writable
      Source arrays must have the same shape.


   .. py:property:: axes
      Returns the axes of the array

      :returns: The axes of the array
      :rtype: List[str]

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      axes = array.axes
      ```

      .. note:: This example shows how to get the axes of the array


   .. py:property:: dims
      :type: int

      Returns the number of dimensions of the array

      :returns: The number of dimensions of the array
      :rtype: int

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      dims = array.dims
      ```

      .. note:: This example shows how to get the number of dimensions of the array


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      Returns the voxel size of the array

      :returns: The voxel size of the array
      :rtype: Coordinate

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      voxel_size = array.voxel_size
      ```

      .. note:: This example shows how to get the voxel size of the array


   .. py:property:: roi
      :type: funlib.geometry.Roi

      Returns the region of interest of the array

      :returns: The region of interest of the array
      :rtype: Roi

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      roi = array.roi
      ```

      .. note:: This example shows how to get the region of interest of the array


   .. py:property:: writable
      :type: bool

      Returns True if the array is writable, False otherwise

      :returns: True if the array is writable, False otherwise
      :rtype: bool

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      writable = array.writable
      ```

      .. note:: This example shows how to check if the array is writable


   .. py:property:: dtype
      Returns the data type of the array

      :returns: The data type of the array
      :rtype: np.dtype

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      dtype = array.dtype
      ```

      .. note:: This example shows how to get the data type of the array


   .. py:property:: num_channels
      Returns the number of channels of the array

      :returns: The number of channels of the array
      :rtype: int

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      num_channels = array.num_channels
      ```

      .. note:: This example shows how to get the number of channels of the array


   .. py:property:: data
      Returns the data of the array

      :returns: The data of the array
      :rtype: np.ndarray

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      data = array.data
      ```

      .. note:: This example shows how to get the data of the array


   .. py:property:: attrs
      Returns the attributes of the array

      :returns: The attributes of the array
      :rtype: Dict[str, Any]

      :raises ValueError: If the source arrays have different shapes

      .. rubric:: Example

      ```python
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArray
      from dacapo.experiments.datasplits.datasets.arrays import MergeInstancesArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayConfig
      from dacapo.experiments.datasplits.datasets.arrays import ArrayType
      from funlib.geometry import Coordinate, Roi
      array_config = MergeInstancesArrayConfig(
          name="array",
          source_array_configs=[
              ArrayConfig(
                  name="array1",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array1.h5",
              ),
              ArrayConfig(
                  name="array2",
                  array_type=ArrayType.INSTANCE_SEGMENTATION,
                  path="path/to/array2.h5",
              ),
          ],
      )
      array = MergeInstancesArray(array_config)
      attributes = array.attrs
      ```

      .. note:: This example shows how to get the attributes of the array


.. py:class:: MergeInstancesArrayConfig



   Configuration for an array that merges instances from multiple arrays
   into a single array. The instances are merged by taking the union of the
   instances in the source arrays.

   .. attribute:: source_array_configs

      List[ArrayConfig]
      The Array of masks from which to take the union

   .. method:: create_array

      () -> MergeInstancesArray
      Create a MergeInstancesArray instance from the configuration

   .. rubric:: Notes

   The MergeInstancesArrayConfig class is used to create a MergeInstancesArray


   .. py:attribute:: array_type


   .. py:attribute:: source_array_configs
      :type:  List[dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig]


.. py:class:: DVIDArray(array_config)



   This is a DVID array. It is a wrapper around a DVID array that provides
   the necessary methods to interact with the array. It is used to fetch data
   from a DVID server. The source is a tuple of three strings: the server, the UUID,
   and the data name.

   DVID: data management system for terabyte-sized 3D images

   .. attribute:: name

      The name of the array

      :type: str

   .. attribute:: source

      The source of the array

      :type: tuple[str, str, str]

   .. method:: __getitem__

      Returns the data from the array for a given region of interest

   .. rubric:: Notes

   The source is a tuple of three strings: the server, the UUID, and the data name.


   .. py:method:: attrs()

      Returns the attributes of the DVID array

      :returns: The attributes of the DVID array
      :rtype: dict

      :raises ValueError: If the attributes is not a dictionary

      .. rubric:: Examples

      >>> dvid_array.attrs
      {'Extended': {'VoxelSize': (1.0, 1.0, 1.0), 'Values': [{'DataType': 'uint64'}]}, 'Extents': {'MinPoint': (0, 0, 0), 'MaxPoint': (100, 100, 100)}}

      .. rubric:: Notes

      The attributes are the same as the source array



   .. py:property:: axes
      Returns the axes of the DVID array

      :returns: The axes of the DVID array
      :rtype: str

      :raises ValueError: If the axes is not a string

      .. rubric:: Examples

      >>> dvid_array.axes
      'zyx'

      .. rubric:: Notes

      The axes are the same as the source array


   .. py:property:: dims
      :type: int

      Returns the dimensions of the DVID array

      :returns: The dimensions of the DVID array
      :rtype: int

      :raises ValueError: If the dimensions is not an integer

      .. rubric:: Examples

      >>> dvid_array.dims
      3

      .. rubric:: Notes

      The dimensions are the same as the source array


   .. py:method:: voxel_size() -> funlib.geometry.Coordinate

      Returns the voxel size of the DVID array

      :returns: The voxel size of the DVID array
      :rtype: Coordinate

      :raises ValueError: If the voxel size is not a Coordinate object

      .. rubric:: Examples

      >>> dvid_array.voxel_size
      Coordinate(x=1.0, y=1.0, z=1.0)

      .. rubric:: Notes

      The voxel size is the same as the source array



   .. py:method:: roi() -> funlib.geometry.Roi

      Returns the region of interest of the DVID array

      :returns: The region of interest of the DVID array
      :rtype: Roi

      :raises ValueError: If the region of interest is not a Roi object

      .. rubric:: Examples

      >>> dvid_array.roi
      Roi(...)

      .. rubric:: Notes

      The region of interest is the same as the source array



   .. py:property:: writable
      :type: bool

      Returns whether the DVID array is writable

      :returns: Whether the DVID array is writable
      :rtype: bool

      :raises ValueError: If the writable is not a boolean

      .. rubric:: Examples

      >>> dvid_array.writable
      False

      .. rubric:: Notes

      The writable is the same as the source array


   .. py:property:: dtype
      :type: Any

      Returns the data type of the DVID array

      :returns: The data type of the DVID array
      :rtype: type

      :raises ValueError: If the data type is not a type

      .. rubric:: Examples

      >>> dvid_array.dtype
      numpy.uint64

      .. rubric:: Notes

      The data type is the same as the source array


   .. py:property:: num_channels
      :type: Optional[int]

      Returns the number of channels of the DVID array

      :returns: The number of channels of the DVID array
      :rtype: int

      :raises ValueError: If the number of channels is not an integer

      .. rubric:: Examples

      >>> dvid_array.num_channels
      1

      .. rubric:: Notes

      The number of channels is the same as the source array


   .. py:property:: spatial_axes
      :type: List[str]

      Returns the spatial axes of the DVID array

      :returns: The spatial axes of the DVID array
      :rtype: List[str]

      :raises ValueError: If the spatial axes is not a list

      .. rubric:: Examples

      >>> dvid_array.spatial_axes
      ['z', 'y', 'x']

      .. rubric:: Notes

      The spatial axes are the same as the source array


   .. py:property:: data
      :type: Any

      :abstractmethod:

      Returns the number of channels of the DVID array

      :returns: The number of channels of the DVID array
      :rtype: int

      :raises ValueError: If the number of channels is not an integer

      .. rubric:: Examples

      >>> dvid_array.num_channels
      1

      .. rubric:: Notes

      The number of channels is the same as the source array


   .. py:method:: add_metadata(metadata: Dict[str, Any]) -> None
      :abstractmethod:


      Adds metadata to the DVID array

      :param metadata: The metadata to add to the DVID array
      :type metadata: dict

      :returns: None

      :raises ValueError: If the metadata is not a dictionary

      .. rubric:: Examples

      >>> dvid_array.add_metadata({'description': 'This is a DVID array'})

      .. rubric:: Notes

      The metadata is added to the source array



.. py:class:: DVIDArrayConfig



   This config class provides the necessary configuration for a DVID array. It takes a source string and returns the DVIDArray object.

   .. attribute:: source

      The source strings

      :type: Tuple[str, str, str]

   .. method:: to_array

      Returns the DVIDArray object

   .. rubric:: Notes

   The source must be a tuple of strings.


   .. py:attribute:: array_type


   .. py:attribute:: source
      :type:  Tuple[str, str, str]


   .. py:method:: verify() -> Tuple[bool, str]

      Check whether this is a valid Array

      :returns: Whether the Array is valid and a message
      :rtype: Tuple[bool, str]

      :raises ValueError: If the source is not a tuple of strings

      .. rubric:: Examples

      >>> dvid_array_config = DVIDArrayConfig(...)
      >>> dvid_array_config.verify()
      (True, "No validation for this Array")

      .. rubric:: Notes

      The source must be a tuple of strings.



.. py:class:: SumArray(array_config)



   This class provides a sum array. This array is a virtual array that is created by summing
   multiple source arrays. The source arrays must have the same shape and ROI.

   .. attribute:: name

      str
      The name of the array.

   .. attribute:: _source_arrays

      List[Array]
      The source arrays to sum.

   .. attribute:: _source_array

      Array
      The first source array.

   .. method:: __getitem__(roi

      Roi) -> np.ndarray
      Get the data for the given region of interest.

   .. method:: _can_neuroglance() -> bool

      
      Check if neuroglance can be used.

   .. method:: _neuroglancer_source() -> Dict

      
      Return the source for neuroglance.

   .. method:: _neuroglancer_layer() -> Tuple[neuroglancer.SegmentationLayer, Dict]

      
      Return the neuroglancer layer.

   .. method:: _source_name() -> str

      
      Return the source name.

   .. note:: This class is a subclass of Array.


   .. py:property:: axes
      The axes of the array.

      :returns: The axes of the array.
      :rtype: List[str]

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.axes
      ['x', 'y', 'z']

      .. note:: This class is a subclass of Array.


   .. py:property:: dims
      :type: int

      The number of dimensions of the array.

      :returns: The number of dimensions of the array.
      :rtype: int

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.dims
      3

      .. note:: This class is a subclass of Array.


   .. py:property:: voxel_size
      :type: funlib.geometry.Coordinate

      The size of each voxel in each dimension.

      :returns: The size of each voxel in each dimension.
      :rtype: Coordinate

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.voxel_size
      Coordinate([1, 1, 1])

      .. note:: This class is a subclass of Array.


   .. py:property:: roi
      :type: funlib.geometry.Roi

      The region of interest of the array.

      :param roi: Roi
                  The region of interest.

      :returns: The region of interest.
      :rtype: Roi

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.roi
      Roi(Coordinate([0, 0, 0]), Coordinate([100, 100, 100]))

      .. note:: This class is a subclass of Array.


   .. py:property:: writable
      :type: bool

      Check if the array is writable.

      :param writable: bool
                       Check if the array is writable.

      :returns: True if the array is writable, otherwise False.
      :rtype: bool

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.writable
      False

      .. note:: This class is a subclass of Array.


   .. py:property:: dtype
      The data type of the array.

      :param dtype: np.uint8
                    The data type of the array.

      :returns: The data type of the array.
      :rtype: np.uint8

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.dtype
      np.uint8

      .. note:: This class is a subclass of Array.


   .. py:property:: num_channels
      The number of channels in the array.

      :param num_channels: Optional[int]
                           The number of channels in the array.

      :returns: The number of channels in the array.
      :rtype: Optional[int]

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.num_channels
      None

      .. note:: This class is a subclass of Array.


   .. py:property:: data
      Get the data of the array.

      :param data: np.ndarray
                   The data of the array.

      :returns: The data of the array.
      :rtype: np.ndarray

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.data
      np.array([[[0, 0], [0, 0]], [[0, 0], [0, 0]]])

      .. note:: This class is a subclass of Array.


   .. py:property:: attrs
      Return the attributes of the array.

      :param attrs: Dict
                    The attributes of the array.

      :returns: The attributes of the array.
      :rtype: Dict

      :raises ValueError: Cannot get a writable view of this array because it is a virtual array created by modifying another array on demand.

      .. rubric:: Examples

      >>> sum_array.attrs
      {}

      .. note:: This class is a subclass of Array.


.. py:class:: SumArrayConfig



   This config class provides the necessary configuration for a sum
   array.

   .. attribute:: source_array_configs

      List[ArrayConfig]
      The Array of masks from which to take the union

   .. note:: This class is a subclass of ArrayConfig.


   .. py:attribute:: array_type


   .. py:attribute:: source_array_configs
      :type:  List[dacapo.experiments.datasplits.datasets.arrays.array_config.ArrayConfig]


.. py:class:: NumpyArray(array_config)



   This is just a wrapper for a numpy array to make it fit the DaCapo Array interface.

   .. attribute:: data

      The numpy array.

   .. attribute:: dtype

      The data type of the numpy array.

   .. attribute:: roi

      The region of interest of the numpy array.

   .. attribute:: voxel_size

      The voxel size of the numpy array.

   .. attribute:: axes

      The axes of the numpy array.

   .. method:: from_gp_array

      Create a NumpyArray from a Gunpowder Array.

   .. method:: from_np_array

      Create a NumpyArray from a numpy array.

   .. note:: This class is a subclass of Array.


   .. py:property:: attrs
      Returns the attributes of the array.

      :returns: The attributes of the array.
      :rtype: dict

      :raises ValueError: If the array does not have attributes.

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.attrs
      {}

      .. note:: This method is a property. It returns the attributes of the array.


   .. py:method:: from_gp_array(array: gunpowder.Array)
      :classmethod:


      Create a NumpyArray from a Gunpowder Array.

      :param array: The Gunpowder Array.
      :type array: gp.Array

      :returns: The NumpyArray.
      :rtype: NumpyArray

      :raises ValueError: If the array does not have a data type.

      .. rubric:: Examples

      >>> array = gp.Array(data=np.zeros((2, 3, 4)), spec=gp.ArraySpec(roi=Roi((0, 0, 0), (2, 3, 4)), voxel_size=Coordinate((1, 1, 1))))
      >>> array = NumpyArray.from_gp_array(array)
      >>> array.data
      array([[[0., 0., 0., 0.],
              [0., 0., 0., 0.],
              [0., 0., 0., 0.]],
      <BLANKLINE>
                  [[0., 0., 0., 0.],
                  [0., 0., 0., 0.],
                  [0., 0., 0., 0.]]])

      .. note:: This method creates a NumpyArray from a Gunpowder Array.



   .. py:method:: from_np_array(array: numpy.ndarray, roi, voxel_size, axes)
      :classmethod:


      Create a NumpyArray from a numpy array.

      :param array: The numpy array.
      :type array: np.ndarray
      :param roi: The region of interest of the array.
      :type roi: Roi
      :param voxel_size: The voxel size of the array.
      :type voxel_size: Coordinate
      :param axes: The axes of the array.
      :type axes: List[str]

      :returns: The NumpyArray.
      :rtype: NumpyArray

      :raises ValueError: If the array does not have a data type.

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.data
      array([[[0., 0., 0., 0.],
              [0., 0., 0., 0.],
              [0., 0., 0., 0.]],
      <BLANKLINE>
               [[0., 0., 0., 0.],
                [0., 0., 0., 0.],
                [0., 0., 0., 0.]]])

      .. note:: This method creates a NumpyArray from a numpy array.



   .. py:property:: axes
      Returns the axes of the array.

      :returns: The axes of the array.
      :rtype: List[str]

      :raises ValueError: If the array does not have axes.

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.axes
      ['z', 'y', 'x']

      .. note:: This method is a property. It returns the axes of the array.


   .. py:property:: dims
      Returns the number of dimensions of the array.

      :returns: The number of dimensions of the array.
      :rtype: int

      :raises ValueError: If the array does not have a dimension.

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.dims
      3

      .. note:: This method is a property. It returns the number of dimensions of the array.


   .. py:property:: voxel_size
      Returns the voxel size of the array.

      :returns: The voxel size of the array.
      :rtype: Coordinate

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.voxel_size
      Coordinate((1, 1, 1))

      .. note:: This method is a property. It returns the voxel size of the array.


   .. py:property:: roi
      Returns the region of interest of the array.

      :returns: The region of interest of the array.
      :rtype: Roi

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.roi
      Roi((0, 0, 0), (2, 3, 4))

      .. note:: This method is a property. It returns the region of interest of the array.


   .. py:property:: writable
      :type: bool

      Returns whether the array is writable.

      :returns: Whether the array is writable.
      :rtype: bool

      :raises ValueError: If the array is not writable.

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.writable
      True

      .. note:: This method is a property. It returns whether the array is writable.


   .. py:property:: data
      Returns the numpy array.

      :returns: The numpy array.
      :rtype: np.ndarray

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.data
      array([[[0., 0., 0., 0.],
              [0., 0., 0., 0.],
              [0., 0., 0., 0.]],
      <BLANKLINE>
             [[0., 0., 0., 0.],
              [0., 0., 0., 0.],
              [0., 0., 0., 0.]]])

      .. note:: This method is a property. It returns the numpy array.


   .. py:property:: dtype
      Returns the data type of the array.

      :returns: The data type of the array.
      :rtype: np.dtype

      :raises ValueError: If the array does not have a data type.

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.dtype
      dtype('float64')

      .. note:: This method is a property. It returns the data type of the array.


   .. py:property:: num_channels
      Returns the number of channels in the array.

      :returns: The number of channels in the array.
      :rtype: int

      :raises ValueError: If the array does not have a channel dimension.

      .. rubric:: Examples

      >>> array = NumpyArray.from_np_array(np.zeros((1, 2, 3, 4)), Roi((0, 0, 0), (1, 2, 3)), Coordinate((1, 1, 1)), ["b", "c", "z", "y", "x"])
      >>> array.num_channels
      1
      >>> array = NumpyArray.from_np_array(np.zeros((2, 3, 4)), Roi((0, 0, 0), (2, 3, 4)), Coordinate((1, 1, 1)), ["z", "y", "x"])
      >>> array.num_channels
      Traceback (most recent call last):
      ...
      ValueError: Array does not have a channel dimension.

      .. note:: This method is a property. It returns the number of channels in the array.


.. py:class:: GraphStoreConfig

   Base class for graph store configurations. Each subclass of a
   `GraphStore` should have a corresponding config class derived from
   `GraphStoreConfig`.

   .. attribute:: store_type

      The type of graph store that is being configured.

      :type: class

   .. method:: verify

      A method to verify the validity of the configuration.

   .. rubric:: Notes

   This class is used to create a configuration object for the graph store.


.. py:class:: Task



   Helper class that provides a standard way to create an ABC using
   inheritance.


   .. py:attribute:: predictor
      :type:  dacapo.experiments.tasks.predictors.Predictor


   .. py:attribute:: loss
      :type:  dacapo.experiments.tasks.losses.Loss


   .. py:attribute:: evaluator
      :type:  dacapo.experiments.tasks.evaluators.Evaluator


   .. py:attribute:: post_processor
      :type:  dacapo.experiments.tasks.post_processors.PostProcessor


   .. py:property:: parameters
      :type: Iterable[dacapo.experiments.tasks.post_processors.PostProcessorParameters]



   .. py:property:: evaluation_scores
      :type: dacapo.experiments.tasks.evaluators.EvaluationScores



   .. py:method:: create_model(architecture)


.. py:class:: TaskConfig

   Base class for task configurations. Each subclass of a `Task` should
   have a corresponding config class derived from `TaskConfig`.

   .. attribute:: name

      A unique name for this task. This will be saved so you and
      others can find and reuse this task. Keep it short and avoid
      special characters.

   .. method:: verify(self) -> Tuple[bool, str]

      This method verifies the TaskConfig object.

   .. rubric:: Notes

   This is a base class for all task configurations. It is not meant to be
   used directly.


   .. py:attribute:: name
      :type:  str


   .. py:method:: verify() -> Tuple[bool, str]

      Check whether this is a valid Task

      :returns:

                A tuple containing a boolean value indicating whether the TaskConfig object is valid
                    and a string containing the reason why the object is invalid.
      :rtype: Tuple[bool, str]

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> valid, reason = task_config.verify()



.. py:class:: DummyTaskConfig



   A class for creating a dummy task configuration object.

   This class extends the TaskConfig class and initializes dummy task configuration
   with default attributes. It is mainly used for testing aspects
   of the application without the need of creating real task configurations.

   .. attribute:: task_type

      The type of task. Here, set to DummyTask.

      :type: cls

   .. attribute:: embedding_dims

      A dummy attribute represented as an integer.

      :type: int

   .. attribute:: detection_threshold

      Another dummy attribute represented as a float.

      :type: float

   .. method:: verify(self) -> Tuple[bool, str]

      This method verifies the DummyTaskConfig object.

   .. note:: This is a subclass of TaskConfig.


   .. py:attribute:: task_type


   .. py:attribute:: embedding_dims
      :type:  int


   .. py:attribute:: detection_threshold
      :type:  float


   .. py:method:: verify() -> Tuple[bool, str]

      A method to verify the dummy task configuration.

      Whenever called, this method always returns False and a statement showing
      that the DummyTaskConfig object is never valid.

      :returns: A tuple containing a boolean status and a string message.
      :rtype: tuple

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> valid, reason = task_config.verify()



.. py:class:: DummyTask(task_config)



   A dummy task class that initializes all components (predictor, loss,
   post-processing, and evaluator) for the dummy task. Primarily used for testing purposes.
   Inherits from the Task class.

   .. attribute:: predictor

      Object
      Instance of DummyPredictor class.

   .. attribute:: loss

      Object
      Instance of DummyLoss class.

   .. attribute:: post_processor

      Object
      Instance of DummyPostProcessor class.

   .. attribute:: evaluator

      Object
      Instance of DummyEvaluator class.

   .. method:: __init__(self, task_config)

      
      Initializes all components for the dummy task.

   .. rubric:: Notes

   This is a subclass of Task.


.. py:class:: DistanceTaskConfig



   This is a Distance task config used for generating and
   evaluating signed distance transforms as a way of generating
   segmentations.

   The advantage of generating distance transforms over regular
   affinities is you can get a denser signal, i.e. 1 misclassified
   pixel in an affinity prediction could merge 2 otherwise very
   distinct objects, this cannot happen with distances.

   .. attribute:: channels

      A list of channel names.

   .. attribute:: clip_distance

      Maximum distance to consider for false positive/negatives.

   .. attribute:: tol_distance

      Tolerance distance for counting false positives/negatives

   .. attribute:: scale_factor

      The amount by which to scale distances before applying a tanh normalization.

   .. attribute:: mask_distances

      Whether or not to mask out regions where the true distance to
      object boundary cannot be known. This is anywhere that the distance to crop boundary
      is less than the distance to object boundary.

   .. attribute:: clipmin

      The minimum value for distance weights.

   .. attribute:: clipmax

      The maximum value for distance weights.

   .. method:: verify(self) -> Tuple[bool, str]

      This method verifies the DistanceTaskConfig object.

   .. rubric:: Notes

   This is a subclass of TaskConfig.


   .. py:attribute:: task_type


   .. py:attribute:: channels
      :type:  List[str]


   .. py:attribute:: clip_distance
      :type:  float


   .. py:attribute:: tol_distance
      :type:  float


   .. py:attribute:: scale_factor
      :type:  float


   .. py:attribute:: mask_distances
      :type:  bool


   .. py:attribute:: clipmin
      :type:  float


   .. py:attribute:: clipmax
      :type:  float


.. py:class:: DistanceTask(task_config)



   DistanceTask is a subclass of Task for handling tasks associated
   with Distance.

   DistanceTask uses `DistancePredictor` for prediction, `MSELoss` for
   computing loss, `ThresholdPostProcessor` for post-processing the
   prediction, and `BinarySegmentationEvaluator` for evaluating the
   prediction.

   .. attribute:: predictor

      DistancePredictor object

   .. attribute:: loss

      MSELoss object

   .. attribute:: post_processor

      ThresholdPostProcessor object

   .. attribute:: evaluator

      BinarySegmentationEvaluator object

   .. method:: __init__(self, task_config)

      Initializes attributes of DistanceTask

   .. rubric:: Notes

   This is a subclass of Task.


.. py:class:: OneHotTaskConfig



   Class that derives from the TaskConfig to perform one hot prediction tasks.

   .. attribute:: task_type

      the type of task, in this case, OneHotTask.

   .. attribute:: classes

      a List of classes which starts from id 0.

   .. method:: None

      
      

   .. note:: The class of each voxel is simply the argmax over the vector of output probabilities.


   .. py:attribute:: task_type


   .. py:attribute:: classes
      :type:  List[str]


.. py:class:: OneHotTask(task_config)



   A task that uses a one-hot predictor. The model is loaded from a file
   and the weights are loaded from a file. The loss is a dummy loss and the
   post processor is an argmax post processor. The evaluator is a dummy evaluator.

   .. attribute:: weights

      The path to the weights file.

      :type: Path

   .. method:: create_model(self, architecture) -> Model

      This method creates a model using the given architecture.

   .. rubric:: Notes

   This is a base class for all tasks that use one-hot predictors.


.. py:class:: PretrainedTaskConfig



   Configuration for a task that uses a pretrained model. The model is loaded from a file
   and the weights are loaded from a file.

   .. attribute:: sub_task_config

      The task to run starting with the provided pretrained weights.

      :type: TaskConfig

   .. attribute:: weights

      A checkpoint containing pretrained model weights.

      :type: Path

   .. method:: verify(self) -> Tuple[bool, str]

      This method verifies the PretrainedTaskConfig object.

   .. rubric:: Notes

   This is a subclass of TaskConfig.


   .. py:attribute:: task_type


   .. py:attribute:: sub_task_config
      :type:  dacapo.experiments.tasks.task_config.TaskConfig


   .. py:attribute:: weights
      :type:  upath.UPath


.. py:class:: PretrainedTask(task_config)



   A task that uses a pretrained model. The model is loaded from a file
   and the weights are loaded from a file.

   .. attribute:: weights

      The path to the weights file.

      :type: Path

   .. method:: create_model(self, architecture) -> Model

      This method creates a model using the given architecture.

   .. rubric:: Notes

   This is a base class for all tasks that use pretrained models.


   .. py:method:: create_model(architecture)

      Create a model using the given architecture.

      :param architecture: The architecture of the model.
      :type architecture: str

      :returns: The model created using the given architecture.
      :rtype: Model

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> model = task.create_model(architecture)



.. py:class:: AffinitiesTaskConfig



   This is a Affinities task config used for generating and
   evaluating voxel affinities for instance segmentations.

   .. attribute:: neighborhood

      A list of Coordinate objects.

   .. attribute:: lsds

      Whether or not to train lsds along with your affinities.

   .. attribute:: lsds_to_affs_weight_ratio

      If training with lsds, set how much they should be weighted compared to affs.

   .. attribute:: affs_weight_clipmin

      The minimum value for affinities weights.

   .. attribute:: affs_weight_clipmax

      The maximum value for affinities weights.

   .. attribute:: lsd_weight_clipmin

      The minimum value for lsds weights.

   .. attribute:: lsd_weight_clipmax

      The maximum value for lsds weights.

   .. attribute:: background_as_object

      Whether to treat the background as a separate object.

   .. method:: verify(self) -> Tuple[bool, str]

      This method verifies the AffinitiesTaskConfig

   .. rubric:: Notes

   This is a subclass of TaskConfig.


   .. py:attribute:: task_type


   .. py:attribute:: neighborhood
      :type:  List[funlib.geometry.Coordinate]


   .. py:attribute:: lsds
      :type:  bool


   .. py:attribute:: lsds_to_affs_weight_ratio
      :type:  float


   .. py:attribute:: affs_weight_clipmin
      :type:  float


   .. py:attribute:: affs_weight_clipmax
      :type:  float


   .. py:attribute:: lsd_weight_clipmin
      :type:  float


   .. py:attribute:: lsd_weight_clipmax
      :type:  float


   .. py:attribute:: background_as_object
      :type:  bool


.. py:class:: AffinitiesTask(task_config)



   This is a task for generating voxel affinities. It uses an `AffinitiesPredictor` for prediction,
   an `AffinitiesLoss` for loss calculation, a `WatershedPostProcessor` for post-processing, and an
   `InstanceEvaluator` for evaluation.

   .. attribute:: predictor

      AffinitiesPredictor object

   .. attribute:: loss

      AffinitiesLoss object

   .. attribute:: post_processor

      WatershedPostProcessor object

   .. attribute:: evaluator

      InstanceEvaluator object

   .. method:: __init__(self, task_config)

      Initializes all components for the affinities task.

   .. rubric:: Notes

   This is a subclass of Task.


.. py:class:: InnerDistanceTaskConfig



   This is a Distance task config used for generating and
   evaluating signed distance transforms as a way of generating
   segmentations.

   The advantage of generating distance transforms over regular
   affinities is you can get a denser signal, i.e. 1 misclassified
   pixel in an affinity prediction could merge 2 otherwise very
   distinct objects, this cannot happen with distances.

   .. attribute:: channels

      A list of channel names.

   .. attribute:: clip_distance

      Maximum distance to consider for false positive/negatives.

   .. attribute:: tol_distance

      Tolerance distance for counting false positives/negatives

   .. attribute:: scale_factor

      The amount by which to scale distances before applying a tanh normalization.

   .. rubric:: Notes

   This is a subclass of TaskConfig.


   .. py:attribute:: task_type


   .. py:attribute:: channels
      :type:  List[str]


   .. py:attribute:: clip_distance
      :type:  float


   .. py:attribute:: tol_distance
      :type:  float


   .. py:attribute:: scale_factor
      :type:  float


.. py:class:: InnerDistanceTask(task_config)



   This class extends the Task class for creating tasks related to computing inner distances.
   It provides methods for prediction, loss calculation and post-processing. It includes Binary Segmentation Evaluator for evaluation.

   .. attribute:: task_config

      The configuration for the task.

   .. attribute:: predictor

      Used for predicting the inner distances.

   .. attribute:: loss

      Used for calculating the mean square error loss.

   .. attribute:: post_processor

      Used for applying threshold post-processing.

   .. attribute:: evaluator

      Used for evaluating the results using binary segmentation.

   .. method:: __init__(self, task_config)

      Initializes an instance of InnerDistanceTask.

   .. rubric:: Notes

   This is a subclass of Task.


.. py:class:: HotDistanceTaskConfig



   Class for generating TaskConfigs for the HotDistanceTask, which predicts one hot encodings of classes, as well as signed distance transforms of those classes.

   .. attribute:: task_type

      A reference to the Hot Distance Task class.

   .. attribute:: channels

      A list of channel names.

      :type: List[str]

   .. attribute:: clip_distance

      Maximum distance to consider for false positive/negatives.

      :type: float

   .. attribute:: tol_distance

      Tolerance distance for counting false positives/negatives.

      :type: float

   .. attribute:: scale_factor

      The amount by which to scale distances before applying
      a tanh normalization. Defaults to 1.

      :type: float

   .. attribute:: mask_distances

      Whether or not to mask out regions where the true distance to
      object boundary cannot be known. Defaults to False

      :type: bool

   .. method:: verify(self) -> Tuple[bool, str]

      This method verifies the HotDistanceTaskConfig object.

   .. note::

      Generating distance transforms over regular affinities provides you with a denser
      signal, i.e., one misclassified pixel in an affinity prediction can merge 2
      otherwise very distinct objects, a situation that cannot happen with distances.


   .. py:attribute:: task_type


   .. py:attribute:: channels
      :type:  List[str]


   .. py:attribute:: clip_distance
      :type:  float


   .. py:attribute:: tol_distance
      :type:  float


   .. py:attribute:: scale_factor
      :type:  float


   .. py:attribute:: mask_distances
      :type:  bool


.. py:class:: HotDistanceTask(task_config)



   A class to represent a hot distance task that use binary prediction and distance prediction.

   Inherits from Task class.

   .. attribute:: predictor

      HotDistancePredictor object.

   .. attribute:: loss

      HotDistanceLoss object.

   .. attribute:: post_processor

      ThresholdPostProcessor object.

   .. attribute:: evaluator

      BinarySegmentationEvaluator object.

   .. method:: __init__(self, task_config)

      Constructs all the necessary attributes for the HotDistanceTask object.

   .. rubric:: Notes

   This is a subclass of Task.


.. py:class:: DummyEvaluationScores



   The evaluation scores for the dummy task. The scores include the frizz level and blipp score. A higher frizz level indicates more frizz, while a higher blipp score indicates better performance.

   .. attribute:: frizz_level

      float
      the frizz level

   .. attribute:: blipp_score

      float
      the blipp score

   .. method:: higher_is_better(criterion)

      
      Return whether higher is better for the given criterion.

   .. method:: bounds(criterion)

      
      Return the bounds for the given criterion.

   .. method:: store_best(criterion)

      
      Return whether to store the best score for the given criterion.

   .. note:: The DummyEvaluationScores class is used to store the evaluation scores for the dummy task. The class also provides methods to determine whether higher is better for a given criterion, the bounds for a given criterion, and whether to store the best score for a given criterion.


   .. py:attribute:: criteria
      :value: ['frizz_level', 'blipp_score']



   .. py:attribute:: frizz_level
      :type:  float


   .. py:attribute:: blipp_score
      :type:  float


   .. py:method:: higher_is_better(criterion: str) -> bool
      :staticmethod:


      Return whether higher is better for the given criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                bool
                    whether higher is better for this criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> DummyEvaluationScores.higher_is_better("frizz_level")
      True

      .. note:: This function is used to determine whether higher is better for the given criterion.



   .. py:method:: bounds(criterion: str) -> Tuple[Union[int, float, None], Union[int, float, None]]
      :staticmethod:


      Return the bounds for the given criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                Tuple[Union[int, float, None], Union[int, float, None]]
                    the bounds for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> DummyEvaluationScores.bounds("frizz_level")
      (0.0, 1.0)

      .. note:: This function is used to return the bounds for the given criterion.



   .. py:method:: store_best(criterion: str) -> bool
      :staticmethod:


      Return whether to store the best score for the given criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                bool
                    whether to store the best score for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> DummyEvaluationScores.store_best("frizz_level")
      True

      .. note:: This function is used to determine whether to store the best score for the given criterion.



.. py:class:: DummyEvaluator



   A class representing a dummy evaluator. This evaluator is used for testing purposes.

   .. attribute:: criteria

      List[str]
      the evaluation criteria

   .. method:: evaluate(output_array_identifier, evaluation_dataset)

      
      Evaluate the output array against the evaluation dataset.

   .. method:: score

      
      Return the evaluation scores.

   .. note:: The DummyEvaluator class is used to evaluate the performance of a dummy task.


   .. py:attribute:: criteria
      :value: ['frizz_level', 'blipp_score']



   .. py:method:: evaluate(output_array_identifier, evaluation_dataset)

      Evaluate the given output array and dataset and returns the scores based on predefined criteria.

      :param output_array_identifier: The output array to be evaluated.
      :param evaluation_dataset: The dataset to be used for evaluation.

      :returns: An object of DummyEvaluationScores class, with the evaluation scores.
      :rtype: DummyEvaluationScore

      :raises ValueError: if the output array identifier is not valid

      .. rubric:: Examples

      >>> dummy_evaluator = DummyEvaluator()
      >>> output_array_identifier = "output_array"
      >>> evaluation_dataset = "evaluation_dataset"
      >>> dummy_evaluator.evaluate(output_array_identifier, evaluation_dataset)
      DummyEvaluationScores(frizz_level=0.0, blipp_score=0.0)

      .. note:: This function is used to evaluate the output array against the evaluation dataset.



   .. py:property:: score
      :type: dacapo.experiments.tasks.evaluators.dummy_evaluation_scores.DummyEvaluationScores

      Return the evaluation scores.

      :returns: An object of DummyEvaluationScores class, with the evaluation scores.
      :rtype: DummyEvaluationScores

      .. rubric:: Examples

      >>> dummy_evaluator = DummyEvaluator()
      >>> dummy_evaluator.score
      DummyEvaluationScores(frizz_level=0.0, blipp_score=0.0)

      .. note:: This function is used to return the evaluation scores.


.. py:class:: EvaluationScores

   Base class for evaluation scores. This class is used to store the evaluation scores for a task.
   The scores include the evaluation criteria. The class also provides methods to determine whether higher is better for a given criterion,
   the bounds for a given criterion, and whether to store the best score for a given criterion.

   .. attribute:: criteria

      List[str]
      the evaluation criteria

   .. method:: higher_is_better(criterion)

      
      Return whether higher is better for the given criterion.

   .. method:: bounds(criterion)

      
      Return the bounds for the given criterion.

   .. method:: store_best(criterion)

      
      Return whether to store the best score for the given criterion.

   .. note:: The EvaluationScores class is used to store the evaluation scores for a task. All evaluation scores should inherit from this class.


   .. py:property:: criteria
      :type: List[str]

      :abstractmethod:

      The evaluation criteria.

      :returns:

                List[str]
                    the evaluation criteria

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluation_scores = EvaluationScores()
      >>> evaluation_scores.criteria
      ["criterion1", "criterion2"]

      .. note:: This function is used to return the evaluation criteria.


   .. py:method:: higher_is_better(criterion: str) -> bool
      :staticmethod:

      :abstractmethod:


      Wether or not higher is better for this criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                bool
                    whether higher is better for this criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluation_scores = EvaluationScores()
      >>> criterion = "criterion1"
      >>> evaluation_scores.higher_is_better(criterion)
      True

      .. note:: This function is used to determine whether higher is better for a given criterion.



   .. py:method:: bounds(criterion: str) -> Tuple[Union[int, float, None], Union[int, float, None]]
      :staticmethod:

      :abstractmethod:


      The bounds for this criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                Tuple[Union[int, float, None], Union[int, float, None]]
                    the bounds for this criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluation_scores = EvaluationScores()
      >>> criterion = "criterion1"
      >>> evaluation_scores.bounds(criterion)
      (0, 1)

      .. note:: This function is used to return the bounds for the given criterion.



   .. py:method:: store_best(criterion: str) -> bool
      :staticmethod:

      :abstractmethod:


      Whether or not to save the best validation block and model
      weights for this criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                bool
                    whether to store the best score for this criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluation_scores = EvaluationScores()
      >>> criterion = "criterion1"
      >>> evaluation_scores.store_best(criterion)
      True

      .. note:: This function is used to return whether to store the best score for the given criterion.



.. py:class:: Evaluator



   Base class of all evaluators: An abstract class representing an evaluator that compares and evaluates the output array against the evaluation array.

   An evaluator takes a post-processor's output and compares it against
   ground-truth. It then returns a set of scores that can be used to
   determine the quality of the post-processor's output.

   .. attribute:: best_scores

      Dict[OutputIdentifier, BestScore]
      the best scores for each dataset/post-processing parameter/criterion combination

   .. method:: evaluate(output_array_identifier, evaluation_array)

      
      Compare and evaluate the output array against the evaluation array.

   .. method:: is_best(dataset, parameter, criterion, score)

      
      Check if the provided score is the best for this dataset/parameter/criterion combo.

   .. method:: get_overall_best(dataset, criterion)

      
      Return the best score for the given dataset and criterion.

   .. method:: get_overall_best_parameters(dataset, criterion)

      
      Return the best parameters for the given dataset and criterion.

   .. method:: compare(score_1, score_2, criterion)

      
      Compare two scores for the given criterion.

   .. method:: set_best(validation_scores)

      
      Find the best iteration for each dataset/post_processing_parameter/criterion.

   .. method:: higher_is_better(criterion)

      
      Return whether higher is better for the given criterion.

   .. method:: bounds(criterion)

      
      Return the bounds for the given criterion.

   .. method:: store_best(criterion)

      
      Return whether to store the best score for the given criterion.

   .. note:: The Evaluator class is used to compare and evaluate the output array against the evaluation array.


   .. py:method:: evaluate(output_array_identifier: dacapo.store.local_array_store.LocalArrayIdentifier, evaluation_array: dacapo.experiments.datasplits.datasets.arrays.Array) -> dacapo.experiments.tasks.evaluators.evaluation_scores.EvaluationScores
      :abstractmethod:


      Compares and evaluates the output array against the evaluation array.

      :param output_array_identifier: LocalArrayIdentifier
                                      The identifier of the output array.
      :param evaluation_array: Array
                               The evaluation array.

      :returns:

                EvaluationScores
                    The evaluation scores.

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> output_array_identifier = LocalArrayIdentifier("output_array")
      >>> evaluation_array = Array()
      >>> evaluator.evaluate(output_array_identifier, evaluation_array)
      EvaluationScores()

      .. note:: This function is used to compare and evaluate the output array against the evaluation array.



   .. py:property:: best_scores
      :type: Dict[OutputIdentifier, BestScore]

      The best scores for each dataset/post-processing parameter/criterion combination.

      :returns:

                Dict[OutputIdentifier, BestScore]
                    the best scores for each dataset/post-processing parameter/criterion combination

      :raises AttributeError: if the best scores are not set

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> evaluator.best_scores
      {}

      .. note:: This function is used to return the best scores for each dataset/post-processing parameter/criterion combination.


   .. py:method:: is_best(dataset: dacapo.experiments.datasplits.datasets.Dataset, parameter: dacapo.experiments.tasks.post_processors.PostProcessorParameters, criterion: str, score: dacapo.experiments.tasks.evaluators.evaluation_scores.EvaluationScores) -> bool

      Check if the provided score is the best for this dataset/parameter/criterion combo.

      :param dataset: Dataset
                      the dataset
      :param parameter: PostProcessorParameters
                        the post-processor parameters
      :param criterion: str
                        the criterion
      :param score: EvaluationScores
                    the evaluation scores

      :returns:

                bool
                    whether the provided score is the best for this dataset/parameter/criterion combo

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> dataset = Dataset()
      >>> parameter = PostProcessorParameters()
      >>> criterion = "criterion"
      >>> score = EvaluationScores()
      >>> evaluator.is_best(dataset, parameter, criterion, score)
      False

      .. note:: This function is used to check if the provided score is the best for this dataset/parameter/criterion combo.



   .. py:method:: get_overall_best(dataset: dacapo.experiments.datasplits.datasets.Dataset, criterion: str)

      Return the best score for the given dataset and criterion.

      :param dataset: Dataset
                      the dataset
      :param criterion: str
                        the criterion

      :returns:

                Optional[float]
                    the best score for the given dataset and criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> dataset = Dataset()
      >>> criterion = "criterion"
      >>> evaluator.get_overall_best(dataset, criterion)
      None

      .. note:: This function is used to return the best score for the given dataset and criterion.



   .. py:method:: get_overall_best_parameters(dataset: dacapo.experiments.datasplits.datasets.Dataset, criterion: str)

      Return the best parameters for the given dataset and criterion.

      :param dataset: Dataset
                      the dataset
      :param criterion: str
                        the criterion

      :returns:

                Optional[PostProcessorParameters]
                    the best parameters for the given dataset and criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> dataset = Dataset()
      >>> criterion = "criterion"
      >>> evaluator.get_overall_best_parameters(dataset, criterion)
      None

      .. note:: This function is used to return the best parameters for the given dataset and criterion.



   .. py:method:: compare(score_1, score_2, criterion)

      Compare two scores for the given criterion.

      :param score_1: float
                      the first score
      :param score_2: float
                      the second score
      :param criterion: str
                        the criterion

      :returns:

                bool
                    whether the first score is better than the second score for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> score_1 = 0.0
      >>> score_2 = 0.0
      >>> criterion = "criterion"
      >>> evaluator.compare(score_1, score_2, criterion)
      False

      .. note:: This function is used to compare two scores for the given criterion.



   .. py:method:: set_best(validation_scores: dacapo.experiments.validation_scores.ValidationScores) -> None

      Find the best iteration for each dataset/post_processing_parameter/criterion.

      :param validation_scores: ValidationScores
                                the validation scores

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> validation_scores = ValidationScores()
      >>> evaluator.set_best(validation_scores)
      None

      .. note::

         This function is used to find the best iteration for each dataset/post_processing_parameter/criterion.
         Typically, this function is called after the validation scores have been computed.



   .. py:property:: criteria
      :type: List[str]

      :abstractmethod:

      A list of all criteria for which a model might be "best". i.e. your
      criteria might be "precision", "recall", and "jaccard". It is unlikely
      that the best iteration/post processing parameters will be the same
      for all 3 of these criteria

      :returns:

                List[str]
                    the evaluation criteria

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> evaluator.criteria
      []

      .. note:: This function is used to return the evaluation criteria.


   .. py:method:: higher_is_better(criterion: str) -> bool

      Wether or not higher is better for this criterion.

      :param criterion: str
                        the criterion

      :returns:

                bool
                    whether higher is better for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> criterion = "criterion"
      >>> evaluator.higher_is_better(criterion)
      False

      .. note:: This function is used to determine whether higher is better for the given criterion.



   .. py:method:: bounds(criterion: str) -> Tuple[Union[int, float, None], Union[int, float, None]]

      The bounds for this criterion

      :param criterion: str
                        the criterion

      :returns:

                Tuple[Union[int, float, None], Union[int, float, None]]
                    the bounds for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> criterion = "criterion"
      >>> evaluator.bounds(criterion)
      (0, 1)

      .. note:: This function is used to return the bounds for the given criterion.



   .. py:method:: store_best(criterion: str) -> bool

      The bounds for this criterion

      :param criterion: str
                        the criterion

      :returns:

                bool
                    whether to store the best score for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> criterion = "criterion"
      >>> evaluator.store_best(criterion)
      False

      .. note:: This function is used to return whether to store the best score for the given criterion.



   .. py:property:: score
      :type: dacapo.experiments.tasks.evaluators.evaluation_scores.EvaluationScores

      :abstractmethod:

      The evaluation scores.

      :returns:

                EvaluationScores
                    the evaluation scores

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> evaluator = Evaluator()
      >>> evaluator.score
      EvaluationScores()

      .. note:: This function is used to return the evaluation scores.


.. py:class:: MultiChannelBinarySegmentationEvaluationScores



   Class representing evaluation scores for multi-channel binary segmentation tasks.

   .. attribute:: channel_scores

      The list of channel scores.

      :type: List[Tuple[str, BinarySegmentationEvaluationScores]]

   .. method:: higher_is_better(criterion

      str) -> bool: Determines whether a higher value is better for a given criterion.

   .. method:: store_best(criterion

      str) -> bool: Whether or not to store the best weights/validation blocks for this criterion.

   .. method:: bounds(criterion

      str) -> Tuple[Union[int, float, None], Union[int, float, None]]: Determines the bounds for a given criterion.

   .. rubric:: Notes

   The evaluation scores are stored as attributes of the class. The class also contains methods to determine whether a higher value is better for a given criterion, whether or not to store the best weights/validation blocks for a given criterion, and the bounds for a given criterion.


   .. py:attribute:: channel_scores
      :type:  List[Tuple[str, BinarySegmentationEvaluationScores]]


   .. py:property:: criteria
      Returns a list of all criteria for all channels.

      :returns: The list of criteria.
      :rtype: List[str]

      :raises ValueError: If the criterion is not recognized.

      .. rubric:: Examples

      >>> channel_scores = [("channel1", BinarySegmentationEvaluationScores()), ("channel2", BinarySegmentationEvaluationScores())]
      >>> MultiChannelBinarySegmentationEvaluationScores(channel_scores).criteria

      .. rubric:: Notes

      The method returns a list of all criteria for all channels. The criteria are stored as attributes of the class.


   .. py:method:: higher_is_better(criterion: str) -> bool
      :staticmethod:


      Determines whether a higher value is better for a given criterion.

      :param criterion: The evaluation criterion.
      :type criterion: str

      :returns: True if a higher value is better, False otherwise.
      :rtype: bool

      :raises ValueError: If the criterion is not recognized.

      .. rubric:: Examples

      >>> MultiChannelBinarySegmentationEvaluationScores.higher_is_better("channel1__dice")
      True
      >>> MultiChannelBinarySegmentationEvaluationScores.higher_is_better("channel1__f1_score")
      True

      .. rubric:: Notes

      The method returns True if the criterion is recognized and False otherwise. Whether a higher value is better for a given criterion is determined by the mapping dictionary.



   .. py:method:: store_best(criterion: str) -> bool
      :staticmethod:


      Determines whether or not to store the best weights/validation blocks for a given criterion.

      :param criterion: The evaluation criterion.
      :type criterion: str

      :returns: True if the best weights/validation blocks should be stored, False otherwise.
      :rtype: bool

      :raises ValueError: If the criterion is not recognized.

      .. rubric:: Examples

      >>> MultiChannelBinarySegmentationEvaluationScores.store_best("channel1__dice")
      False
      >>> MultiChannelBinarySegmentationEvaluationScores.store_best("channel1__f1_score")
      True

      .. rubric:: Notes

      The method returns True if the criterion is recognized and False otherwise. Whether or not to store the best weights/validation blocks for a given criterion is determined by the mapping dictionary.



   .. py:method:: bounds(criterion: str) -> Tuple[Union[int, float, None], Union[int, float, None]]
      :staticmethod:


      Determines the bounds for a given criterion. The bounds are used to determine the best value for a given criterion.

      :param criterion: The evaluation criterion.
      :type criterion: str

      :returns: The lower and upper bounds for the criterion.
      :rtype: Tuple[Union[int, float, None], Union[int, float, None]]

      :raises ValueError: If the criterion is not recognized.

      .. rubric:: Examples

      >>> MultiChannelBinarySegmentationEvaluationScores.bounds("channel1__dice")
      (0, 1)
      >>> MultiChannelBinarySegmentationEvaluationScores.bounds("channel1__hausdorff")
      (0, nan)

      .. rubric:: Notes

      The method returns the lower and upper bounds for the criterion. The bounds are determined by the mapping dictionary.



.. py:class:: BinarySegmentationEvaluationScores



   Class representing evaluation scores for binary segmentation tasks.

   The metrics include:
   - Dice coefficient: 2 * |A  B| / |A| + |B| ; where A and B are the binary segmentations
   - Jaccard coefficient: |A  B| / |A  B| ; where A and B are the binary segmentations
   - Hausdorff distance: max(h(A, B), h(B, A)) ; where h(A, B) is the Hausdorff distance between A and B
   - False negative rate: |A - B| / |A| ; where A and B are the binary segmentations
   - False positive rate: |B - A| / |B| ; where A and B are the binary segmentations
   - False discovery rate: |B - A| / |A| ; where A and B are the binary segmentations
   - VOI: Variation of Information; split and merge errors combined into a single measure of segmentation quality
   - Mean false distance: 0.5 * (mean false positive distance + mean false negative distance)
   - Mean false negative distance: mean distance of false negatives
   - Mean false positive distance: mean distance of false positives
   - Mean false distance clipped: 0.5 * (mean false positive distance clipped + mean false negative distance clipped) ; clipped to a maximum distance
   - Mean false negative distance clipped: mean distance of false negatives clipped ; clipped to a maximum distance
   - Mean false positive distance clipped: mean distance of false positives clipped ; clipped to a maximum distance
   - Precision with tolerance: TP / (TP + FP) ; where TP and FP are the true and false positives within a tolerance distance
   - Recall with tolerance: TP / (TP + FN) ; where TP and FN are the true and false positives within a tolerance distance
   - F1 score with tolerance: 2 * (Recall * Precision) / (Recall + Precision) ; where Recall and Precision are the true and false positives within a tolerance distance
   - Precision: TP / (TP + FP) ; where TP and FP are the true and false positives
   - Recall: TP / (TP + FN) ; where TP and FN are the true and false positives
   - F1 score: 2 * (Recall * Precision) / (Recall + Precision) ; where Recall and Precision are the true and false positives

   .. attribute:: dice

      The Dice coefficient.

      :type: float

   .. attribute:: jaccard

      The Jaccard index.

      :type: float

   .. attribute:: hausdorff

      The Hausdorff distance.

      :type: float

   .. attribute:: false_negative_rate

      The false negative rate.

      :type: float

   .. attribute:: false_negative_rate_with_tolerance

      The false negative rate with tolerance.

      :type: float

   .. attribute:: false_positive_rate

      The false positive rate.

      :type: float

   .. attribute:: false_discovery_rate

      The false discovery rate.

      :type: float

   .. attribute:: false_positive_rate_with_tolerance

      The false positive rate with tolerance.

      :type: float

   .. attribute:: voi

      The variation of information.

      :type: float

   .. attribute:: mean_false_distance

      The mean false distance.

      :type: float

   .. attribute:: mean_false_negative_distance

      The mean false negative distance.

      :type: float

   .. attribute:: mean_false_positive_distance

      The mean false positive distance.

      :type: float

   .. attribute:: mean_false_distance_clipped

      The mean false distance clipped.

      :type: float

   .. attribute:: mean_false_negative_distance_clipped

      The mean false negative distance clipped.

      :type: float

   .. attribute:: mean_false_positive_distance_clipped

      The mean false positive distance clipped.

      :type: float

   .. attribute:: precision_with_tolerance

      The precision with tolerance.

      :type: float

   .. attribute:: recall_with_tolerance

      The recall with tolerance.

      :type: float

   .. attribute:: f1_score_with_tolerance

      The F1 score with tolerance.

      :type: float

   .. attribute:: precision

      The precision.

      :type: float

   .. attribute:: recall

      The recall.

      :type: float

   .. attribute:: f1_score

      The F1 score.

      :type: float

   .. method:: store_best(criterion

      str) -> bool: Whether or not to store the best weights/validation blocks for this criterion.

   .. method:: higher_is_better(criterion

      str) -> bool: Determines whether a higher value is better for a given criterion.

   .. method:: bounds(criterion

      str) -> Tuple[Union[int, float, None], Union[int, float, None]]: Determines the bounds for a given criterion.

   .. rubric:: Notes

   The evaluation scores are stored as attributes of the class. The class also contains methods to determine whether a higher value is better for a given criterion, whether or not to store the best weights/validation blocks for a given criterion, and the bounds for a given criterion.


   .. py:attribute:: dice
      :type:  float


   .. py:attribute:: jaccard
      :type:  float


   .. py:attribute:: hausdorff
      :type:  float


   .. py:attribute:: false_negative_rate
      :type:  float


   .. py:attribute:: false_negative_rate_with_tolerance
      :type:  float


   .. py:attribute:: false_positive_rate
      :type:  float


   .. py:attribute:: false_discovery_rate
      :type:  float


   .. py:attribute:: false_positive_rate_with_tolerance
      :type:  float


   .. py:attribute:: voi
      :type:  float


   .. py:attribute:: mean_false_distance
      :type:  float


   .. py:attribute:: mean_false_negative_distance
      :type:  float


   .. py:attribute:: mean_false_positive_distance
      :type:  float


   .. py:attribute:: mean_false_distance_clipped
      :type:  float


   .. py:attribute:: mean_false_negative_distance_clipped
      :type:  float


   .. py:attribute:: mean_false_positive_distance_clipped
      :type:  float


   .. py:attribute:: precision_with_tolerance
      :type:  float


   .. py:attribute:: recall_with_tolerance
      :type:  float


   .. py:attribute:: f1_score_with_tolerance
      :type:  float


   .. py:attribute:: precision
      :type:  float


   .. py:attribute:: recall
      :type:  float


   .. py:attribute:: f1_score
      :type:  float


   .. py:attribute:: criteria
      :value: ['dice', 'jaccard', 'hausdorff', 'false_negative_rate', 'false_negative_rate_with_tolerance',...



   .. py:method:: store_best(criterion: str) -> bool
      :staticmethod:


      Determines whether or not to store the best weights/validation blocks for a given criterion.

      :param criterion: The evaluation criterion.
      :type criterion: str

      :returns: True if the best weights/validation blocks should be stored, False otherwise.
      :rtype: bool

      :raises ValueError: If the criterion is not recognized.

      .. rubric:: Examples

      >>> BinarySegmentationEvaluationScores.store_best("dice")
      False
      >>> BinarySegmentationEvaluationScores.store_best("f1_score")
      True

      .. rubric:: Notes

      The method returns True if the criterion is recognized and False otherwise. Whether or not to store the best weights/validation blocks for a given criterion is determined by the mapping dictionary.



   .. py:method:: higher_is_better(criterion: str) -> bool
      :staticmethod:


      Determines whether a higher value is better for a given criterion.

      :param criterion: The evaluation criterion.
      :type criterion: str

      :returns: True if a higher value is better, False otherwise.
      :rtype: bool

      :raises ValueError: If the criterion is not recognized.

      .. rubric:: Examples

      >>> BinarySegmentationEvaluationScores.higher_is_better("dice")
      True
      >>> BinarySegmentationEvaluationScores.higher_is_better("f1_score")
      True

      .. rubric:: Notes

      The method returns True if the criterion is recognized and False otherwise. Whether a higher value is better for a given criterion is determined by the mapping dictionary.



   .. py:method:: bounds(criterion: str) -> Tuple[Union[int, float, None], Union[int, float, None]]
      :staticmethod:


      Determines the bounds for a given criterion. The bounds are used to determine the best value for a given criterion.

      :param criterion: The evaluation criterion.
      :type criterion: str

      :returns: The lower and upper bounds for the criterion.
      :rtype: Tuple[Union[int, float, None], Union[int, float, None]]

      :raises ValueError: If the criterion is not recognized.

      .. rubric:: Examples

      >>> BinarySegmentationEvaluationScores.bounds("dice")
      (0, 1)
      >>> BinarySegmentationEvaluationScores.bounds("hausdorff")
      (0, nan)

      .. rubric:: Notes

      The method returns the lower and upper bounds for the criterion. The bounds are determined by the mapping dictionary.



.. py:class:: BinarySegmentationEvaluator(clip_distance: float, tol_distance: float, channels: List[str])



   Given a binary segmentation, compute various metrics to determine their similarity. The metrics include:
   - Dice coefficient: 2 * |A  B| / |A| + |B| ; where A and B are the binary segmentations
   - Jaccard coefficient: |A  B| / |A  B| ; where A and B are the binary segmentations
   - Hausdorff distance: max(h(A, B), h(B, A)) ; where h(A, B) is the Hausdorff distance between A and B
   - False negative rate: |A - B| / |A| ; where A and B are the binary segmentations
   - False positive rate: |B - A| / |B| ; where A and B are the binary segmentations
   - False discovery rate: |B - A| / |A| ; where A and B are the binary segmentations
   - VOI: Variation of Information; split and merge errors combined into a single measure of segmentation quality
   - Mean false distance: 0.5 * (mean false positive distance + mean false negative distance)
   - Mean false negative distance: mean distance of false negatives
   - Mean false positive distance: mean distance of false positives
   - Mean false distance clipped: 0.5 * (mean false positive distance clipped + mean false negative distance clipped) ; clipped to a maximum distance
   - Mean false negative distance clipped: mean distance of false negatives clipped ; clipped to a maximum distance
   - Mean false positive distance clipped: mean distance of false positives clipped ; clipped to a maximum distance
   - Precision with tolerance: TP / (TP + FP) ; where TP and FP are the true and false positives within a tolerance distance
   - Recall with tolerance: TP / (TP + FN) ; where TP and FN are the true and false positives within a tolerance distance
   - F1 score with tolerance: 2 * (Recall * Precision) / (Recall + Precision) ; where Recall and Precision are the true and false positives within a tolerance distance
   - Precision: TP / (TP + FP) ; where TP and FP are the true and false positives
   - Recall: TP / (TP + FN) ; where TP and FN are the true and false positives
   - F1 score: 2 * (Recall * Precision) / (Recall + Precision) ; where Recall and Precision are the true and false positives

   .. attribute:: clip_distance

      float
      the clip distance

   .. attribute:: tol_distance

      float
      the tolerance distance

   .. attribute:: channels

      List[str]
      the channels

   .. attribute:: criteria

      List[str]
      the evaluation criteria

   .. method:: evaluate(output_array_identifier, evaluation_array)

      
      Evaluate the output array against the evaluation array.

   .. method:: score

      
      Return the evaluation scores.

   .. note::

      The BinarySegmentationEvaluator class is used to evaluate the performance of a binary segmentation task.
      The class provides methods to evaluate the output array against the evaluation array and return the evaluation scores.
      All evaluation scores should inherit from this class.
      
      Clip distance is the maximum distance between the ground truth and the predicted segmentation for a pixel to be considered a false positive.
      Tolerance distance is the maximum distance between the ground truth and the predicted segmentation for a pixel to be considered a true positive.
      Channels are the channels of the binary segmentation.
      Criteria are the evaluation criteria.


   .. py:attribute:: criteria
      :value: ['jaccard', 'voi']



   .. py:method:: evaluate(output_array_identifier, evaluation_array)

      Evaluate the output array against the evaluation array.

      :param output_array_identifier: str
                                      the identifier of the output array
      :param evaluation_array: ZarrArray
                               the evaluation array

      :returns:

                BinarySegmentationEvaluationScores or MultiChannelBinarySegmentationEvaluationScores
                    the evaluation scores

      :raises ValueError: if the output array identifier is not valid

      .. rubric:: Examples

      >>> binary_segmentation_evaluator = BinarySegmentationEvaluator(clip_distance=200, tol_distance=40, channels=["channel1", "channel2"])
      >>> output_array_identifier = "output_array"
      >>> evaluation_array = ZarrArray.open_from_array_identifier("evaluation_array")
      >>> binary_segmentation_evaluator.evaluate(output_array_identifier, evaluation_array)
      BinarySegmentationEvaluationScores(dice=0.0, jaccard=0.0, hausdorff=0.0, false_negative_rate=0.0, false_positive_rate=0.0, false_discovery_rate=0.0, voi=0.0, mean_false_distance=0.0, mean_false_negative_distance=0.0, mean_false_positive_distance=0.0, mean_false_distance_clipped=0.0, mean_false_negative_distance_clipped=0.0, mean_false_positive_distance_clipped=0.0, precision_with_tolerance=0.0, recall_with_tolerance=0.0, f1_score_with_tolerance=0.0, precision=0.0, recall=0.0, f1_score=0.0)

      .. note:: This function is used to evaluate the output array against the evaluation array.



   .. py:property:: score
      Return the evaluation scores.

      :returns:

                BinarySegmentationEvaluationScores or MultiChannelBinarySegmentationEvaluationScores
                    the evaluation scores

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> binary_segmentation_evaluator = BinarySegmentationEvaluator(clip_distance=200, tol_distance=40, channels=["channel1", "channel2"])
      >>> binary_segmentation_evaluator.score
      BinarySegmentationEvaluationScores(dice=0.0, jaccard=0.0, hausdorff=0.0, false_negative_rate=0.0, false_positive_rate=0.0, false_discovery_rate=0.0, voi=0.0, mean_false_distance=0.0, mean_false_negative_distance=0.0, mean_false_positive_distance=0.0, mean_false_distance_clipped=0.0, mean_false_negative_distance_clipped=0.0, mean_false_positive_distance_clipped=0.0, precision_with_tolerance=0.0, recall_with_tolerance=0.0, f1_score_with_tolerance=0.0, precision=0.0, recall=0.0, f1_score=0.0)

      .. note:: This function is used to return the evaluation scores.


.. py:class:: InstanceEvaluationScores



   The evaluation scores for the instance segmentation task. The scores include the variation of information (VOI) split, VOI merge, and VOI.

   .. attribute:: voi_split

      float
      the variation of information (VOI) split

   .. attribute:: voi_merge

      float
      the variation of information (VOI) merge

   .. attribute:: voi

      float
      the variation of information (VOI)

   .. method:: higher_is_better(criterion)

      
      Return whether higher is better for the given criterion.

   .. method:: bounds(criterion)

      
      Return the bounds for the given criterion.

   .. method:: store_best(criterion)

      
      Return whether to store the best score for the given criterion.

   .. note:: The InstanceEvaluationScores class is used to store the evaluation scores for the instance segmentation task.


   .. py:attribute:: criteria
      :value: ['voi_split', 'voi_merge', 'voi']



   .. py:attribute:: voi_split
      :type:  float


   .. py:attribute:: voi_merge
      :type:  float


   .. py:property:: voi
      Return the average of the VOI split and VOI merge.

      :returns:

                float
                    the average of the VOI split and VOI merge

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> instance_evaluation_scores = InstanceEvaluationScores(voi_split=0.1, voi_merge=0.2)
      >>> instance_evaluation_scores.voi
      0.15

      .. note:: This function is used to calculate the average of the VOI split and VOI merge.


   .. py:method:: higher_is_better(criterion: str) -> bool
      :staticmethod:


      Return whether higher is better for the given criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                bool
                    whether higher is better for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> InstanceEvaluationScores.higher_is_better("voi_split")
      False

      .. note:: This function is used to determine whether higher is better for the given criterion.



   .. py:method:: bounds(criterion: str) -> Tuple[Union[int, float, None], Union[int, float, None]]
      :staticmethod:


      Return the bounds for the given criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                Tuple[Union[int, float, None], Union[int, float, None]]
                    the bounds for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> InstanceEvaluationScores.bounds("voi_split")
      (0, 1)

      .. note:: This function is used to return the bounds for the given criterion.



   .. py:method:: store_best(criterion: str) -> bool
      :staticmethod:


      Return whether to store the best score for the given criterion.

      :param criterion: str
                        the evaluation criterion

      :returns:

                bool
                    whether to store the best score for the given criterion

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> InstanceEvaluationScores.store_best("voi_split")
      True

      .. note:: This function is used to determine whether to store the best score for the given criterion.



.. py:class:: InstanceEvaluator



   A class representing an evaluator for instance segmentation tasks.

   .. attribute:: criteria

      List[str]
      the evaluation criteria

   .. method:: evaluate(output_array_identifier, evaluation_array)

      
      Evaluate the output array against the evaluation array.

   .. method:: score

      
      Return the evaluation scores.

   .. note:: The InstanceEvaluator class is used to evaluate the performance of an instance segmentation task.


   .. py:attribute:: criteria
      :type:  List[str]
      :value: ['voi_merge', 'voi_split', 'voi']



   .. py:method:: evaluate(output_array_identifier, evaluation_array)

      Evaluate the output array against the evaluation array.

      :param output_array_identifier: str
                                      the identifier of the output array
      :param evaluation_array: ZarrArray
                               the evaluation array

      :returns:

                InstanceEvaluationScores
                    the evaluation scores

      :raises ValueError: if the output array identifier is not valid

      .. rubric:: Examples

      >>> instance_evaluator = InstanceEvaluator()
      >>> output_array_identifier = "output_array"
      >>> evaluation_array = ZarrArray.open_from_array_identifier("evaluation_array")
      >>> instance_evaluator.evaluate(output_array_identifier, evaluation_array)
      InstanceEvaluationScores(voi_merge=0.0, voi_split=0.0)

      .. note:: This function is used to evaluate the output array against the evaluation array.



   .. py:property:: score
      :type: dacapo.experiments.tasks.evaluators.instance_evaluation_scores.InstanceEvaluationScores

      Return the evaluation scores.

      :returns:

                InstanceEvaluationScores
                    the evaluation scores

      :raises NotImplementedError: if the function is not implemented

      .. rubric:: Examples

      >>> instance_evaluator = InstanceEvaluator()
      >>> instance_evaluator.score
      InstanceEvaluationScores(voi_merge=0.0, voi_split=0.0)

      .. note:: This function is used to return the evaluation scores.


.. py:class:: DummyPostProcessor(detection_threshold: float)



   Dummy post-processor that stores some dummy data. The dummy data is a 10x10x10
   array filled with the value of the min_size parameter. The min_size parameter
   is specified in the parameters of the post-processor. The post-processor has
   a detection threshold that is used to determine if an object is detected.

   .. attribute:: detection_threshold

      The detection threshold.

   .. method:: enumerate_parameters

      Enumerate all possible parameters of this post-processor.

   .. method:: set_prediction

      Set the prediction array identifier.

   .. method:: process

      Convert predictions into the final output.

   .. note::

      This class is abstract. Subclasses must implement the abstract methods. Once
      created, the values of its attributes cannot be changed.


   .. py:method:: enumerate_parameters() -> Iterable[dacapo.experiments.tasks.post_processors.dummy_post_processor_parameters.DummyPostProcessorParameters]

      Enumerate all possible parameters of this post-processor. Should
      return instances of ``PostProcessorParameters``.

      :returns: An iterable of `PostProcessorParameters` instances.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = DummyPostProcessor()
      >>> for parameters in post_processor.enumerate_parameters():
      ...     print(parameters)
      DummyPostProcessorParameters(id=0, min_size=1)
      DummyPostProcessorParameters(id=1, min_size=2)
      DummyPostProcessorParameters(id=2, min_size=3)
      DummyPostProcessorParameters(id=3, min_size=4)
      DummyPostProcessorParameters(id=4, min_size=5)
      DummyPostProcessorParameters(id=5, min_size=6)
      DummyPostProcessorParameters(id=6, min_size=7)
      DummyPostProcessorParameters(id=7, min_size=8)
      DummyPostProcessorParameters(id=8, min_size=9)
      DummyPostProcessorParameters(id=9, min_size=10)

      .. note::

         This method must be implemented in the subclass. It should return an
         iterable of `PostProcessorParameters` instances.



   .. py:method:: set_prediction(prediction_array_identifier)

      Set the prediction array identifier.

      :param prediction_array_identifier: The identifier of the array containing
                                          the model's prediction.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = DummyPostProcessor()
      >>> post_processor.set_prediction("prediction")

      .. note::

         This method must be implemented in the subclass. It should set the
         `prediction_array_identifier` attribute.



   .. py:method:: process(parameters, output_array_identifier, *args, **kwargs)

      Convert predictions into the final output.

      :param parameters: The parameters of the post-processor.
      :param output_array_identifier: The identifier of the output array.
      :param num_workers: The number of workers to use.
      :param chunk_size: The size of the chunks to process.

      :returns: The output array.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = DummyPostProcessor()
      >>> post_processor.process(parameters, "output")

      .. note::

         This method must be implemented in the subclass. It should process the
         predictions and store the output in the output array.



.. py:class:: DummyPostProcessorParameters



   Parameters for the dummy post-processor. The dummy post-processor will set
   the output to 1 if the input is greater than the minimum size, and 0
   otherwise.

   .. attribute:: min_size

      The minimum size. If the input is greater than this value, the
      output will be set to 1. Otherwise, the output will be set to 0.

   .. method:: parameter_names

      Get the names of the parameters.

   .. note::

      This class is immutable. Once created, the values of its attributes
      cannot be changed.


   .. py:attribute:: min_size
      :type:  int


.. py:class:: PostProcessorParameters

   Base class for post-processor parameters. Post-processor parameters are
   immutable objects that define the parameters of a post-processor. The
   parameters are used to configure the post-processor.

   .. attribute:: id

      The identifier of the post-processor parameter.

   .. method:: parameter_names

      Get the names of the parameters.

   .. note::

      This class is immutable. Once created, the values of its attributes
      cannot be changed.


   .. py:attribute:: id
      :type:  int


   .. py:property:: parameter_names
      :type: List[str]

      Get the names of the parameters.

      :returns: A list of parameter names.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> parameters = PostProcessorParameters(0)
      >>> parameters.parameter_names
      ["id"]

      .. note::

         This method must be implemented in the subclass. It should return a
         list of parameter names.


.. py:class:: PostProcessor



   Base class of all post-processors.

   A post-processor takes a model's prediction and converts it into the final
   output (e.g., per-voxel class probabilities into a semantic segmentation). A
   post-processor can have multiple parameters, which can be enumerated using
   the `enumerate_parameters` method. The `process` method takes a set of
   parameters and applies the post-processing to the prediction.

   .. attribute:: prediction_array_identifier

      The identifier of the array containing the
      model's prediction.

   .. method:: enumerate_parameters

      Enumerate all possible parameters of this
      post-processor.

   .. method:: set_prediction

      Set the prediction array identifier.

   .. method:: process

      Convert predictions into the final output.

   .. note::

      This class is abstract. Subclasses must implement the abstract methods. Once
      created, the values of its attributes cannot be changed.


   .. py:method:: enumerate_parameters() -> Iterable[dacapo.experiments.tasks.post_processors.post_processor_parameters.PostProcessorParameters]
      :abstractmethod:


      Enumerate all possible parameters of this post-processor.

      :returns: An iterable of `PostProcessorParameters` instances.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = MyPostProcessor()
      >>> for parameters in post_processor.enumerate_parameters():
      ...     print(parameters)
      MyPostProcessorParameters(param1=0.0, param2=0.0)
      MyPostProcessorParameters(param1=0.0, param2=1.0)
      MyPostProcessorParameters(param1=1.0, param2=0.0)
      MyPostProcessorParameters(param1=1.0, param2=1.0)

      .. note::

         This method must be implemented in the subclass. It should return an
         iterable of `PostProcessorParameters` instances.



   .. py:method:: set_prediction(prediction_array_identifier: dacapo.store.local_array_store.LocalArrayIdentifier) -> None
      :abstractmethod:


      Set the prediction array identifier.

      :param prediction_array_identifier: The identifier of the array containing
                                          the model's prediction.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = MyPostProcessor()
      >>> post_processor.set_prediction("prediction")

      .. note::

         This method must be implemented in the subclass. It should set the
         `prediction_array_identifier` attribute.



   .. py:method:: process(parameters: dacapo.experiments.tasks.post_processors.post_processor_parameters.PostProcessorParameters, output_array_identifier: dacapo.store.local_array_store.LocalArrayIdentifier, num_workers: int = 16, chunk_size: funlib.geometry.Coordinate = Coordinate((64, 64, 64))) -> dacapo.experiments.datasplits.datasets.arrays.Array
      :abstractmethod:


      Convert predictions into the final output.

      :param parameters: The parameters of the post-processor.
      :param output_array_identifier: The identifier of the array to store the
                                      output.
      :param num_workers: The number of workers to use.
      :param chunk_size: The size of the chunks to process.

      :returns: The output array.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = MyPostProcessor()
      >>> post_processor.set_prediction("prediction")
      >>> parameters = MyPostProcessorParameters(param1=0.0, param2=0.0)
      >>> output = post_processor.process(parameters, "output")

      .. note::

         This method must be implemented in the subclass. It should convert the
         model's prediction into the final output.



.. py:class:: ThresholdPostProcessor



   A post-processor that applies a threshold to the prediction.

   .. attribute:: prediction_array_identifier

      The identifier of the prediction array.

   .. attribute:: prediction_array

      The prediction array.

   .. method:: enumerate_parameters

      Enumerate all possible parameters of this post-processor.

   .. method:: set_prediction

      Set the prediction array.

   .. method:: process

      Process the prediction with the given parameters.

   .. note:: This post-processor applies a threshold to the prediction. The threshold is used to define the segmentation. The prediction array is set using the `set_prediction` method.


   .. py:method:: enumerate_parameters() -> Iterable[dacapo.experiments.tasks.post_processors.threshold_post_processor_parameters.ThresholdPostProcessorParameters]

      Enumerate all possible parameters of this post-processor.

      :returns: A generator of parameters.
      :rtype: Generator[ThresholdPostProcessorParameters]

      :raises NotImplementedError: If the method is not implemented.

      .. rubric:: Examples

      >>> for parameters in post_processor.enumerate_parameters():
      ...     print(parameters)

      .. note:: This method should return a generator of instances of ``ThresholdPostProcessorParameters``.



   .. py:method:: set_prediction(prediction_array_identifier)

      Set the prediction array.

      :param prediction_array_identifier: The identifier of the prediction array.
      :type prediction_array_identifier: LocalArrayIdentifier

      :raises NotImplementedError: If the method is not implemented.

      .. rubric:: Examples

      >>> post_processor.set_prediction(prediction_array_identifier)

      .. note:: This method should set the prediction array using the given identifier.



   .. py:method:: process(parameters: dacapo.experiments.tasks.post_processors.threshold_post_processor_parameters.ThresholdPostProcessorParameters, output_array_identifier: dacapo.store.array_store.LocalArrayIdentifier, num_workers: int = 16, block_size: daisy.Coordinate = Coordinate((256, 256, 256))) -> dacapo.experiments.datasplits.datasets.arrays.zarr_array.ZarrArray

      Process the prediction with the given parameters.

      :param parameters: The parameters to use for processing.
      :type parameters: ThresholdPostProcessorParameters
      :param output_array_identifier: The identifier of the output array.
      :type output_array_identifier: LocalArrayIdentifier
      :param num_workers: The number of workers to use for processing.
      :type num_workers: int
      :param block_size: The block size to use for processing.
      :type block_size: Coordinate

      :returns: The output array.
      :rtype: ZarrArray

      :raises NotImplementedError: If the method is not implemented.

      .. rubric:: Examples

      >>> post_processor.process(parameters, output_array_identifier)

      .. note::

         This method should process the prediction with the given parameters and return the output array. The method uses the `run_blockwise` function from the `dacapo.blockwise.scheduler` module to run the blockwise post-processing.
         The output array is created using the `ZarrArray.create_from_array_identifier` function from the `dacapo.experiments.datasplits.datasets.arrays` module.



.. py:class:: ThresholdPostProcessorParameters



   Parameters for the threshold post-processor. The threshold post-processor
   will set the output to 1 if the input is greater than the threshold, and 0
   otherwise.

   .. attribute:: threshold

      The threshold value. If the input is greater than this
      value, the output will be set to 1. Otherwise, the output will be
      set to 0.

   .. note::

      This class is immutable. Once created, the values of its attributes
      cannot be changed.


   .. py:attribute:: threshold
      :type:  float


.. py:class:: ArgmaxPostProcessor



   Post-processor that takes the argmax of the input array along the channel
   axis. The output is a binary array where the value is 1 if the argmax is
   greater than the threshold, and 0 otherwise.

   .. attribute:: prediction_array

      The array containing the model's prediction.

   .. method:: enumerate_parameters

      Enumerate all possible parameters of this post-processor.

   .. method:: set_prediction

      Set the prediction array identifier.

   .. method:: process

      Convert predictions into the final output.

   .. note::

      This class is abstract. Subclasses must implement the abstract methods. Once
      created, the values of its attributes cannot be changed.


   .. py:method:: enumerate_parameters()

      Enumerate all possible parameters of this post-processor. Should
      return instances of ``PostProcessorParameters``.

      :returns: An iterable of `PostProcessorParameters` instances.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = ArgmaxPostProcessor()
      >>> for parameters in post_processor.enumerate_parameters():
      ...     print(parameters)
      ArgmaxPostProcessorParameters(id=0)

      .. note::

         This method must be implemented in the subclass. It should return an
         iterable of `PostProcessorParameters` instances.



   .. py:method:: set_prediction(prediction_array_identifier)

      Set the prediction array identifier.

      :param prediction_array_identifier: The identifier of the array containing
                                          the model's prediction.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = ArgmaxPostProcessor()
      >>> post_processor.set_prediction("prediction")

      .. note::

         This method must be implemented in the subclass. It should set the
         `prediction_array_identifier` attribute.



   .. py:method:: process(parameters, output_array_identifier: dacapo.store.array_store.LocalArrayIdentifier, num_workers: int = 16, block_size: daisy.Coordinate = Coordinate((256, 256, 256)))

      Convert predictions into the final output.

      :param parameters: The parameters of the post-processor.
      :param output_array_identifier: The identifier of the output array.
      :param num_workers: The number of workers to use.
      :param block_size: The size of the blocks to process.

      :returns: The output array.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = ArgmaxPostProcessor()
      >>> post_processor.set_prediction("prediction")
      >>> post_processor.process(parameters, "output")

      .. note::

         This method must be implemented in the subclass. It should process the
         predictions and return the output array.



.. py:class:: ArgmaxPostProcessorParameters



   Parameters for the argmax post-processor. The argmax post-processor will set
   the output to the index of the maximum value in the input array.

   .. method:: parameter_names

      Get the names of the parameters.

   .. note::

      This class is immutable. Once created, the values of its attributes
      cannot be changed.


.. py:class:: WatershedPostProcessor(offsets: List[funlib.geometry.Coordinate])



   A post-processor that applies a watershed transformation to the
   prediction.

   .. attribute:: offsets

      List of offsets for the watershed transformation.

   .. method:: enumerate_parameters

      Enumerate all possible parameters of this post-processor.

   .. method:: set_prediction

      Set the prediction array.

   .. method:: process

      Process the prediction with the given parameters.

   .. note:: This post-processor uses the `watershed_function.py` script to apply the watershed transformation. The offsets are used to define the neighborhood for the watershed transformation.


   .. py:method:: enumerate_parameters()

      Enumerate all possible parameters of this post-processor. Should
      return instances of ``PostProcessorParameters``.

      :returns: A generator of parameters.
      :rtype: Generator[WatershedPostProcessorParameters]

      :raises NotImplementedError: If the method is not implemented.

      .. rubric:: Examples

      >>> for parameters in post_processor.enumerate_parameters():
      ...     print(parameters)

      .. note:: This method should be implemented by the subclass. It should return a generator of instances of ``WatershedPostProcessorParameters``.



   .. py:method:: set_prediction(prediction_array_identifier)

      Set the prediction array identifier.

      :param prediction_array_identifier: The identifier of the array containing
                                          the model's prediction.

      :raises NotImplementedError: If the method is not implemented in the subclass.

      .. rubric:: Examples

      >>> post_processor = MyPostProcessor()
      >>> post_processor.set_prediction("prediction")

      .. note::

         This method must be implemented in the subclass. It should set the
         `prediction_array_identifier` attribute.



   .. py:method:: process(parameters: dacapo.experiments.tasks.post_processors.watershed_post_processor_parameters.WatershedPostProcessorParameters, output_array_identifier: dacapo.store.array_store.LocalArrayIdentifier, num_workers: int = 16, block_size: funlib.geometry.Coordinate = Coordinate((256, 256, 256)))

      Process the prediction with the given parameters.

      :param parameters: The parameters to use for processing.
      :type parameters: WatershedPostProcessorParameters
      :param output_array_identifier: The output array identifier.
      :type output_array_identifier: LocalArrayIdentifier
      :param num_workers: The number of workers to use for processing.
      :type num_workers: int
      :param block_size: The block size to use for processing.
      :type block_size: Coordinate

      :returns: The output array identifier.
      :rtype: LocalArrayIdentifier

      :raises NotImplementedError: If the method is not implemented.

      .. rubric:: Examples

      >>> post_processor.process(parameters, output_array_identifier)

      .. note:: This method should be implemented by the subclass. To run the watershed transformation, the method uses the `segment_blockwise` function from the `dacapo.blockwise.scheduler` module.



.. py:class:: WatershedPostProcessorParameters



   Parameters for the watershed post-processor.

   .. attribute:: offsets

      List of offsets for the watershed transformation.

   .. attribute:: threshold

      Threshold for the watershed transformation.

   .. attribute:: sigma

      Sigma for the watershed transformation.

   .. attribute:: min_size

      Minimum size of the segments.

   .. attribute:: bias

      Bias for the watershed transformation.

   .. attribute:: context

      Context for the watershed transformation.

   .. rubric:: Examples

   >>> WatershedPostProcessorParameters(offsets=[(0, 0, 1), (0, 1, 0), (1, 0, 0)], threshold=0.5, sigma=1.0, min_size=100, bias=0.5, context=(32, 32, 32))

   .. note:: This class is used by the ``WatershedPostProcessor`` to define the parameters for the watershed transformation. The offsets are used to define the neighborhood for the watershed transformation.


   .. py:attribute:: bias
      :type:  float


   .. py:attribute:: context
      :type:  funlib.geometry.Coordinate


.. py:class:: Trainer



   Trainer Abstract Base Class

   This serves as the blueprint for any trainer classes in the dacapo library.
   It defines essential methods that every subclass must implement for effective
   training of a neural network model.

   .. attribute:: iteration

      The number of training iterations.

      :type: int

   .. attribute:: batch_size

      The size of the training batch.

      :type: int

   .. attribute:: learning_rate

      The learning rate for the optimizer.

      :type: float

   .. method:: create_optimizer(model

      Model) -> torch.optim.Optimizer:
      Creates an optimizer for the model.

   .. method:: iterate(num_iterations

      int, model: Model, optimizer: torch.optim.Optimizer, device: torch.device) -> Iterator[TrainingIterationStats]:
      Performs a number of training iterations.

   .. method:: can_train(datasets

      List[Dataset]) -> bool:
      Checks if the trainer can train with a specific set of datasets.

   .. method:: build_batch_provider(datasets

      List[Dataset], model: Model, task: Task, snapshot_container: LocalContainerIdentifier) -> None:
      Initializes the training pipeline using various components.

   .. note:: The Trainer class is an abstract class that cannot be instantiated directly. It is meant to be subclassed.


   .. py:attribute:: iteration
      :type:  int


   .. py:attribute:: batch_size
      :type:  int


   .. py:attribute:: learning_rate
      :type:  float


   .. py:method:: create_optimizer(model: dacapo.experiments.model.Model) -> torch.optim.Optimizer
      :abstractmethod:


      Creates an optimizer for the model.

      :param model: The model for which the optimizer will be created.
      :type model: Model

      :returns: The optimizer created for the model.
      :rtype: torch.optim.Optimizer

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> optimizer = trainer.create_optimizer(model)

      .. note:: This method must be implemented by the subclass.



   .. py:method:: iterate(num_iterations: int, model: dacapo.experiments.model.Model, optimizer: torch.optim.Optimizer, device: torch.device) -> Iterator[dacapo.experiments.training_iteration_stats.TrainingIterationStats]
      :abstractmethod:


      Performs a number of training iterations.

      :param num_iterations: Number of training iterations.
      :type num_iterations: int
      :param model: The model to be trained.
      :type model: Model
      :param optimizer: The optimizer for the model.
      :type optimizer: torch.optim.Optimizer
      :param device: The device (GPU/CPU) where the model will be trained.
      :type device: torch.device

      :returns: An iterator of the training statistics.
      :rtype: Iterator[TrainingIterationStats]

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> for iteration_stats in trainer.iterate(num_iterations, model, optimizer, device):
      >>>     print(iteration_stats)

      .. note:: This method must be implemented by the subclass.



   .. py:method:: can_train(datasets: List[dacapo.experiments.datasplits.datasets.Dataset]) -> bool
      :abstractmethod:


      Checks if the trainer can train with a specific set of datasets.

      Some trainers may have specific requirements for their training datasets.

      :param datasets: The training datasets.
      :type datasets: List[Dataset]

      :returns: True if the trainer can train on the given datasets, False otherwise.
      :rtype: bool

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> can_train = trainer.can_train(datasets)

      .. note:: This method must be implemented by the subclass.



   .. py:method:: build_batch_provider(datasets: List[dacapo.experiments.datasplits.datasets.Dataset], model: dacapo.experiments.model.Model, task: dacapo.experiments.tasks.task.Task, snapshot_container: dacapo.store.array_store.LocalContainerIdentifier) -> None
      :abstractmethod:


      Initializes the training pipeline using various components.

      This method uses the datasets, model, task, and snapshot_container to set up the
      training pipeline.

      :param datasets: The datasets to pull data from.
      :type datasets: List[Dataset]
      :param model: The model to inform the pipeline of required input/output sizes.
      :type model: Model
      :param task: The task to transform ground truth into target.
      :type task: Task
      :param snapshot_container: Defines where snapshots will be saved.
      :type snapshot_container: LocalContainerIdentifier

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> trainer.build_batch_provider(datasets, model, task, snapshot_container)

      .. note:: This method must be implemented by the subclass.



.. py:class:: TrainerConfig

   A class to represent the Trainer Configurations.

   It is the base class for trainer configurations. Each subclass of a `Trainer`
   should have a specific config class derived from `TrainerConfig`.

   .. attribute:: name

      A unique name for this trainer.

      :type: str

   .. attribute:: batch_size

      The batch size to be used during training.

      :type: int

   .. attribute:: learning_rate

      The learning rate of the optimizer.

      :type: float

   .. method:: verify() -> Tuple[bool, str]

      
      Verify whether this TrainerConfig is valid or not.

   .. note:: The TrainerConfig class is an abstract class that cannot be instantiated directly. It is meant to be subclassed.


   .. py:attribute:: name
      :type:  str


   .. py:attribute:: batch_size
      :type:  int


   .. py:attribute:: learning_rate
      :type:  float


   .. py:method:: verify() -> Tuple[bool, str]

      Verify whether this TrainerConfig is valid or not.
      A TrainerConfig is considered valid if it has a valid batch size and learning rate.

      :returns: A tuple containing a boolean indicating whether the
                TrainerConfig is valid and a message explaining why.
      :rtype: tuple

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> valid, message = trainer_config.verify()
      >>> valid
      True
      >>> message
      "No validation for this Trainer"

      .. note:: This method must be implemented by the subclass.



.. py:class:: DummyTrainerConfig



   This is just a dummy trainer config used for testing. None of the
   attributes have any particular meaning. This is just to test the trainer
   and the trainer config.

   .. attribute:: mirror_augment

      A boolean value indicating whether to use mirror
      augmentation or not.

      :type: bool

   .. method:: verify(self) -> Tuple[bool, str]

      This method verifies the DummyTrainerConfig object.
      
      


   .. py:attribute:: trainer_type


   .. py:attribute:: mirror_augment
      :type:  bool


   .. py:method:: verify() -> Tuple[bool, str]

      Verify the DummyTrainerConfig object.

      :returns:

                A tuple containing a boolean value indicating whether the DummyTrainerConfig object is valid
                    and a string containing the reason why the object is invalid.
      :rtype: Tuple[bool, str]

      .. rubric:: Examples

      >>> valid, reason = trainer_config.verify()



.. py:class:: DummyTrainer(trainer_config)



   This class is used to train a model using dummy data and is used for testing purposes. It contains attributes
   related to learning rate, batch size, and mirror augment. It also contains methods to create an optimizer, iterate
   over the training data, build a batch provider, and check if the trainer can train on the given data split. This class
   contains methods to enter and exit the context manager. The iterate method yields training iteration statistics.

   .. attribute:: learning_rate

      The learning rate to use.

      :type: float

   .. attribute:: batch_size

      The batch size to use.

      :type: int

   .. attribute:: mirror_augment

      A boolean value indicating whether to use mirror augmentation or not.

      :type: bool

   .. method:: __init__(self, trainer_config)

      This method initializes the DummyTrainer object.

   .. method:: create_optimizer(self, model)

      This method creates an optimizer for the given model.

   .. method:: iterate(self, num_iterations

      int, model, optimizer, device): This method iterates over the training data for the specified number of iterations.

   .. method:: build_batch_provider(self, datasplit, architecture, task, snapshot_container)

      This method builds a batch provider for the given data split, architecture, task, and snapshot container.

   .. method:: can_train(self, datasplit)

      This method checks if the trainer can train on the given data split.

   .. method:: __enter__(self)

      This method enters the context manager.

   .. method:: __exit__(self, exc_type, exc_val, exc_tb)

      This method exits the context manager.

   .. note:: The iterate method yields TrainingIterationStats.


   .. py:attribute:: iteration
      :value: 0



   .. py:method:: create_optimizer(model)

      Create an optimizer for the given model.

      :param model: The model to optimize.
      :type model: Model

      :returns: The optimizer object.
      :rtype: torch.optim.Optimizer

      .. rubric:: Examples

      >>> optimizer = create_optimizer(model)



   .. py:method:: iterate(num_iterations: int, model: dacapo.experiments.model.Model, optimizer, device)

      Iterate over the training data for the specified number of iterations.

      :param num_iterations: The number of iterations to perform.
      :type num_iterations: int
      :param model: The model to train.
      :type model: Model
      :param optimizer: The optimizer to use.
      :type optimizer: torch.optim.Optimizer
      :param device: The device to perform the computations on.
      :type device: torch.device

      :Yields: *TrainingIterationStats* -- The training iteration statistics.

      :raises ValueError: If the number of iterations is less than or equal to zero.

      .. rubric:: Examples

      >>> for stats in iterate(num_iterations, model, optimizer, device):
      >>>     print(stats)



   .. py:method:: build_batch_provider(datasplit, architecture, task, snapshot_container)

      Build a batch provider for the given data split, architecture, task, and snapshot container.

      :param datasplit: The data split to use.
      :type datasplit: DataSplit
      :param architecture: The architecture to use.
      :type architecture: Architecture
      :param task: The task to perform.
      :type task: Task
      :param snapshot_container: The snapshot container to use.
      :type snapshot_container: SnapshotContainer

      :returns: The batch provider object.
      :rtype: BatchProvider

      :raises ValueError: If the task loss is not set.

      .. rubric:: Examples

      >>> batch_provider = build_batch_provider(datasplit, architecture, task, snapshot_container)



   .. py:method:: can_train(datasplit)

      Check if the trainer can train on the given data split.

      :param datasplit: The data split to check.
      :type datasplit: DataSplit

      :returns: True if the trainer can train on the data split, False otherwise.
      :rtype: bool

      :raises NotImplementedError: If the method is not implemented.

      .. rubric:: Examples

      >>> can_train(datasplit)



.. py:class:: GunpowderTrainerConfig



   This class is used to configure a Gunpowder Trainer. It contains attributes related to trainer type,
   number of data fetchers, augmentations to apply, snapshot interval, minimum masked value, and a boolean
   value indicating whether to clip raw or not.

   .. attribute:: trainer_type

      This is the type of the trainer which is set to GunpowderTrainer by default.

      :type: class

   .. attribute:: num_data_fetchers

      This is the number of CPU workers who will be dedicated to fetch and process the data.

      :type: int

   .. attribute:: augments

      This is the list of augments to apply during the training.

      :type: List[AugmentConfig]

   .. attribute:: snapshot_interval

      This is the number of iterations after which a new snapshot should be saved.

      :type: Optional[int]

   .. attribute:: min_masked

      This is the minimum masked value.

      :type: Optional[float]

   .. attribute:: clip_raw

      This is a boolean value indicating if the raw data should be clipped to the size of the GT data or not.

      :type: bool


   .. py:attribute:: trainer_type


   .. py:attribute:: num_data_fetchers
      :type:  int


   .. py:attribute:: augments
      :type:  List[dacapo.experiments.trainers.gp_augments.AugmentConfig]


   .. py:attribute:: snapshot_interval
      :type:  Optional[int]


   .. py:attribute:: min_masked
      :type:  Optional[float]


   .. py:attribute:: clip_raw
      :type:  bool


.. py:class:: GunpowderTrainer(trainer_config)



   GunpowderTrainer class for training a model using gunpowder. This class is a subclass of the Trainer class. It
   implements the abstract methods defined in the Trainer class. The GunpowderTrainer class is used to train a model
   using gunpowder, a data loading and augmentation library. It is used to train a model on a dataset using a specific
   task.

   .. attribute:: learning_rate

      The learning rate for the optimizer.

      :type: float

   .. attribute:: batch_size

      The size of the training batch.

      :type: int

   .. attribute:: num_data_fetchers

      The number of data fetchers.

      :type: int

   .. attribute:: print_profiling

      The number of iterations after which to print profiling stats.

      :type: int

   .. attribute:: snapshot_iteration

      The number of iterations after which to save a snapshot.

      :type: int

   .. attribute:: min_masked

      The minimum value of the mask.

      :type: float

   .. attribute:: augments

      The list of augmentations to apply to the data.

      :type: List[Augment]

   .. attribute:: mask_integral_downsample_factor

      The downsample factor for the mask integral.

      :type: int

   .. attribute:: clip_raw

      Whether to clip the raw data.

      :type: bool

   .. attribute:: scheduler

      The learning rate scheduler.

      :type: torch.optim.lr_scheduler.LinearLR

   .. method:: create_optimizer(model

      Model) -> torch.optim.Optimizer:
      Creates an optimizer for the model.

   .. method:: build_batch_provider(datasets

      List[Dataset], model: Model, task: Task, snapshot_container: LocalContainerIdentifier) -> None:
      Initializes the training pipeline using various components.

   .. method:: iterate(num_iterations

      int, model: Model, optimizer: torch.optim.Optimizer, device: torch.device) -> Iterator[TrainingIterationStats]:
      Performs a number of training iterations.

   .. method:: __iter__() -> Iterator[None]

      
      Initializes the training pipeline.

   .. method:: next() -> Tuple[NumpyArray, NumpyArray, NumpyArray, NumpyArray, NumpyArray]

      
      Fetches the next batch of data.

   .. method:: __enter__() -> GunpowderTrainer

      
      Enters the context manager.

   .. method:: __exit__(exc_type, exc_val, exc_tb) -> None

      
      Exits the context manager.

   .. method:: can_train(datasets

      List[Dataset]) -> bool:
      Checks if the trainer can train with a specific set of datasets.

   .. note:: The GunpowderTrainer class is a subclass of the Trainer class. It is used to train a model using gunpowder.


   .. py:attribute:: iteration
      :value: 0



   .. py:method:: create_optimizer(model)

      Creates an optimizer for the model.

      :param model: The model for which the optimizer will be created.
      :type model: Model

      :returns: The optimizer created for the model.
      :rtype: torch.optim.Optimizer

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> optimizer = trainer.create_optimizer(model)



   .. py:method:: build_batch_provider(datasets, model, task, snapshot_container=None)

      Initializes the training pipeline using various components.

      :param datasets: The list of datasets.
      :type datasets: List[Dataset]
      :param model: The model to be trained.
      :type model: Model
      :param task: The task to be performed.
      :type task: Task
      :param snapshot_container: The snapshot container.
      :type snapshot_container: LocalContainerIdentifier

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> trainer.build_batch_provider(datasets, model, task, snapshot_container)



   .. py:method:: iterate(num_iterations, model, optimizer, device)

      Performs a number of training iterations.

      :param num_iterations: The number of training iterations.
      :type num_iterations: int
      :param model: The model to be trained.
      :type model: Model
      :param optimizer: The optimizer for the model.
      :type optimizer: torch.optim.Optimizer
      :param device: The device (GPU/CPU) where the model will be trained.
      :type device: torch.device

      :returns: An iterator of the training statistics.
      :rtype: Iterator[TrainingIterationStats]

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> for iteration_stats in trainer.iterate(num_iterations, model, optimizer, device):
      >>>     print(iteration_stats)



   .. py:method:: next()

      Fetches the next batch of data.

      :returns: A tuple containing the raw data, ground truth data, target data, weight data, and mask data.
      :rtype: Tuple[NumpyArray, NumpyArray, NumpyArray, NumpyArray, NumpyArray]

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> raw, gt, target, weight, mask = trainer.next()



   .. py:method:: can_train(datasets) -> bool

      Checks if the trainer can train with a specific set of datasets.

      :param datasets: The list of datasets.
      :type datasets: List[Dataset]

      :returns: True if the trainer can train with the datasets, False otherwise.
      :rtype: bool

      :raises NotImplementedError: If the method is not implemented by the subclass.

      .. rubric:: Examples

      >>> can_train = trainer.can_train(datasets)



.. py:class:: AugmentConfig



   Base class for gunpowder augment configurations. Each subclass of a `Augment`
   should have a corresponding config class derived from `AugmentConfig`.

   .. attribute:: _raw_key

      Key for raw data. Not used in this implementation. Defaults to None.

   .. attribute:: _gt_key

      Key for ground truth data. Not used in this implementation. Defaults to None.

   .. attribute:: _mask_key

      Key for mask data. Not used in this implementation. Defaults to None.

   .. method:: node(_raw_key=None, _gt_key=None, _mask_key=None)

      Get a gp.Augment node.
      
      


   .. py:method:: node(raw_key: gunpowder.ArrayKey, gt_key: gunpowder.ArrayKey, mask_key: gunpowder.ArrayKey) -> gunpowder.BatchFilter
      :abstractmethod:


      Get a gunpowder augment node.

      :param raw_key: Key for raw data.
      :type raw_key: gp.ArrayKey
      :param gt_key: Key for ground truth data.
      :type gt_key: gp.ArrayKey
      :param mask_key: Key for mask data.
      :type mask_key: gp.ArrayKey

      :returns: Augmentation node which can be incorporated in the pipeline.
      :rtype: gunpowder.BatchFilter

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> node = augment_config.node(raw_key, gt_key, mask_key)



.. py:class:: AugmentConfig



   Base class for gunpowder augment configurations. Each subclass of a `Augment`
   should have a corresponding config class derived from `AugmentConfig`.

   .. attribute:: _raw_key

      Key for raw data. Not used in this implementation. Defaults to None.

   .. attribute:: _gt_key

      Key for ground truth data. Not used in this implementation. Defaults to None.

   .. attribute:: _mask_key

      Key for mask data. Not used in this implementation. Defaults to None.

   .. method:: node(_raw_key=None, _gt_key=None, _mask_key=None)

      Get a gp.Augment node.
      
      


   .. py:method:: node(raw_key: gunpowder.ArrayKey, gt_key: gunpowder.ArrayKey, mask_key: gunpowder.ArrayKey) -> gunpowder.BatchFilter
      :abstractmethod:


      Get a gunpowder augment node.

      :param raw_key: Key for raw data.
      :type raw_key: gp.ArrayKey
      :param gt_key: Key for ground truth data.
      :type gt_key: gp.ArrayKey
      :param mask_key: Key for mask data.
      :type mask_key: gp.ArrayKey

      :returns: Augmentation node which can be incorporated in the pipeline.
      :rtype: gunpowder.BatchFilter

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> node = augment_config.node(raw_key, gt_key, mask_key)



.. py:class:: ElasticAugmentConfig



   A class that holds the configuration details for the elastic augmentations.

   .. attribute:: control_point_spacing

      Distance(in voxels per dimension) between control points for
      the elastic deformation.

      :type: List[int]

   .. attribute:: control_point_displacement_sigma

      Standard deviation of control point displacement
      distribution, in world coordinates.

      :type: List[float]

   .. attribute:: rotation_interval

      An interval to randomly sample rotation angles from
      (0,2PI).

      :type: Tuple[float, float]

   .. attribute:: subsample

      Downsample factor to perform the elastic augmentation
      on a grid. Default is 1.

      :type: int

   .. attribute:: uniform_3d_rotation

      Should 3D rotations be performed uniformly. The 'rotation_interval'
      will be ignored. Default is False.

      :type: bool

   .. method:: node(_raw_key=None, _gt_key=None, _mask_key=None)

      Returns the object of ElasticAugment with the given
      configuration details.
      
      


   .. py:attribute:: control_point_spacing
      :type:  List[int]


   .. py:attribute:: control_point_displacement_sigma
      :type:  List[float]


   .. py:attribute:: rotation_interval
      :type:  Tuple[float, float]


   .. py:attribute:: subsample
      :type:  int


   .. py:attribute:: uniform_3d_rotation
      :type:  bool


   .. py:method:: node(_raw_key=None, _gt_key=None, _mask_key=None)

      Returns the object of ElasticAugment with the given configuration details.

      :param _raw_key: Unused variable, kept for future use.
      :param _gt_key: Unused variable, kept for future use.
      :param _mask_key: Unused variable, kept for future use.

      :returns:

                A ElasticAugment object configured with `control_point_spacing`,
                                `control_point_displacement_sigma`, `rotation_interval`, `subsample` and
                                `uniform_3d_rotation`.
      :rtype: ElasticAugment

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> node = elastic_augment_config.node()



.. py:class:: SimpleAugmentConfig



   This class is an implementation of AugmentConfig that applies simple augmentations.

   :param _raw_key: Key for raw data. Not used in this implementation. Defaults to None.
   :param _gt_key: Key for ground truth data. Not used in this implementation. Defaults to None.
   :param _mask_key: Key for mask data. Not used in this implementation. Defaults to None.

   .. method:: node(_raw_key=None, _gt_key=None, _mask_key=None)

      Get a gp.SimpleAugment node.

   .. note:: This class is a subclass of AugmentConfig.


   .. py:method:: node(_raw_key=None, _gt_key=None, _mask_key=None)

      Get a gp.SimpleAugment node.

      :param _raw_key: Specific key for raw data, not used in this implementation. Defaults to None.
      :type _raw_key: [type], optional
      :param _gt_key: Specific key for ground truth data, not used in this implementation. Defaults to None.
      :type _gt_key: [type], optional
      :param _mask_key: Specific key for mask data, not used in this implementation. Defaults to None.
      :type _mask_key: [type], optional

      :returns: Simple augmentation node which can be incorporated in the pipeline.
      :rtype: gunpowder.SimpleAugment

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> node = simple_augment_config.node()



.. py:class:: GammaAugmentConfig



   This class manages the configuration of gamma augmentation for a given dataset.

   .. attribute:: gamma_range

      A tuple of float values represents the min and max range of gamma noise

   .. attribute:: to apply on the raw data.

      

   .. method:: node()

      Constructs a node in the augmentation pipeline.
      


   .. py:attribute:: gamma_range
      :type:  Tuple[float, float]


   .. py:method:: node(raw_key: gunpowder.ArrayKey, _gt_key=None, _mask_key=None)

      Constructs a node in the augmentation pipeline.

      :param raw_key: Key to an Array (volume) in the pipeline
      :type raw_key: gp.ArrayKey
      :param _gt_key: Ground Truth key, not used in this function. Defaults to None.
      :type _gt_key: gp.ArrayKey, optional
      :param _mask_key: Mask Key, not used in this function. Defaults to None.
      :type _mask_key: gp.ArrayKey, optional

      :returns: The augmentation method to be applied on the source data.
      :rtype: GammaAugment instance

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> node = gamma_augment_config.node(raw_key)



.. py:class:: IntensityAugmentConfig



   This class is an implementation of AugmentConfig that applies intensity augmentations.

   .. attribute:: scale

      A range within which to choose a random scale factor.

      :type: Tuple[float, float]

   .. attribute:: shift

      A range within which to choose a random additive shift.

      :type: Tuple[float, float]

   .. attribute:: clip

      Set to False if modified values should not be clipped to [0, 1]

      :type: bool

   .. method:: node(raw_key, _gt_key=None, _mask_key=None)

      Get a gp.IntensityAugment node.
      
      


   .. py:attribute:: scale
      :type:  Tuple[float, float]


   .. py:attribute:: shift
      :type:  Tuple[float, float]


   .. py:attribute:: clip
      :type:  bool


   .. py:method:: node(raw_key: gunpowder.ArrayKey, _gt_key=None, _mask_key=None)

      Get a gp.IntensityAugment node.

      :param raw_key: Key for raw data.
      :type raw_key: gp.ArrayKey
      :param _gt_key: Specific key for ground truth data, not used in this implementation. Defaults to None.
      :type _gt_key: [type], optional
      :param _mask_key: Specific key for mask data, not used in this implementation. Defaults to None.
      :type _mask_key: [type], optional

      :returns: Intensity augmentation node which can be incorporated in the pipeline.
      :rtype: gunpowder.IntensityAugment

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> node = intensity_augment_config.node(raw_key)



.. py:class:: IntensityScaleShiftAugmentConfig



   This class is an implementation of AugmentConfig that applies intensity scaling and shifting.

   .. attribute:: scale

      A constant to scale your intensities.

      :type: float

   .. attribute:: shift

      A constant to shift your intensities.

      :type: float

   .. method:: node(raw_key, _gt_key=None, _mask_key=None)

      Get a gp.IntensityScaleShift node.

   .. note:: This class is a subclass of AugmentConfig.


   .. py:attribute:: scale
      :type:  float


   .. py:attribute:: shift
      :type:  float


   .. py:method:: node(raw_key: gunpowder.ArrayKey, _gt_key=None, _mask_key=None)

      Get a gp.IntensityScaleShift node.

      :param raw_key: Key for raw data.
      :type raw_key: gp.ArrayKey
      :param _gt_key: Specific key for ground truth data, not used in this implementation. Defaults to None.
      :type _gt_key: [type], optional
      :param _mask_key: Specific key for mask data, not used in this implementation. Defaults to None.
      :type _mask_key: [type], optional

      :returns: Intensity scaling and shifting node which can be incorporated in the pipeline.
      :rtype: gunpowder.IntensityScaleShift

      :raises NotImplementedError: This method is not implemented.

      .. rubric:: Examples

      >>> node = intensity_scale_shift_augment_config.node(raw_key)



.. py:class:: Start(start_config)



   This class interfaces with the dacapo store to retrieve and load the
   weights of the starter model used for finetuning.

   .. attribute:: run

      str
      The specified run to retrieve weights for the model.

   .. attribute:: criterion

      str
      The policy that was used to decide when to store the weights.

   .. attribute:: channels

      int
      The number of channels in the input data.

   .. method:: __init__(start_config)

      
      Initializes the Start class with specified config to run the
      initialization of weights for a model associated with a specific
      criterion.

   .. method:: initialize_weights(model, new_head=None)

      
      Retrieves the weights from the dacapo store and load them into
      the model.

   .. rubric:: Notes

   This class is used to retrieve and load the weights of the starter
   model used for finetuning from the dacapo store.


   .. py:method:: initialize_weights(model, new_head=None)

      Retrieves the weights from the dacapo store and load them into
      the model.

      :param model: obj
                    The model to which the weights are to be loaded.
      :param new_head: list
                       The labels of the new head.

      :returns:

                obj
                    The model with the weights loaded from the dacapo store.
      :rtype: model

      :raises RuntimeError: If weights of a non-existing or mismatched layer are being
          loaded, a RuntimeError exception is thrown which is logged
          and handled by loading only the common layers from weights.

      .. rubric:: Examples

      >>> model = start.initialize_weights(model, new_head)

      .. rubric:: Notes

      This function is called by the Start class to retrieve the weights
      from the dacapo store and load them into the model.



.. py:class:: StartConfig

   A class to represent the configuration for running tasks. This class
   interfaces with the dacapo store to retrieve and load the weights of the
   starter model used for finetuning.

   .. attribute:: run

      str
      The run to be used as a starting point for tasks.

   .. attribute:: criterion

      str
      The criterion to be used for choosing weights from run.

   .. method:: __init__(start_config)

      
      Initializes the StartConfig class with specified config to run the
      initialization of weights for a model associated with a specific
      criterion.

   .. rubric:: Notes

   This class is used to represent the configuration for running tasks.


   .. py:attribute:: start_type


   .. py:attribute:: run
      :type:  str


   .. py:attribute:: criterion
      :type:  str


.. py:class:: CosemStart(start_config)



   A class to represent the starting point for tasks. This class inherits
   from the Start class and is used to load the weights of the starter model
   used for finetuning. The weights are loaded from the dacapo store for the
   specified run and criterion.

   .. attribute:: run

      str
      The run to be used as a starting point for tasks.

   .. attribute:: criterion

      str
      The criterion to be used for choosing weights from run.

   .. attribute:: name

      str
      The name of the run and criterion.

   .. attribute:: channels

      list
      The classes_channels of the model.

   .. method:: __init__(start_config)

      
      Initializes the CosemStart class with specified config to run the
      initialization of weights for a model associated with a specific
      criterion.

   .. method:: check()

      
      Checks if the checkpoint for the specified run and criterion exists.

   .. method:: initialize_weights(model, new_head=None)

      
      Retrieves the weights from the dacapo store and load them into
      the model.

   .. rubric:: Notes

   This class is used to represent the starting point for tasks. The weights
   of the starter model used for finetuning are loaded from the dacapo store.


   .. py:method:: check()

      Checks if the checkpoint for the specified run and criterion exists.

      :raises Exception: If the checkpoint does not exist, an Exception is thrown which
          is logged and handled by training the model without head matching.

      .. rubric:: Examples

      >>> check()

      .. rubric:: Notes

      This function is called by the CosemStart class to check if the
      checkpoint for the specified run and criterion exists.



   .. py:method:: initialize_weights(model, new_head=None)

      Retrieves the weights from the dacapo store and load them into
      the model.

      :param model: obj
                    The model to which the weights are to be loaded.
      :param new_head: list
                       The labels of the new head.

      :returns:

                obj
                    The model with the weights loaded from the dacapo store.
      :rtype: model

      :raises RuntimeError: If weights of a non-existing or mismatched layer are being
          loaded, a RuntimeError exception is thrown which is logged
          and handled by loading only the common layers from weights.

      .. rubric:: Examples

      >>> model = initialize_weights(model, new_head)

      .. rubric:: Notes

      This function is called by the CosemStart class to retrieve the weights
      from the dacapo store and load them into the model.



.. py:class:: CosemStartConfig



   Starter for COSEM pretained models. This is a subclass of `StartConfig` and
   should be used to initialize the model with pretrained weights from a previous
   run.

   The weights are loaded from the dacapo store for the specified run. The
   configuration is used to initialize the weights for the model associated with
   a specific criterion.

   .. attribute:: run

      str
      The run to be used as a starting point for tasks.

   .. attribute:: criterion

      str
      The criterion to be used for choosing weights from run.

   .. method:: __init__(start_config)

      
      Initializes the CosemStartConfig class with specified config to run the
      initialization of weights for a model associated with a specific
      criterion.

   .. rubric:: Examples

   >>> start_config = CosemStartConfig(run="run_1", criterion="best")

   .. rubric:: Notes

   This class is used to represent the configuration for running tasks.


   .. py:attribute:: start_type


.. py:function:: register_hierarchy_hooks(converter)

   Central place to register type hierarchies for conversion.

   :param converter: The converter to register the hooks with.
   :type converter: Converter

   :raises TypeError: If ``cls`` is not a class.

   .. rubric:: Example

   If class ``A`` is the base of class ``B``, and
   ``converter.register_hierarchy(A, lambda typ: eval(typ))`` has been
   called, the dictionary ``y = converter.unstructure(x)`` will
   contain a ``__type__`` field that is ``'A'`` if ``x = A()`` and
   ``B`` if ``x = B()``.

   This ``__type__`` field is then used by ``x =
   converter.structure(y, A)`` to recreate the concrete type of ``x``.

   .. note::

      This method is used to register a class hierarchy for typed
      structure/unstructure conversion. For each class in the hierarchy
      under (including) ``cls``, this will store an additional
      ``__type__`` attribute (a string) in the object dictionary. This
      ``__type__`` string will be the concrete class of the object, and
      will be used to structure the dictionary back into an object of the
      correct class.
      
      For this to work, this function needs to know how to convert a
      ``__type__`` string back into a class, for which it used the
      provided ``cls_fn``.


.. py:function:: register_hooks(converter)

   Central place to register all conversion hooks with the given
   converter.

   :param converter: The converter to register the hooks with.
   :type converter: Converter

   :raises TypeError: If ``cls`` is not a class.

   .. rubric:: Example

   If class ``A`` is the base of class ``B``, and
   ``converter.register_hierarchy(A, lambda typ: eval(typ))`` has been
   called, the dictionary ``y = converter.unstructure(x)`` will
   contain a ``__type__`` field that is ``'A'`` if ``x = A()`` and
   ``B`` if ``x = B()``.

   This ``__type__`` field is then used by ``x =
   converter.structure(y, A)`` to recreate the concrete type of ``x``.

   .. note::

      This method is used to register a class hierarchy for typed
      structure/unstructure conversion. For each class in the hierarchy
      under (including) ``cls``, this will store an additional
      ``__type__`` attribute (a string) in the object dictionary. This
      ``__type__`` string will be the concrete class of the object, and
      will be used to structure the dictionary back into an object of the
      correct class.
      
      For this to work, this function needs to know how to convert a
      ``__type__`` string back into a class, for which it used the
      provided ``cls_fn``.


.. py:function:: cls_fun(typ)

   Convert a type string into the corresponding class. The class must be
   visible to this module (hence the star imports at the top).

   :param typ: The type string to convert.
   :type typ: str

   :returns: The class corresponding to the type string.
   :rtype: class

   :raises NameError: If the class is not visible to this module.

   .. rubric:: Example

   ``cls_fun('TaskConfig')`` will return the class ``TaskConfig``.

   .. note::

      This function is used to convert a type string back into a class. It is
      used in conjunction with the ``register_hierarchy`` function to
      register a class hierarchy for typed structure/unstructure conversion.


