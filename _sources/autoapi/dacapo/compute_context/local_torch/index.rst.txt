dacapo.compute_context.local_torch
==================================

.. py:module:: dacapo.compute_context.local_torch


Classes
-------

.. autoapisummary::

   dacapo.compute_context.local_torch.LocalTorch


Module Contents
---------------

.. py:class:: LocalTorch



   The LocalTorch class is a subclass of the ComputeContext class.
   It is used to specify the context in which computations are to be done.
   LocalTorch is used to specify that computations are to be done on the local machine using PyTorch.

   .. attribute:: _device

      This stores the type of device on which torch computations are to be done. It can

      :type: Optional[str]

   .. attribute:: take "cuda" for GPU or "cpu" for CPU. None value results in automatic detection of device type.

      

   .. attribute:: oom_limit

      The out of GPU memory to leave free in GB. If the free memory is below

      :type: Optional[float | int]

   .. attribute:: this limit, we will fall back on CPU.

      

   .. method:: device()

      Returns the torch device object.

   .. note:: The class is a subclass of the ComputeContext class.


   .. py:attribute:: distribute_workers
      :type:  Optional[bool]


   .. py:attribute:: oom_limit
      :type:  Optional[float | int]


   .. py:property:: device
      A property method that returns the torch device object. It automatically detects and uses "cuda" (GPU) if
      available, else it falls back on using "cpu".

      :returns: The torch device object.
      :rtype: torch.device


